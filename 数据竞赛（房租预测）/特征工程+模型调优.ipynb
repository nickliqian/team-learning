{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务3 特征工程&特征选择(3天)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#核心代码举例\n",
    "\n",
    "# 统计特征\n",
    "    #计算均值\n",
    "    gp = train.groupby(by)[fea].mean()\n",
    "    #计算中位数\n",
    "    gp = train.groupby(by)[fea].median()\n",
    "    #计算方差\n",
    "    gp = train.groupby(by)[fea].std()\n",
    "    #计算最大值\n",
    "    gp = train.groupby(by)[fea].max()\n",
    "    #计算最小值\n",
    "    gp = train.groupby(by)[fea].min()\n",
    "    #计算出现次数\n",
    "    gp = train.groupby(by)[fea].size()\n",
    "    \n",
    "\n",
    "# groupby生成统计特征：mean,std\n",
    "    # 按照communityName分组计算面积的均值和方差\n",
    "    temp = data.groupby('communityName')['area'].agg({'com_area_mean': 'mean', 'com_area_std': 'std'})\n",
    "\n",
    "# 特征拆分\n",
    "    # 将houseType转为'Room'，'Hall'，'Bath'\n",
    "    def Room(x):\n",
    "        Room = int(x.split('室')[0])\n",
    "        return Room\n",
    "    def Hall(x):\n",
    "        Hall = int(x.split(\"室\")[1].split(\"厅\")[0])\n",
    "        return Hall\n",
    "    def Bath(x):\n",
    "        Bath = int(x.split(\"室\")[1].split(\"厅\")[1].split(\"卫\")[0])\n",
    "        return Bath\n",
    "\n",
    "    data['Room'] = data['houseType'].apply(lambda x: Room(x))\n",
    "    data['Hall'] = data['houseType'].apply(lambda x: Hall(x))\n",
    "    data['Bath'] = data['houseType'].apply(lambda x: Bath(x))\n",
    "    \n",
    "#特征合并\n",
    "    # 合并部分配套设施特征\n",
    "    data['trainsportNum'] = 5 * data['subwayStationNum'] / data['subwayStationNum'].mean() + data['busStationNum'] / \\\n",
    "                                                                                             data[\n",
    "                                                                                                 'busStationNum'].mean()\n",
    "\n",
    "# 交叉生成特征:特征之间交叉+ - * / \n",
    "data['Room_Bath'] = (data['Bath']+1) / (data['Room']+1)\n",
    "\n",
    "\n",
    "# 聚类特征\n",
    "from sklearn.mixture import GaussianMixture  使用GaussianMixture做聚类特征\n",
    "gmm = GaussianMixture(n_components=4, covariance_type='full', random_state=0)\n",
    "gmm.fit_predict(data)\n",
    " \n",
    "# 特征编码\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "data['communityName'] = LabelEncoder().fit_transform(data['communityName'])\n",
    "from sklearn import preprocessing.OneHotEncoder\n",
    "data['communityName'] = OneHotEncoder().fit_transform(data['communityName'])\n",
    "\n",
    "\n",
    "# 过大量级值取log平滑（针对线性模型有效）\n",
    "data[feature]=np.log1p(data[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import IsolationForest\n",
    "pd.options.display.max_columns = None\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-24T13:40:19.692972Z",
     "start_time": "2019-12-24T13:40:19.126469Z"
    }
   },
   "outputs": [],
   "source": [
    "origin = pd.read_csv('数据集/train_data.csv')\n",
    "train, test, Y_train, Y_test = train_test_split(origin, origin[\"tradeMoney\"], test_size=0.3, random_state=30)\n",
    "# target_train = train.pop('tradeMoney')\n",
    "# target_test = test.pop('tradeMoney')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41440, 51)\n"
     ]
    }
   ],
   "source": [
    "print(origin.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>area</th>\n",
       "      <th>rentType</th>\n",
       "      <th>houseType</th>\n",
       "      <th>houseFloor</th>\n",
       "      <th>totalFloor</th>\n",
       "      <th>houseToward</th>\n",
       "      <th>houseDecoration</th>\n",
       "      <th>communityName</th>\n",
       "      <th>city</th>\n",
       "      <th>region</th>\n",
       "      <th>plate</th>\n",
       "      <th>buildYear</th>\n",
       "      <th>saleSecHouseNum</th>\n",
       "      <th>subwayStationNum</th>\n",
       "      <th>busStationNum</th>\n",
       "      <th>interSchoolNum</th>\n",
       "      <th>schoolNum</th>\n",
       "      <th>privateSchoolNum</th>\n",
       "      <th>hospitalNum</th>\n",
       "      <th>drugStoreNum</th>\n",
       "      <th>gymNum</th>\n",
       "      <th>bankNum</th>\n",
       "      <th>shopNum</th>\n",
       "      <th>parkNum</th>\n",
       "      <th>mallNum</th>\n",
       "      <th>superMarketNum</th>\n",
       "      <th>totalTradeMoney</th>\n",
       "      <th>totalTradeArea</th>\n",
       "      <th>tradeMeanPrice</th>\n",
       "      <th>tradeSecNum</th>\n",
       "      <th>totalNewTradeMoney</th>\n",
       "      <th>totalNewTradeArea</th>\n",
       "      <th>tradeNewMeanPrice</th>\n",
       "      <th>tradeNewNum</th>\n",
       "      <th>remainNewNum</th>\n",
       "      <th>supplyNewNum</th>\n",
       "      <th>supplyLandNum</th>\n",
       "      <th>supplyLandArea</th>\n",
       "      <th>tradeLandNum</th>\n",
       "      <th>tradeLandArea</th>\n",
       "      <th>landTotalPrice</th>\n",
       "      <th>landMeanPrice</th>\n",
       "      <th>totalWorkers</th>\n",
       "      <th>newWorkers</th>\n",
       "      <th>residentPopulation</th>\n",
       "      <th>pv</th>\n",
       "      <th>uv</th>\n",
       "      <th>lookNum</th>\n",
       "      <th>tradeTime</th>\n",
       "      <th>tradeMoney</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36041</th>\n",
       "      <td>100010531</td>\n",
       "      <td>57.88</td>\n",
       "      <td>未知方式</td>\n",
       "      <td>1室1厅1卫</td>\n",
       "      <td>高</td>\n",
       "      <td>15</td>\n",
       "      <td>南</td>\n",
       "      <td>其他</td>\n",
       "      <td>XQ00706</td>\n",
       "      <td>SH</td>\n",
       "      <td>RG00002</td>\n",
       "      <td>BK00054</td>\n",
       "      <td>暂无信息</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>94</td>\n",
       "      <td>37</td>\n",
       "      <td>50</td>\n",
       "      <td>419</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>126</td>\n",
       "      <td>392130000</td>\n",
       "      <td>12589.57</td>\n",
       "      <td>31147.21154</td>\n",
       "      <td>158</td>\n",
       "      <td>26293744</td>\n",
       "      <td>751</td>\n",
       "      <td>35011.64314</td>\n",
       "      <td>5</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8498</td>\n",
       "      <td>0</td>\n",
       "      <td>428071</td>\n",
       "      <td>64170.0</td>\n",
       "      <td>6665.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018/6/18</td>\n",
       "      <td>2650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>100147629</td>\n",
       "      <td>42.38</td>\n",
       "      <td>未知方式</td>\n",
       "      <td>2室0厅1卫</td>\n",
       "      <td>低</td>\n",
       "      <td>7</td>\n",
       "      <td>西北</td>\n",
       "      <td>其他</td>\n",
       "      <td>XQ03806</td>\n",
       "      <td>SH</td>\n",
       "      <td>RG00012</td>\n",
       "      <td>BK00012</td>\n",
       "      <td>1986</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>42</td>\n",
       "      <td>354</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>438650000</td>\n",
       "      <td>7612.89</td>\n",
       "      <td>57619.37976</td>\n",
       "      <td>113</td>\n",
       "      <td>23201066</td>\n",
       "      <td>240</td>\n",
       "      <td>96671.10833</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120755</td>\n",
       "      <td>0</td>\n",
       "      <td>309216</td>\n",
       "      <td>10489.0</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018/3/2</td>\n",
       "      <td>4000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14429</th>\n",
       "      <td>100150268</td>\n",
       "      <td>78.00</td>\n",
       "      <td>整租</td>\n",
       "      <td>2室2厅1卫</td>\n",
       "      <td>高</td>\n",
       "      <td>18</td>\n",
       "      <td>南</td>\n",
       "      <td>精装</td>\n",
       "      <td>XQ01723</td>\n",
       "      <td>SH</td>\n",
       "      <td>RG00004</td>\n",
       "      <td>BK00043</td>\n",
       "      <td>暂无信息</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>150</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>613340000</td>\n",
       "      <td>17786.21</td>\n",
       "      <td>34484.01880</td>\n",
       "      <td>199</td>\n",
       "      <td>1687918516</td>\n",
       "      <td>34610</td>\n",
       "      <td>48769.67686</td>\n",
       "      <td>301</td>\n",
       "      <td>407</td>\n",
       "      <td>371</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253330</td>\n",
       "      <td>0</td>\n",
       "      <td>165159</td>\n",
       "      <td>30581.0</td>\n",
       "      <td>2704.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018/8/8</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6069</th>\n",
       "      <td>100306156</td>\n",
       "      <td>35.60</td>\n",
       "      <td>未知方式</td>\n",
       "      <td>1室0厅1卫</td>\n",
       "      <td>低</td>\n",
       "      <td>5</td>\n",
       "      <td>南</td>\n",
       "      <td>其他</td>\n",
       "      <td>XQ02684</td>\n",
       "      <td>SH</td>\n",
       "      <td>RG00007</td>\n",
       "      <td>BK00029</td>\n",
       "      <td>1957</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>488757600</td>\n",
       "      <td>9483.30</td>\n",
       "      <td>51538.76815</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49805</td>\n",
       "      <td>111</td>\n",
       "      <td>98604</td>\n",
       "      <td>293.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018/11/11</td>\n",
       "      <td>3550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14485</th>\n",
       "      <td>100149952</td>\n",
       "      <td>36.78</td>\n",
       "      <td>未知方式</td>\n",
       "      <td>1室1厅1卫</td>\n",
       "      <td>高</td>\n",
       "      <td>4</td>\n",
       "      <td>南</td>\n",
       "      <td>其他</td>\n",
       "      <td>XQ01355</td>\n",
       "      <td>SH</td>\n",
       "      <td>RG00003</td>\n",
       "      <td>BK00045</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>824</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>174</td>\n",
       "      <td>88</td>\n",
       "      <td>119</td>\n",
       "      <td>824</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>299</td>\n",
       "      <td>1088280000</td>\n",
       "      <td>37696.24</td>\n",
       "      <td>28869.72282</td>\n",
       "      <td>422</td>\n",
       "      <td>274032611</td>\n",
       "      <td>6796</td>\n",
       "      <td>40322.63258</td>\n",
       "      <td>62</td>\n",
       "      <td>775</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>138730.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46725</td>\n",
       "      <td>0</td>\n",
       "      <td>928198</td>\n",
       "      <td>147575.0</td>\n",
       "      <td>13354.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018/6/8</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID   area rentType houseType houseFloor  totalFloor houseToward  \\\n",
       "36041  100010531  57.88     未知方式    1室1厅1卫          高          15           南   \n",
       "1232   100147629  42.38     未知方式    2室0厅1卫          低           7          西北   \n",
       "14429  100150268  78.00       整租    2室2厅1卫          高          18           南   \n",
       "6069   100306156  35.60     未知方式    1室0厅1卫          低           5           南   \n",
       "14485  100149952  36.78     未知方式    1室1厅1卫          高           4           南   \n",
       "\n",
       "      houseDecoration communityName city   region    plate buildYear  \\\n",
       "36041              其他       XQ00706   SH  RG00002  BK00054      暂无信息   \n",
       "1232               其他       XQ03806   SH  RG00012  BK00012      1986   \n",
       "14429              精装       XQ01723   SH  RG00004  BK00043      暂无信息   \n",
       "6069               其他       XQ02684   SH  RG00007  BK00029      1957   \n",
       "14485              其他       XQ01355   SH  RG00003  BK00045      2003   \n",
       "\n",
       "       saleSecHouseNum  subwayStationNum  busStationNum  interSchoolNum  \\\n",
       "36041                0                 6            306               1   \n",
       "1232                 0                 7             82               0   \n",
       "14429                1                 2             98               0   \n",
       "6069                15                 0             27               3   \n",
       "14485                0                 5            824               3   \n",
       "\n",
       "       schoolNum  privateSchoolNum  hospitalNum  drugStoreNum  gymNum  \\\n",
       "36041         61                 2            5            94      37   \n",
       "1232          59                 8            5            40      25   \n",
       "14429         10                 3            1            37      16   \n",
       "6069          24                 9            5            11       6   \n",
       "14485         99                 9           11           174      88   \n",
       "\n",
       "       bankNum  shopNum  parkNum  mallNum  superMarketNum  totalTradeMoney  \\\n",
       "36041       50      419       14       10             126        392130000   \n",
       "1232        42      354        6        4              63        438650000   \n",
       "14429       18      150        6        8              46        613340000   \n",
       "6069        27       65        4        2              15        488757600   \n",
       "14485      119      824       24       19             299       1088280000   \n",
       "\n",
       "       totalTradeArea  tradeMeanPrice  tradeSecNum  totalNewTradeMoney  \\\n",
       "36041        12589.57     31147.21154          158            26293744   \n",
       "1232          7612.89     57619.37976          113            23201066   \n",
       "14429        17786.21     34484.01880          199          1687918516   \n",
       "6069          9483.30     51538.76815          169                   0   \n",
       "14485        37696.24     28869.72282          422           274032611   \n",
       "\n",
       "       totalNewTradeArea  tradeNewMeanPrice  tradeNewNum  remainNewNum  \\\n",
       "36041                751        35011.64314            5           214   \n",
       "1232                 240        96671.10833            2            59   \n",
       "14429              34610        48769.67686          301           407   \n",
       "6069                   0            0.00000            0             0   \n",
       "14485               6796        40322.63258           62           775   \n",
       "\n",
       "       supplyNewNum  supplyLandNum  supplyLandArea  tradeLandNum  \\\n",
       "36041             0              0             0.0             0   \n",
       "1232              0              0             0.0             0   \n",
       "14429           371              0             0.0             0   \n",
       "6069              0              0             0.0             0   \n",
       "14485             0              2        138730.8             0   \n",
       "\n",
       "       tradeLandArea  landTotalPrice  landMeanPrice  totalWorkers  newWorkers  \\\n",
       "36041            0.0               0            0.0          8498           0   \n",
       "1232             0.0               0            0.0        120755           0   \n",
       "14429            0.0               0            0.0        253330           0   \n",
       "6069             0.0               0            0.0         49805         111   \n",
       "14485            0.0               0            0.0         46725           0   \n",
       "\n",
       "       residentPopulation        pv       uv  lookNum   tradeTime  tradeMoney  \n",
       "36041              428071   64170.0   6665.0        0   2018/6/18      2650.0  \n",
       "1232               309216   10489.0   1328.0        0    2018/3/2      4000.0  \n",
       "14429              165159   30581.0   2704.0        0    2018/8/8      5000.0  \n",
       "6069                98604     293.0     58.0        0  2018/11/11      3550.0  \n",
       "14485              928198  147575.0  13354.0        0    2018/6/8      2000.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>area</th>\n",
       "      <th>rentType</th>\n",
       "      <th>houseType</th>\n",
       "      <th>houseFloor</th>\n",
       "      <th>totalFloor</th>\n",
       "      <th>houseToward</th>\n",
       "      <th>houseDecoration</th>\n",
       "      <th>communityName</th>\n",
       "      <th>city</th>\n",
       "      <th>region</th>\n",
       "      <th>plate</th>\n",
       "      <th>buildYear</th>\n",
       "      <th>saleSecHouseNum</th>\n",
       "      <th>subwayStationNum</th>\n",
       "      <th>busStationNum</th>\n",
       "      <th>interSchoolNum</th>\n",
       "      <th>schoolNum</th>\n",
       "      <th>privateSchoolNum</th>\n",
       "      <th>hospitalNum</th>\n",
       "      <th>drugStoreNum</th>\n",
       "      <th>gymNum</th>\n",
       "      <th>bankNum</th>\n",
       "      <th>shopNum</th>\n",
       "      <th>parkNum</th>\n",
       "      <th>mallNum</th>\n",
       "      <th>superMarketNum</th>\n",
       "      <th>totalTradeMoney</th>\n",
       "      <th>totalTradeArea</th>\n",
       "      <th>tradeMeanPrice</th>\n",
       "      <th>tradeSecNum</th>\n",
       "      <th>totalNewTradeMoney</th>\n",
       "      <th>totalNewTradeArea</th>\n",
       "      <th>tradeNewMeanPrice</th>\n",
       "      <th>tradeNewNum</th>\n",
       "      <th>remainNewNum</th>\n",
       "      <th>supplyNewNum</th>\n",
       "      <th>supplyLandNum</th>\n",
       "      <th>supplyLandArea</th>\n",
       "      <th>tradeLandNum</th>\n",
       "      <th>tradeLandArea</th>\n",
       "      <th>landTotalPrice</th>\n",
       "      <th>landMeanPrice</th>\n",
       "      <th>totalWorkers</th>\n",
       "      <th>newWorkers</th>\n",
       "      <th>residentPopulation</th>\n",
       "      <th>pv</th>\n",
       "      <th>uv</th>\n",
       "      <th>lookNum</th>\n",
       "      <th>tradeTime</th>\n",
       "      <th>tradeMoney</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31363</th>\n",
       "      <td>100035824</td>\n",
       "      <td>62.45</td>\n",
       "      <td>整租</td>\n",
       "      <td>2室1厅1卫</td>\n",
       "      <td>低</td>\n",
       "      <td>18</td>\n",
       "      <td>南</td>\n",
       "      <td>精装</td>\n",
       "      <td>XQ02282</td>\n",
       "      <td>SH</td>\n",
       "      <td>RG00005</td>\n",
       "      <td>BK00040</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>138</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>224</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>75</td>\n",
       "      <td>141480000</td>\n",
       "      <td>4519.40</td>\n",
       "      <td>31305.04049</td>\n",
       "      <td>65</td>\n",
       "      <td>14982767</td>\n",
       "      <td>248</td>\n",
       "      <td>60414.38306</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17401</td>\n",
       "      <td>0</td>\n",
       "      <td>319860</td>\n",
       "      <td>23515.0</td>\n",
       "      <td>2661.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018/3/9</td>\n",
       "      <td>5300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26208</th>\n",
       "      <td>100064898</td>\n",
       "      <td>44.29</td>\n",
       "      <td>未知方式</td>\n",
       "      <td>1室1厅1卫</td>\n",
       "      <td>中</td>\n",
       "      <td>6</td>\n",
       "      <td>南</td>\n",
       "      <td>其他</td>\n",
       "      <td>XQ02249</td>\n",
       "      <td>SH</td>\n",
       "      <td>RG00005</td>\n",
       "      <td>BK00039</td>\n",
       "      <td>1980</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>1040680000</td>\n",
       "      <td>21633.04</td>\n",
       "      <td>48106.04520</td>\n",
       "      <td>250</td>\n",
       "      <td>68461853</td>\n",
       "      <td>792</td>\n",
       "      <td>86441.73359</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11209</td>\n",
       "      <td>0</td>\n",
       "      <td>134822</td>\n",
       "      <td>8431.0</td>\n",
       "      <td>1405.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018/9/2</td>\n",
       "      <td>3700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11590</th>\n",
       "      <td>100200789</td>\n",
       "      <td>100.00</td>\n",
       "      <td>未知方式</td>\n",
       "      <td>2室1厅1卫</td>\n",
       "      <td>低</td>\n",
       "      <td>7</td>\n",
       "      <td>南</td>\n",
       "      <td>毛坯</td>\n",
       "      <td>XQ01634</td>\n",
       "      <td>SH</td>\n",
       "      <td>RG00004</td>\n",
       "      <td>BK00042</td>\n",
       "      <td>暂无信息</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>441</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>145</td>\n",
       "      <td>84</td>\n",
       "      <td>91</td>\n",
       "      <td>671</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>159</td>\n",
       "      <td>109340000</td>\n",
       "      <td>3382.67</td>\n",
       "      <td>32323.57871</td>\n",
       "      <td>45</td>\n",
       "      <td>835783956</td>\n",
       "      <td>26501</td>\n",
       "      <td>31537.82710</td>\n",
       "      <td>259</td>\n",
       "      <td>2193</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120140</td>\n",
       "      <td>0</td>\n",
       "      <td>589930</td>\n",
       "      <td>80164.0</td>\n",
       "      <td>5250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018/2/28</td>\n",
       "      <td>2700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8479</th>\n",
       "      <td>100262036</td>\n",
       "      <td>41.00</td>\n",
       "      <td>未知方式</td>\n",
       "      <td>1室1厅1卫</td>\n",
       "      <td>中</td>\n",
       "      <td>15</td>\n",
       "      <td>南</td>\n",
       "      <td>其他</td>\n",
       "      <td>XQ01413</td>\n",
       "      <td>SH</td>\n",
       "      <td>RG00003</td>\n",
       "      <td>BK00046</td>\n",
       "      <td>2007</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>167</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>560700000</td>\n",
       "      <td>16001.07</td>\n",
       "      <td>35041.40661</td>\n",
       "      <td>149</td>\n",
       "      <td>368507053</td>\n",
       "      <td>7965</td>\n",
       "      <td>46265.79448</td>\n",
       "      <td>58</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19615</td>\n",
       "      <td>0</td>\n",
       "      <td>274232</td>\n",
       "      <td>17911.0</td>\n",
       "      <td>4094.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018/9/10</td>\n",
       "      <td>3700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>100036819</td>\n",
       "      <td>144.50</td>\n",
       "      <td>未知方式</td>\n",
       "      <td>3室2厅2卫</td>\n",
       "      <td>中</td>\n",
       "      <td>11</td>\n",
       "      <td>南北</td>\n",
       "      <td>其他</td>\n",
       "      <td>XQ01033</td>\n",
       "      <td>SH</td>\n",
       "      <td>RG00002</td>\n",
       "      <td>BK00056</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>88</td>\n",
       "      <td>52</td>\n",
       "      <td>75</td>\n",
       "      <td>341</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>130</td>\n",
       "      <td>1905570000</td>\n",
       "      <td>35849.63</td>\n",
       "      <td>53154.52349</td>\n",
       "      <td>443</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>388879</td>\n",
       "      <td>0</td>\n",
       "      <td>491767</td>\n",
       "      <td>39739.0</td>\n",
       "      <td>6001.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018/7/31</td>\n",
       "      <td>7500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID    area rentType houseType houseFloor  totalFloor  \\\n",
       "31363  100035824   62.45       整租    2室1厅1卫          低          18   \n",
       "26208  100064898   44.29     未知方式    1室1厅1卫          中           6   \n",
       "11590  100200789  100.00     未知方式    2室1厅1卫          低           7   \n",
       "8479   100262036   41.00     未知方式    1室1厅1卫          中          15   \n",
       "3401   100036819  144.50     未知方式    3室2厅2卫          中          11   \n",
       "\n",
       "      houseToward houseDecoration communityName city   region    plate  \\\n",
       "31363           南              精装       XQ02282   SH  RG00005  BK00040   \n",
       "26208           南              其他       XQ02249   SH  RG00005  BK00039   \n",
       "11590           南              毛坯       XQ01634   SH  RG00004  BK00042   \n",
       "8479            南              其他       XQ01413   SH  RG00003  BK00046   \n",
       "3401           南北              其他       XQ01033   SH  RG00002  BK00056   \n",
       "\n",
       "      buildYear  saleSecHouseNum  subwayStationNum  busStationNum  \\\n",
       "31363      2010                0                 7            138   \n",
       "26208      1980                4                 1             41   \n",
       "11590      暂无信息                0                13            441   \n",
       "8479       2007                6                 1            167   \n",
       "3401       2002                0                14            258   \n",
       "\n",
       "       interSchoolNum  schoolNum  privateSchoolNum  hospitalNum  drugStoreNum  \\\n",
       "31363               2         41                24            0            67   \n",
       "26208               2         21                 9            2            22   \n",
       "11590               1         62                 8            9           145   \n",
       "8479                1         13                 2            3            54   \n",
       "3401                0         98                13            5            88   \n",
       "\n",
       "       gymNum  bankNum  shopNum  parkNum  mallNum  superMarketNum  \\\n",
       "31363      43       35      224        7        6              75   \n",
       "26208      28       24       80        1        2              21   \n",
       "11590      84       91      671       30       16             159   \n",
       "8479       25       21      167        0        2             100   \n",
       "3401       52       75      341       11        7             130   \n",
       "\n",
       "       totalTradeMoney  totalTradeArea  tradeMeanPrice  tradeSecNum  \\\n",
       "31363        141480000         4519.40     31305.04049           65   \n",
       "26208       1040680000        21633.04     48106.04520          250   \n",
       "11590        109340000         3382.67     32323.57871           45   \n",
       "8479         560700000        16001.07     35041.40661          149   \n",
       "3401        1905570000        35849.63     53154.52349          443   \n",
       "\n",
       "       totalNewTradeMoney  totalNewTradeArea  tradeNewMeanPrice  tradeNewNum  \\\n",
       "31363            14982767                248        60414.38306            1   \n",
       "26208            68461853                792        86441.73359            3   \n",
       "11590           835783956              26501        31537.82710          259   \n",
       "8479            368507053               7965        46265.79448           58   \n",
       "3401                    0                  0            0.00000            0   \n",
       "\n",
       "       remainNewNum  supplyNewNum  supplyLandNum  supplyLandArea  \\\n",
       "31363            48             0              0             0.0   \n",
       "26208            61             0              0             0.0   \n",
       "11590          2193           258              0             0.0   \n",
       "8479            142             0              0             0.0   \n",
       "3401             82             0              0             0.0   \n",
       "\n",
       "       tradeLandNum  tradeLandArea  landTotalPrice  landMeanPrice  \\\n",
       "31363             0            0.0               0            0.0   \n",
       "26208             0            0.0               0            0.0   \n",
       "11590             0            0.0               0            0.0   \n",
       "8479              0            0.0               0            0.0   \n",
       "3401              0            0.0               0            0.0   \n",
       "\n",
       "       totalWorkers  newWorkers  residentPopulation       pv      uv  lookNum  \\\n",
       "31363         17401           0              319860  23515.0  2661.0        0   \n",
       "26208         11209           0              134822   8431.0  1405.0        0   \n",
       "11590        120140           0              589930  80164.0  5250.0        0   \n",
       "8479          19615           0              274232  17911.0  4094.0        0   \n",
       "3401         388879           0              491767  39739.0  6001.0        0   \n",
       "\n",
       "       tradeTime  tradeMoney  \n",
       "31363   2018/3/9      5300.0  \n",
       "26208   2018/9/2      3700.0  \n",
       "11590  2018/2/28      2700.0  \n",
       "8479   2018/9/10      3700.0  \n",
       "3401   2018/7/31      7500.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = train.pop('tradeMoney')\n",
    "target_test = test.pop('tradeMoney')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # clean data\n",
    "# def IF_drop(data):\n",
    "#     # 孤立森林模型\n",
    "#     IForest = IsolationForest(contamination=0.01)\n",
    "#     IForest.fit(data[\"tradeMoney\"].values.reshape(-1,1))\n",
    "#     y_pred = IForest.predict(data[\"tradeMoney\"].values.reshape(-1,1))\n",
    "#     # 训练孤立点森林模型，然后预测孤立点，筛选出他们的索引并把这些行删除掉\n",
    "#     drop_index = data.loc[y_pred==-1].index\n",
    "#     data.drop(drop_index,inplace=True)\n",
    "#     return data\n",
    "\n",
    "# train = IF_drop(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocessingData(data):\n",
    "    # 填充缺失值\n",
    "    # 有两种缺失值：-- 和 未知方式 \n",
    "    # 把 -- 转换为 未知方式 然后使用 labelEncoder 编码\n",
    "    data['rentType'][data['rentType'] == '--'] = '未知方式'\n",
    "    \n",
    "    # 转换object类型数据\n",
    "    columns = ['rentType','communityName', 'houseFloor', 'houseToward', 'houseDecoration',  'region', 'plate']\n",
    "    \n",
    "    for feature in columns:\n",
    "        le = LabelEncoder()\n",
    "        data[feature] = le.fit_transform(data[feature])\n",
    "#         print(le.classes_)\n",
    "\n",
    "    # 将buildYear列转换为整型数据\n",
    "    # 缺失值是 暂无信息\n",
    "    # 取非缺失值，计算buildYear的众数： 1994\n",
    "    # buildYearmean.iloc[0, 0] 是取这个serise的值\n",
    "    buildYearmean = pd.DataFrame(data[data['buildYear'] != '暂无信息']['buildYear'].mode())\n",
    "    # data[data['buildYear'] != '暂无信息']['buildYear'] 这种方式也可以赋值\n",
    "    data.loc[data[data['buildYear'] == '暂无信息'].index, 'buildYear'] = buildYearmean.iloc[0, 0]\n",
    "    # 改变buildYear类型 buildYear最开始是object类型，现在需要转换为int类型\n",
    "    data['buildYear'] = data['buildYear'].astype('int')\n",
    "\n",
    "    # 处理pv和uv的空值\n",
    "    # 使用平均值填充\n",
    "    data['pv'].fillna(data['pv'].mean(), inplace=True)\n",
    "    data['uv'].fillna(data['uv'].mean(), inplace=True)\n",
    "    # pv和uv是float类型，根据实际经验这里转为int类型\n",
    "    data['pv'] = data['pv'].astype('int')\n",
    "    data['uv'] = data['uv'].astype('int')\n",
    "\n",
    "    # 分割交易时间tradeTime\n",
    "    # 没有缺失值，可以直接处理\n",
    "    # 全部是2008年所以不用分割年\n",
    "    # 分割出月和日即可\n",
    "    def month(x):\n",
    "        month = int(x.split('/')[1])\n",
    "        return month\n",
    "    def day(x):\n",
    "        day = int(x.split('/')[2])\n",
    "        return day\n",
    "    data['month'] = data['tradeTime'].apply(lambda x: month(x))\n",
    "    data['day'] = data['tradeTime'].apply(lambda x: day(x))\n",
    "    \n",
    "    # 去掉部分特征\n",
    "    data.drop('city', axis=1, inplace=True)\n",
    "#     data.drop('tradeTime', axis=1, inplace=True)\n",
    "    data.drop('ID', axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "train = preprocessingData(train)\n",
    "test = preprocessingData(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['Type'] = 'Train'\n",
    "# test['Type'] = 'Test'\n",
    "# data_all = pd.concat([train, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-24T13:40:55.454321Z",
     "start_time": "2019-12-24T13:40:55.291756Z"
    }
   },
   "outputs": [],
   "source": [
    "def newfeature(data):\n",
    "\n",
    "    # 将x室x厅拆分\n",
    "    # 将houseType转为'Room'，'Hall'，'Bath'\n",
    "    def Room(x):\n",
    "        Room = int(x.split('室')[0])\n",
    "        return Room\n",
    "    def Hall(x):\n",
    "        Hall = int(x.split(\"室\")[1].split(\"厅\")[0])\n",
    "        return Hall\n",
    "    def Bath(x):\n",
    "        Bath = int(x.split(\"室\")[1].split(\"厅\")[1].split(\"卫\")[0])\n",
    "        return Bath\n",
    "\n",
    "    data['Room'] = data['houseType'].apply(lambda x: Room(x))\n",
    "    data['Hall'] = data['houseType'].apply(lambda x: Hall(x))\n",
    "    data['Bath'] = data['houseType'].apply(lambda x: Bath(x))\n",
    "    data['Room_Bath'] = (data['Bath']+1) / (data['Room']+1)\n",
    "    \n",
    "    # 根据面积和房间的数量填充租房类型（未知方式的真实类型）\n",
    "    # 填充租房类型\n",
    "    data.loc[(data['rentType'] == '未知方式') & (data['Room'] <= 1), 'rentType'] = '整租'\n",
    "    # print(data.loc[(data['rentType']=='未知方式')&(data['Room_Bath']>1),'rentType'])\n",
    "    data.loc[(data['rentType'] == '未知方式') & (data['Room_Bath'] > 1), 'rentType'] = '合租'\n",
    "    data.loc[(data['rentType'] == '未知方式') & (data['Room'] > 1) & (data['area'] < 50), 'rentType'] = '合租'\n",
    "    data.loc[(data['rentType'] == '未知方式') & (data['area'] / data['Room'] < 20), 'rentType'] = '合租'\n",
    "    # data.loc[(data['rentType']=='未知方式')&(data['area']>60),'rentType']='合租'\n",
    "    data.loc[(data['rentType'] == '未知方式') & (data['area'] <= 50) & (data['Room'] == 2), 'rentType'] = '合租'\n",
    "    data.loc[(data['rentType'] == '未知方式') & (data['area'] > 60) & (data['Room'] == 2), 'rentType'] = '整租'\n",
    "    data.loc[(data['rentType'] == '未知方式') & (data['area'] <= 60) & (data['Room'] == 3), 'rentType'] = '合租'\n",
    "    data.loc[(data['rentType'] == '未知方式') & (data['area'] > 60) & (data['Room'] == 3), 'rentType'] = '整租'\n",
    "    data.loc[(data['rentType'] == '未知方式') & (data['area'] >= 100) & (data['Room'] > 3), 'rentType'] = '整租'\n",
    "    \n",
    "    # 拆分成交日期，单独构造成交月份的字段\n",
    "    # data.drop('Room_Bath', axis=1, inplace=True)\n",
    "    # 提升0.0001\n",
    "    def month(x):\n",
    "        month = int(x.split('/')[1])\n",
    "        return month\n",
    "    # def day(x):\n",
    "    #     day = int(x.split('/')[2])\n",
    "    #     return day\n",
    "    # 结果变差\n",
    "\n",
    "    # 分割交易时间\n",
    "    # data['year']=data['tradeTime'].apply(lambda x:year(x))\n",
    "    data['month'] = data['tradeTime'].apply(lambda x: month(x))\n",
    "    # data['day'] = data['tradeTime'].apply(lambda x: day(x))# 结果变差\n",
    "    #     data['pv/uv'] = data['pv'] / data['uv']\n",
    "    #     data['房间总数'] = data['室'] + data['厅'] + data['卫']\n",
    "\n",
    "    # 合并部分配套设施特征\n",
    "    data['trainsportNum'] = 5 * data['subwayStationNum'] / data['subwayStationNum'].mean() + data['busStationNum'] / \\\n",
    "                                                                                             data[\n",
    "                                                                                                 'busStationNum'].mean()\n",
    "    data['all_SchoolNum'] = 2 * data['interSchoolNum'] / data['interSchoolNum'].mean() + data['schoolNum'] / data[\n",
    "        'schoolNum'].mean() \\\n",
    "                            + data['privateSchoolNum'] / data['privateSchoolNum'].mean()\n",
    "    data['all_hospitalNum'] = 2 * data['hospitalNum'] / data['hospitalNum'].mean() + \\\n",
    "                              data['drugStoreNum'] / data['drugStoreNum'].mean()\n",
    "    data['all_mall'] = data['mallNum'] / data['mallNum'].mean() + \\\n",
    "                       data['superMarketNum'] / data['superMarketNum'].mean()\n",
    "    data['otherNum'] = data['gymNum'] / data['gymNum'].mean() + data['bankNum'] / data['bankNum'].mean() + \\\n",
    "                       data['shopNum'] / data['shopNum'].mean() + 2 * data['parkNum'] / data['parkNum'].mean()\n",
    "\n",
    "    data.drop(['subwayStationNum', 'busStationNum',\n",
    "               'interSchoolNum', 'schoolNum', 'privateSchoolNum',\n",
    "               'hospitalNum', 'drugStoreNum', 'mallNum', 'superMarketNum', 'gymNum', 'bankNum', 'shopNum', 'parkNum'],\n",
    "              axis=1, inplace=True)\n",
    "    # 提升0.0005\n",
    "    \n",
    "#     data['houseType_1sumcsu']=data['Bath'].map(lambda x:str(x))+data['month'].map(lambda x:str(x))\n",
    "#     data['houseType_2sumcsu']=data['Bath'].map(lambda x:str(x))+data['communityName']\n",
    "#     data['houseType_3sumcsu']=data['Bath'].map(lambda x:str(x))+data['plate']\n",
    "    \n",
    "    data.drop('houseType', axis=1, inplace=True)\n",
    "    data.drop('tradeTime', axis=1, inplace=True)\n",
    "    \n",
    "    data[\"area\"] = data[\"area\"].astype(int)\n",
    "\n",
    "\n",
    "    # categorical_feats = ['rentType', 'houseFloor', 'houseToward', 'houseDecoration', 'communityName','region', 'plate']\n",
    "    categorical_feats = ['rentType', 'houseFloor', 'houseToward', 'houseDecoration',  'region', 'plate','cluster']\n",
    "\n",
    "    return data, categorical_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, cate_df_all = newfeature(train)\n",
    "test, cate_df_all = newfeature(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>rentType</th>\n",
       "      <th>houseFloor</th>\n",
       "      <th>totalFloor</th>\n",
       "      <th>houseToward</th>\n",
       "      <th>houseDecoration</th>\n",
       "      <th>communityName</th>\n",
       "      <th>region</th>\n",
       "      <th>plate</th>\n",
       "      <th>buildYear</th>\n",
       "      <th>saleSecHouseNum</th>\n",
       "      <th>totalTradeMoney</th>\n",
       "      <th>totalTradeArea</th>\n",
       "      <th>tradeMeanPrice</th>\n",
       "      <th>tradeSecNum</th>\n",
       "      <th>totalNewTradeMoney</th>\n",
       "      <th>totalNewTradeArea</th>\n",
       "      <th>tradeNewMeanPrice</th>\n",
       "      <th>tradeNewNum</th>\n",
       "      <th>remainNewNum</th>\n",
       "      <th>supplyNewNum</th>\n",
       "      <th>supplyLandNum</th>\n",
       "      <th>supplyLandArea</th>\n",
       "      <th>tradeLandNum</th>\n",
       "      <th>tradeLandArea</th>\n",
       "      <th>landTotalPrice</th>\n",
       "      <th>landMeanPrice</th>\n",
       "      <th>totalWorkers</th>\n",
       "      <th>newWorkers</th>\n",
       "      <th>residentPopulation</th>\n",
       "      <th>pv</th>\n",
       "      <th>uv</th>\n",
       "      <th>lookNum</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>Room</th>\n",
       "      <th>Hall</th>\n",
       "      <th>Bath</th>\n",
       "      <th>Room_Bath</th>\n",
       "      <th>trainsportNum</th>\n",
       "      <th>all_SchoolNum</th>\n",
       "      <th>all_hospitalNum</th>\n",
       "      <th>all_mall</th>\n",
       "      <th>otherNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36041</th>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>646</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1994</td>\n",
       "      <td>0</td>\n",
       "      <td>392130000</td>\n",
       "      <td>12589.57</td>\n",
       "      <td>31147.21154</td>\n",
       "      <td>158</td>\n",
       "      <td>26293744</td>\n",
       "      <td>751</td>\n",
       "      <td>35011.64314</td>\n",
       "      <td>5</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8498</td>\n",
       "      <td>0</td>\n",
       "      <td>428071</td>\n",
       "      <td>64170</td>\n",
       "      <td>6665</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.861430</td>\n",
       "      <td>2.914163</td>\n",
       "      <td>3.955609</td>\n",
       "      <td>3.118232</td>\n",
       "      <td>7.035898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3470</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1986</td>\n",
       "      <td>0</td>\n",
       "      <td>438650000</td>\n",
       "      <td>7612.89</td>\n",
       "      <td>57619.37976</td>\n",
       "      <td>113</td>\n",
       "      <td>23201066</td>\n",
       "      <td>240</td>\n",
       "      <td>96671.10833</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120755</td>\n",
       "      <td>0</td>\n",
       "      <td>309216</td>\n",
       "      <td>10489</td>\n",
       "      <td>1328</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6.533145</td>\n",
       "      <td>2.499231</td>\n",
       "      <td>3.019493</td>\n",
       "      <td>1.399270</td>\n",
       "      <td>4.335986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14429</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1595</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "      <td>613340000</td>\n",
       "      <td>17786.21</td>\n",
       "      <td>34484.01880</td>\n",
       "      <td>199</td>\n",
       "      <td>1687918516</td>\n",
       "      <td>34610</td>\n",
       "      <td>48769.67686</td>\n",
       "      <td>301</td>\n",
       "      <td>407</td>\n",
       "      <td>371</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253330</td>\n",
       "      <td>0</td>\n",
       "      <td>165159</td>\n",
       "      <td>30581</td>\n",
       "      <td>2704</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.265734</td>\n",
       "      <td>0.685633</td>\n",
       "      <td>1.106628</td>\n",
       "      <td>1.833608</td>\n",
       "      <td>2.839831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6069</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2466</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>1957</td>\n",
       "      <td>15</td>\n",
       "      <td>488757600</td>\n",
       "      <td>9483.30</td>\n",
       "      <td>51538.76815</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49805</td>\n",
       "      <td>111</td>\n",
       "      <td>98604</td>\n",
       "      <td>293</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.144510</td>\n",
       "      <td>5.921589</td>\n",
       "      <td>2.516764</td>\n",
       "      <td>0.500618</td>\n",
       "      <td>1.940400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14485</th>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1255</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>1088280000</td>\n",
       "      <td>37696.24</td>\n",
       "      <td>28869.72282</td>\n",
       "      <td>422</td>\n",
       "      <td>274032611</td>\n",
       "      <td>6796</td>\n",
       "      <td>40322.63258</td>\n",
       "      <td>62</td>\n",
       "      <td>775</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>138730.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46725</td>\n",
       "      <td>0</td>\n",
       "      <td>928198</td>\n",
       "      <td>147575</td>\n",
       "      <td>13354</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.763263</td>\n",
       "      <td>7.477743</td>\n",
       "      <td>8.133736</td>\n",
       "      <td>6.643515</td>\n",
       "      <td>13.817228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       area  rentType  houseFloor  totalFloor  houseToward  houseDecoration  \\\n",
       "36041    57         2           2          15            4                0   \n",
       "1232     42         2           1           7            8                0   \n",
       "14429    78         1           2          18            4                3   \n",
       "6069     35         2           1           5            4                0   \n",
       "14485    36         2           2           4            4                0   \n",
       "\n",
       "       communityName  region  plate  buildYear  saleSecHouseNum  \\\n",
       "36041            646       1     53       1994                0   \n",
       "1232            3470      11     11       1986                0   \n",
       "14429           1595       3     42       1994                1   \n",
       "6069            2466       6     28       1957               15   \n",
       "14485           1255       2     44       2003                0   \n",
       "\n",
       "       totalTradeMoney  totalTradeArea  tradeMeanPrice  tradeSecNum  \\\n",
       "36041        392130000        12589.57     31147.21154          158   \n",
       "1232         438650000         7612.89     57619.37976          113   \n",
       "14429        613340000        17786.21     34484.01880          199   \n",
       "6069         488757600         9483.30     51538.76815          169   \n",
       "14485       1088280000        37696.24     28869.72282          422   \n",
       "\n",
       "       totalNewTradeMoney  totalNewTradeArea  tradeNewMeanPrice  tradeNewNum  \\\n",
       "36041            26293744                751        35011.64314            5   \n",
       "1232             23201066                240        96671.10833            2   \n",
       "14429          1687918516              34610        48769.67686          301   \n",
       "6069                    0                  0            0.00000            0   \n",
       "14485           274032611               6796        40322.63258           62   \n",
       "\n",
       "       remainNewNum  supplyNewNum  supplyLandNum  supplyLandArea  \\\n",
       "36041           214             0              0             0.0   \n",
       "1232             59             0              0             0.0   \n",
       "14429           407           371              0             0.0   \n",
       "6069              0             0              0             0.0   \n",
       "14485           775             0              2        138730.8   \n",
       "\n",
       "       tradeLandNum  tradeLandArea  landTotalPrice  landMeanPrice  \\\n",
       "36041             0            0.0               0            0.0   \n",
       "1232              0            0.0               0            0.0   \n",
       "14429             0            0.0               0            0.0   \n",
       "6069              0            0.0               0            0.0   \n",
       "14485             0            0.0               0            0.0   \n",
       "\n",
       "       totalWorkers  newWorkers  residentPopulation      pv     uv  lookNum  \\\n",
       "36041          8498           0              428071   64170   6665        0   \n",
       "1232         120755           0              309216   10489   1328        0   \n",
       "14429        253330           0              165159   30581   2704        0   \n",
       "6069          49805         111               98604     293     58        0   \n",
       "14485         46725           0              928198  147575  13354        0   \n",
       "\n",
       "       month  day  Room  Hall  Bath  Room_Bath  trainsportNum  all_SchoolNum  \\\n",
       "36041      6   18     1     1     1   1.000000       6.861430       2.914163   \n",
       "1232       3    2     2     0     1   0.666667       6.533145       2.499231   \n",
       "14429      8    8     2     2     1   0.666667       2.265734       0.685633   \n",
       "6069      11   11     1     0     1   1.000000       0.144510       5.921589   \n",
       "14485      6    8     1     1     1   1.000000       8.763263       7.477743   \n",
       "\n",
       "       all_hospitalNum  all_mall   otherNum  \n",
       "36041         3.955609  3.118232   7.035898  \n",
       "1232          3.019493  1.399270   4.335986  \n",
       "14429         1.106628  1.833608   2.839831  \n",
       "6069          2.516764  0.500618   1.940400  \n",
       "14485         8.133736  6.643515  13.817228  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rentType',\n",
       " 'houseFloor',\n",
       " 'houseToward',\n",
       " 'houseDecoration',\n",
       " 'region',\n",
       " 'plate',\n",
       " 'cluster']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-24T13:41:02.458588Z",
     "start_time": "2019-12-24T13:41:00.981539Z"
    }
   },
   "outputs": [],
   "source": [
    "#计算统计特征\n",
    "# 统计不同行数据指定字段该特征值在所有数据中有多少条\n",
    "def featureCount(train,test):\n",
    "    train['data_type'] = 0\n",
    "    test['data_type'] = 1\n",
    "    data = pd.concat([train, test], axis=0, join='outer')\n",
    "    def feature_count(data, features=[]):\n",
    "        new_feature = 'count'\n",
    "        for i in features:\n",
    "            new_feature += '_' + i\n",
    "        temp = data.groupby(features).size().reset_index().rename(columns={0: new_feature})\n",
    "        data = data.merge(temp, 'left', on=features)\n",
    "        return data\n",
    "\n",
    "    data = feature_count(data, ['communityName'])  # 统计相同小区出现了多少次\n",
    "    data = feature_count(data, ['buildYear'])  # 统计相同的建筑年限出现了多少次\n",
    "    data = feature_count(data, ['totalFloor'])  # 统计相同的总楼层出现的次数\n",
    "    data = feature_count(data, ['communityName', 'totalFloor'])  # 不同小区的总楼层\n",
    "    data = feature_count(data, ['communityName', 'newWorkers'])  # 不同的小区的当月流入人口\n",
    "    data = feature_count(data, ['communityName', 'totalTradeMoney'])  # 不同小区的当月二手房成交总额次数\n",
    "    new_train = data[data['data_type'] == 0]\n",
    "    new_test = data[data['data_type'] == 1]\n",
    "    new_train.drop('data_type', axis=1, inplace=True)\n",
    "    new_test.drop(['data_type'], axis=1, inplace=True)\n",
    "    return new_train, new_test\n",
    "    \n",
    "train, test = featureCount(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "communityName\n",
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(\"communityName\").size()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "communityName  totalTradeMoney\n",
       "0              339655896          1\n",
       "1              416910000          1\n",
       "2              416910000          1\n",
       "3              509150000          1\n",
       "4              416910000          1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['communityName', 'totalTradeMoney']).size()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>rentType</th>\n",
       "      <th>houseFloor</th>\n",
       "      <th>totalFloor</th>\n",
       "      <th>houseToward</th>\n",
       "      <th>houseDecoration</th>\n",
       "      <th>communityName</th>\n",
       "      <th>region</th>\n",
       "      <th>plate</th>\n",
       "      <th>buildYear</th>\n",
       "      <th>saleSecHouseNum</th>\n",
       "      <th>totalTradeMoney</th>\n",
       "      <th>totalTradeArea</th>\n",
       "      <th>tradeMeanPrice</th>\n",
       "      <th>tradeSecNum</th>\n",
       "      <th>totalNewTradeMoney</th>\n",
       "      <th>totalNewTradeArea</th>\n",
       "      <th>tradeNewMeanPrice</th>\n",
       "      <th>tradeNewNum</th>\n",
       "      <th>remainNewNum</th>\n",
       "      <th>supplyNewNum</th>\n",
       "      <th>supplyLandNum</th>\n",
       "      <th>supplyLandArea</th>\n",
       "      <th>tradeLandNum</th>\n",
       "      <th>tradeLandArea</th>\n",
       "      <th>landTotalPrice</th>\n",
       "      <th>landMeanPrice</th>\n",
       "      <th>totalWorkers</th>\n",
       "      <th>newWorkers</th>\n",
       "      <th>residentPopulation</th>\n",
       "      <th>pv</th>\n",
       "      <th>uv</th>\n",
       "      <th>lookNum</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>Room</th>\n",
       "      <th>Hall</th>\n",
       "      <th>Bath</th>\n",
       "      <th>Room_Bath</th>\n",
       "      <th>trainsportNum</th>\n",
       "      <th>all_SchoolNum</th>\n",
       "      <th>all_hospitalNum</th>\n",
       "      <th>all_mall</th>\n",
       "      <th>otherNum</th>\n",
       "      <th>count_communityName</th>\n",
       "      <th>count_buildYear</th>\n",
       "      <th>count_totalFloor</th>\n",
       "      <th>count_communityName_totalFloor</th>\n",
       "      <th>count_communityName_newWorkers</th>\n",
       "      <th>count_communityName_totalTradeMoney</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>646</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1994</td>\n",
       "      <td>0</td>\n",
       "      <td>392130000</td>\n",
       "      <td>12589.57</td>\n",
       "      <td>31147.21154</td>\n",
       "      <td>158</td>\n",
       "      <td>26293744</td>\n",
       "      <td>751</td>\n",
       "      <td>35011.64314</td>\n",
       "      <td>5</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8498</td>\n",
       "      <td>0</td>\n",
       "      <td>428071</td>\n",
       "      <td>64170</td>\n",
       "      <td>6665</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.861430</td>\n",
       "      <td>2.914163</td>\n",
       "      <td>3.955609</td>\n",
       "      <td>3.118232</td>\n",
       "      <td>7.035898</td>\n",
       "      <td>15</td>\n",
       "      <td>5659</td>\n",
       "      <td>809</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3470</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1986</td>\n",
       "      <td>0</td>\n",
       "      <td>438650000</td>\n",
       "      <td>7612.89</td>\n",
       "      <td>57619.37976</td>\n",
       "      <td>113</td>\n",
       "      <td>23201066</td>\n",
       "      <td>240</td>\n",
       "      <td>96671.10833</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120755</td>\n",
       "      <td>0</td>\n",
       "      <td>309216</td>\n",
       "      <td>10489</td>\n",
       "      <td>1328</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6.533145</td>\n",
       "      <td>2.499231</td>\n",
       "      <td>3.019493</td>\n",
       "      <td>1.399270</td>\n",
       "      <td>4.335986</td>\n",
       "      <td>21</td>\n",
       "      <td>320</td>\n",
       "      <td>1362</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1595</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "      <td>613340000</td>\n",
       "      <td>17786.21</td>\n",
       "      <td>34484.01880</td>\n",
       "      <td>199</td>\n",
       "      <td>1687918516</td>\n",
       "      <td>34610</td>\n",
       "      <td>48769.67686</td>\n",
       "      <td>301</td>\n",
       "      <td>407</td>\n",
       "      <td>371</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253330</td>\n",
       "      <td>0</td>\n",
       "      <td>165159</td>\n",
       "      <td>30581</td>\n",
       "      <td>2704</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.265734</td>\n",
       "      <td>0.685633</td>\n",
       "      <td>1.106628</td>\n",
       "      <td>1.833608</td>\n",
       "      <td>2.839831</td>\n",
       "      <td>15</td>\n",
       "      <td>5659</td>\n",
       "      <td>3553</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2466</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>1957</td>\n",
       "      <td>15</td>\n",
       "      <td>488757600</td>\n",
       "      <td>9483.30</td>\n",
       "      <td>51538.76815</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49805</td>\n",
       "      <td>111</td>\n",
       "      <td>98604</td>\n",
       "      <td>293</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.144510</td>\n",
       "      <td>5.921589</td>\n",
       "      <td>2.516764</td>\n",
       "      <td>0.500618</td>\n",
       "      <td>1.940400</td>\n",
       "      <td>56</td>\n",
       "      <td>227</td>\n",
       "      <td>2730</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1255</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>1088280000</td>\n",
       "      <td>37696.24</td>\n",
       "      <td>28869.72282</td>\n",
       "      <td>422</td>\n",
       "      <td>274032611</td>\n",
       "      <td>6796</td>\n",
       "      <td>40322.63258</td>\n",
       "      <td>62</td>\n",
       "      <td>775</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>138730.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46725</td>\n",
       "      <td>0</td>\n",
       "      <td>928198</td>\n",
       "      <td>147575</td>\n",
       "      <td>13354</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.763263</td>\n",
       "      <td>7.477743</td>\n",
       "      <td>8.133736</td>\n",
       "      <td>6.643515</td>\n",
       "      <td>13.817228</td>\n",
       "      <td>8</td>\n",
       "      <td>1156</td>\n",
       "      <td>486</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   area  rentType  houseFloor  totalFloor  houseToward  houseDecoration  \\\n",
       "0    57         2           2          15            4                0   \n",
       "1    42         2           1           7            8                0   \n",
       "2    78         1           2          18            4                3   \n",
       "3    35         2           1           5            4                0   \n",
       "4    36         2           2           4            4                0   \n",
       "\n",
       "   communityName  region  plate  buildYear  saleSecHouseNum  totalTradeMoney  \\\n",
       "0            646       1     53       1994                0        392130000   \n",
       "1           3470      11     11       1986                0        438650000   \n",
       "2           1595       3     42       1994                1        613340000   \n",
       "3           2466       6     28       1957               15        488757600   \n",
       "4           1255       2     44       2003                0       1088280000   \n",
       "\n",
       "   totalTradeArea  tradeMeanPrice  tradeSecNum  totalNewTradeMoney  \\\n",
       "0        12589.57     31147.21154          158            26293744   \n",
       "1         7612.89     57619.37976          113            23201066   \n",
       "2        17786.21     34484.01880          199          1687918516   \n",
       "3         9483.30     51538.76815          169                   0   \n",
       "4        37696.24     28869.72282          422           274032611   \n",
       "\n",
       "   totalNewTradeArea  tradeNewMeanPrice  tradeNewNum  remainNewNum  \\\n",
       "0                751        35011.64314            5           214   \n",
       "1                240        96671.10833            2            59   \n",
       "2              34610        48769.67686          301           407   \n",
       "3                  0            0.00000            0             0   \n",
       "4               6796        40322.63258           62           775   \n",
       "\n",
       "   supplyNewNum  supplyLandNum  supplyLandArea  tradeLandNum  tradeLandArea  \\\n",
       "0             0              0             0.0             0            0.0   \n",
       "1             0              0             0.0             0            0.0   \n",
       "2           371              0             0.0             0            0.0   \n",
       "3             0              0             0.0             0            0.0   \n",
       "4             0              2        138730.8             0            0.0   \n",
       "\n",
       "   landTotalPrice  landMeanPrice  totalWorkers  newWorkers  \\\n",
       "0               0            0.0          8498           0   \n",
       "1               0            0.0        120755           0   \n",
       "2               0            0.0        253330           0   \n",
       "3               0            0.0         49805         111   \n",
       "4               0            0.0         46725           0   \n",
       "\n",
       "   residentPopulation      pv     uv  lookNum  month  day  Room  Hall  Bath  \\\n",
       "0              428071   64170   6665        0      6   18     1     1     1   \n",
       "1              309216   10489   1328        0      3    2     2     0     1   \n",
       "2              165159   30581   2704        0      8    8     2     2     1   \n",
       "3               98604     293     58        0     11   11     1     0     1   \n",
       "4              928198  147575  13354        0      6    8     1     1     1   \n",
       "\n",
       "   Room_Bath  trainsportNum  all_SchoolNum  all_hospitalNum  all_mall  \\\n",
       "0   1.000000       6.861430       2.914163         3.955609  3.118232   \n",
       "1   0.666667       6.533145       2.499231         3.019493  1.399270   \n",
       "2   0.666667       2.265734       0.685633         1.106628  1.833608   \n",
       "3   1.000000       0.144510       5.921589         2.516764  0.500618   \n",
       "4   1.000000       8.763263       7.477743         8.133736  6.643515   \n",
       "\n",
       "    otherNum  count_communityName  count_buildYear  count_totalFloor  \\\n",
       "0   7.035898                   15             5659               809   \n",
       "1   4.335986                   21              320              1362   \n",
       "2   2.839831                   15             5659              3553   \n",
       "3   1.940400                   56              227              2730   \n",
       "4  13.817228                    8             1156               486   \n",
       "\n",
       "   count_communityName_totalFloor  count_communityName_newWorkers  \\\n",
       "0                              14                              10   \n",
       "1                              21                              19   \n",
       "2                              11                              11   \n",
       "3                              48                               5   \n",
       "4                               3                               7   \n",
       "\n",
       "   count_communityName_totalTradeMoney  \n",
       "0                                    1  \n",
       "1                                    4  \n",
       "2                                    1  \n",
       "3                                    5  \n",
       "4                                    1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## groupby方法生成统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-24T13:41:05.546332Z",
     "start_time": "2019-12-24T13:41:04.242821Z"
    }
   },
   "outputs": [],
   "source": [
    "#groupby生成统计特征：mean,std等\n",
    "# 为部分特征新增一些统计特征\n",
    "def gourpby(train,test):\n",
    "    train['data_type'] = 0\n",
    "    test['data_type'] = 1\n",
    "    data = pd.concat([train, test], axis=0, join='outer')\n",
    "    \n",
    "    # 数字编码\n",
    "    columns = ['rentType', 'houseFloor', 'houseToward', 'houseDecoration', 'communityName', 'region', 'plate']\n",
    "    for feature in columns:\n",
    "        data[feature] = LabelEncoder().fit_transform(data[feature])\n",
    "    \n",
    "    # 不同小区房源面积的平均值和标准差\n",
    "    temp = data.groupby('communityName')['area'].agg({'com_area_mean': 'mean', 'com_area_std': 'std'})\n",
    "    # nan填充0\n",
    "    temp.fillna(0, inplace=True)\n",
    "    data = data.merge(temp, on='communityName', how='left')\n",
    "    \n",
    "    # 计算平均面积出租价格\n",
    "    data['price_per_area'] = data.tradeMeanPrice / data.area * 100\n",
    "    \n",
    "    # 小区的面积价格的平均值和标准差\n",
    "    temp = data.groupby('communityName')['price_per_area'].agg(\n",
    "        {'comm_price_mean': 'mean', 'comm_price_std': 'std'})\n",
    "    temp.fillna(0, inplace=True)\n",
    "    data = data.merge(temp, on='communityName', how='left')\n",
    "    \n",
    "    # 区域板块的面积价格的平均值和标准差\n",
    "    temp = data.groupby('plate')['price_per_area'].agg(\n",
    "        {'plate_price_mean': 'mean', 'plate_price_std': 'std'})\n",
    "    temp.fillna(0, inplace=True)\n",
    "    data = data.merge(temp, on='plate', how='left')\n",
    "    data.drop('price_per_area', axis=1, inplace=True)\n",
    "    \n",
    "    # 区域-面积 => 平均值 标准差\n",
    "    temp = data.groupby('plate')['area'].agg({'plate_area_mean': 'mean', 'plate_area_std': 'std'})\n",
    "    temp.fillna(0, inplace=True)\n",
    "    data = data.merge(temp, on='plate', how='left')\n",
    "    \n",
    "    # 区域 建筑年份\n",
    "    temp = data.groupby(['plate'])['buildYear'].agg({'plate_year_mean': 'mean', 'plate_year_std': 'std'})\n",
    "    data = data.merge(temp, on='plate', how='left')\n",
    "    data.plate_year_mean = data.plate_year_mean.astype('int')\n",
    "    data['comm_plate_year_diff'] = data.buildYear - data.plate_year_mean  # 年份 - 平均年份\n",
    "    data.drop('plate_year_mean', axis=1, inplace=True)\n",
    "    \n",
    "    # 区域——交通特征\n",
    "    temp = data.groupby('plate')['trainsportNum'].agg('sum').reset_index(name='plate_trainsportNum')\n",
    "    data = data.merge(temp, on='plate', how='left')\n",
    "    temp = data.groupby(['communityName', 'plate'])['trainsportNum'].agg('sum').reset_index(name='com_trainsportNum')\n",
    "    data = data.merge(temp, on=['communityName', 'plate'], how='left')\n",
    "    data['trainsportNum_ratio'] = list(map(lambda x, y: round(x / y, 3) if y != 0 else -1,\n",
    "                                           data['com_trainsportNum'], data['plate_trainsportNum']))\n",
    "    data = data.drop(['com_trainsportNum', 'plate_trainsportNum'], axis=1)\n",
    "\n",
    "    # 区域 学校数量 总数\n",
    "    temp = data.groupby('plate')['all_SchoolNum'].agg('sum').reset_index(name='plate_all_SchoolNum')\n",
    "    data = data.merge(temp, on='plate', how='left')\n",
    "    temp = data.groupby(['communityName', 'plate'])['all_SchoolNum'].agg('sum').reset_index(name='com_all_SchoolNum')\n",
    "    data = data.merge(temp, on=['communityName', 'plate'], how='left')\n",
    "    data = data.drop(['com_all_SchoolNum', 'plate_all_SchoolNum'], axis=1)\n",
    "    \n",
    "    # 小区-区域 总数\n",
    "    temp = data.groupby(['communityName', 'plate'])['all_mall'].agg('sum').reset_index(name='com_all_mall')\n",
    "    data = data.merge(temp, on=['communityName', 'plate'], how='left')\n",
    "    \n",
    "    # 区域 其他配套特征 总数\n",
    "    temp = data.groupby('plate')['otherNum'].agg('sum').reset_index(name='plate_otherNum')\n",
    "    data = data.merge(temp, on='plate', how='left')\n",
    "    temp = data.groupby(['communityName', 'plate'])['otherNum'].agg('sum').reset_index(name='com_otherNum')\n",
    "    data = data.merge(temp, on=['communityName', 'plate'], how='left')\n",
    "    data['other_ratio'] = list(map(lambda x, y: round(x / y, 3) if y != 0 else -1,\n",
    "                                   data['com_otherNum'], data['plate_otherNum']))\n",
    "    data = data.drop(['com_otherNum', 'plate_otherNum'], axis=1)\n",
    "    \n",
    "    # 月份小区成交\n",
    "    temp = data.groupby(['month', 'communityName']).size().reset_index(name='communityName_saleNum')\n",
    "    data = data.merge(temp, on=['month', 'communityName'], how='left')\n",
    "    temp = data.groupby(['month', 'plate']).size().reset_index(name='plate_saleNum')\n",
    "    data = data.merge(temp, on=['month', 'plate'], how='left')\n",
    "    \n",
    "    # 成交比例\n",
    "    data['sale_ratio'] = round((data.communityName_saleNum + 1) / (data.plate_saleNum + 1), 3)\n",
    "    data['sale_newworker_differ'] = 3 * data.plate_saleNum - data.newWorkers\n",
    "    data.drop(['communityName_saleNum', 'plate_saleNum'], axis=1, inplace=True)\n",
    "\n",
    "    new_train = data[data['data_type'] == 0]\n",
    "    new_test = data[data['data_type'] == 1]\n",
    "    new_train.drop('data_type', axis=1, inplace=True)\n",
    "    new_test.drop(['data_type'], axis=1, inplace=True)\n",
    "    return new_train, new_test\n",
    "\n",
    "train, test = gourpby(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>rentType</th>\n",
       "      <th>houseFloor</th>\n",
       "      <th>totalFloor</th>\n",
       "      <th>houseToward</th>\n",
       "      <th>houseDecoration</th>\n",
       "      <th>communityName</th>\n",
       "      <th>region</th>\n",
       "      <th>plate</th>\n",
       "      <th>buildYear</th>\n",
       "      <th>saleSecHouseNum</th>\n",
       "      <th>totalTradeMoney</th>\n",
       "      <th>totalTradeArea</th>\n",
       "      <th>tradeMeanPrice</th>\n",
       "      <th>tradeSecNum</th>\n",
       "      <th>totalNewTradeMoney</th>\n",
       "      <th>totalNewTradeArea</th>\n",
       "      <th>tradeNewMeanPrice</th>\n",
       "      <th>tradeNewNum</th>\n",
       "      <th>remainNewNum</th>\n",
       "      <th>supplyNewNum</th>\n",
       "      <th>supplyLandNum</th>\n",
       "      <th>supplyLandArea</th>\n",
       "      <th>tradeLandNum</th>\n",
       "      <th>tradeLandArea</th>\n",
       "      <th>landTotalPrice</th>\n",
       "      <th>landMeanPrice</th>\n",
       "      <th>totalWorkers</th>\n",
       "      <th>newWorkers</th>\n",
       "      <th>residentPopulation</th>\n",
       "      <th>pv</th>\n",
       "      <th>uv</th>\n",
       "      <th>lookNum</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>Room</th>\n",
       "      <th>Hall</th>\n",
       "      <th>Bath</th>\n",
       "      <th>Room_Bath</th>\n",
       "      <th>trainsportNum</th>\n",
       "      <th>all_SchoolNum</th>\n",
       "      <th>all_hospitalNum</th>\n",
       "      <th>all_mall</th>\n",
       "      <th>otherNum</th>\n",
       "      <th>count_communityName</th>\n",
       "      <th>count_buildYear</th>\n",
       "      <th>count_totalFloor</th>\n",
       "      <th>count_communityName_totalFloor</th>\n",
       "      <th>count_communityName_newWorkers</th>\n",
       "      <th>count_communityName_totalTradeMoney</th>\n",
       "      <th>com_area_mean</th>\n",
       "      <th>com_area_std</th>\n",
       "      <th>comm_price_mean</th>\n",
       "      <th>comm_price_std</th>\n",
       "      <th>plate_price_mean</th>\n",
       "      <th>plate_price_std</th>\n",
       "      <th>plate_area_mean</th>\n",
       "      <th>plate_area_std</th>\n",
       "      <th>plate_year_std</th>\n",
       "      <th>comm_plate_year_diff</th>\n",
       "      <th>trainsportNum_ratio</th>\n",
       "      <th>com_all_mall</th>\n",
       "      <th>other_ratio</th>\n",
       "      <th>sale_ratio</th>\n",
       "      <th>sale_newworker_differ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>646</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1994</td>\n",
       "      <td>0</td>\n",
       "      <td>392130000</td>\n",
       "      <td>12589.57</td>\n",
       "      <td>31147.21154</td>\n",
       "      <td>158</td>\n",
       "      <td>26293744</td>\n",
       "      <td>751</td>\n",
       "      <td>35011.64314</td>\n",
       "      <td>5</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8498</td>\n",
       "      <td>0</td>\n",
       "      <td>428071</td>\n",
       "      <td>64170</td>\n",
       "      <td>6665</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.861430</td>\n",
       "      <td>2.914163</td>\n",
       "      <td>3.955609</td>\n",
       "      <td>3.118232</td>\n",
       "      <td>7.035898</td>\n",
       "      <td>15</td>\n",
       "      <td>5659</td>\n",
       "      <td>809</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>57.666667</td>\n",
       "      <td>8.005950</td>\n",
       "      <td>56011.618848</td>\n",
       "      <td>11432.901072</td>\n",
       "      <td>95866.315739</td>\n",
       "      <td>103261.303345</td>\n",
       "      <td>67.563758</td>\n",
       "      <td>87.878800</td>\n",
       "      <td>8.720308</td>\n",
       "      <td>-6</td>\n",
       "      <td>0.009</td>\n",
       "      <td>43.655253</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.014</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3470</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1986</td>\n",
       "      <td>0</td>\n",
       "      <td>438650000</td>\n",
       "      <td>7612.89</td>\n",
       "      <td>57619.37976</td>\n",
       "      <td>113</td>\n",
       "      <td>23201066</td>\n",
       "      <td>240</td>\n",
       "      <td>96671.10833</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120755</td>\n",
       "      <td>0</td>\n",
       "      <td>309216</td>\n",
       "      <td>10489</td>\n",
       "      <td>1328</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6.533145</td>\n",
       "      <td>2.499231</td>\n",
       "      <td>3.019493</td>\n",
       "      <td>1.399270</td>\n",
       "      <td>4.335986</td>\n",
       "      <td>21</td>\n",
       "      <td>320</td>\n",
       "      <td>1362</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>39.238095</td>\n",
       "      <td>7.974364</td>\n",
       "      <td>140701.447242</td>\n",
       "      <td>25959.585233</td>\n",
       "      <td>154231.435167</td>\n",
       "      <td>144059.477704</td>\n",
       "      <td>53.939891</td>\n",
       "      <td>33.509477</td>\n",
       "      <td>14.759094</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.047</td>\n",
       "      <td>29.384662</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.045</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1595</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "      <td>613340000</td>\n",
       "      <td>17786.21</td>\n",
       "      <td>34484.01880</td>\n",
       "      <td>199</td>\n",
       "      <td>1687918516</td>\n",
       "      <td>34610</td>\n",
       "      <td>48769.67686</td>\n",
       "      <td>301</td>\n",
       "      <td>407</td>\n",
       "      <td>371</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253330</td>\n",
       "      <td>0</td>\n",
       "      <td>165159</td>\n",
       "      <td>30581</td>\n",
       "      <td>2704</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.265734</td>\n",
       "      <td>0.685633</td>\n",
       "      <td>1.106628</td>\n",
       "      <td>1.833608</td>\n",
       "      <td>2.839831</td>\n",
       "      <td>15</td>\n",
       "      <td>5659</td>\n",
       "      <td>3553</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>72.866667</td>\n",
       "      <td>23.191337</td>\n",
       "      <td>64715.839564</td>\n",
       "      <td>83080.341652</td>\n",
       "      <td>74449.615731</td>\n",
       "      <td>83069.250127</td>\n",
       "      <td>74.935159</td>\n",
       "      <td>42.805242</td>\n",
       "      <td>9.095648</td>\n",
       "      <td>-12</td>\n",
       "      <td>0.016</td>\n",
       "      <td>20.169689</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.031</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2466</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>1957</td>\n",
       "      <td>15</td>\n",
       "      <td>488757600</td>\n",
       "      <td>9483.30</td>\n",
       "      <td>51538.76815</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49805</td>\n",
       "      <td>111</td>\n",
       "      <td>98604</td>\n",
       "      <td>293</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.144510</td>\n",
       "      <td>5.921589</td>\n",
       "      <td>2.516764</td>\n",
       "      <td>0.500618</td>\n",
       "      <td>1.940400</td>\n",
       "      <td>56</td>\n",
       "      <td>227</td>\n",
       "      <td>2730</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>35.839286</td>\n",
       "      <td>18.444784</td>\n",
       "      <td>169607.758678</td>\n",
       "      <td>78663.619452</td>\n",
       "      <td>142872.849542</td>\n",
       "      <td>97885.206437</td>\n",
       "      <td>46.166352</td>\n",
       "      <td>24.522229</td>\n",
       "      <td>14.789971</td>\n",
       "      <td>-20</td>\n",
       "      <td>0.028</td>\n",
       "      <td>27.533977</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.154</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1255</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>1088280000</td>\n",
       "      <td>37696.24</td>\n",
       "      <td>28869.72282</td>\n",
       "      <td>422</td>\n",
       "      <td>274032611</td>\n",
       "      <td>6796</td>\n",
       "      <td>40322.63258</td>\n",
       "      <td>62</td>\n",
       "      <td>775</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>138730.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46725</td>\n",
       "      <td>0</td>\n",
       "      <td>928198</td>\n",
       "      <td>147575</td>\n",
       "      <td>13354</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.763263</td>\n",
       "      <td>7.477743</td>\n",
       "      <td>8.133736</td>\n",
       "      <td>6.643515</td>\n",
       "      <td>13.817228</td>\n",
       "      <td>8</td>\n",
       "      <td>1156</td>\n",
       "      <td>486</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>56.250000</td>\n",
       "      <td>50.609852</td>\n",
       "      <td>104614.815020</td>\n",
       "      <td>88372.684692</td>\n",
       "      <td>77186.781252</td>\n",
       "      <td>117756.951718</td>\n",
       "      <td>77.491443</td>\n",
       "      <td>52.280512</td>\n",
       "      <td>7.267132</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.005</td>\n",
       "      <td>46.504606</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.013</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   area  rentType  houseFloor  totalFloor  houseToward  houseDecoration  \\\n",
       "0    57         2           2          15            4                0   \n",
       "1    42         2           1           7            8                0   \n",
       "2    78         1           2          18            4                3   \n",
       "3    35         2           1           5            4                0   \n",
       "4    36         2           2           4            4                0   \n",
       "\n",
       "   communityName  region  plate  buildYear  saleSecHouseNum  totalTradeMoney  \\\n",
       "0            646       1     53       1994                0        392130000   \n",
       "1           3470      11     11       1986                0        438650000   \n",
       "2           1595       3     42       1994                1        613340000   \n",
       "3           2466       6     28       1957               15        488757600   \n",
       "4           1255       2     44       2003                0       1088280000   \n",
       "\n",
       "   totalTradeArea  tradeMeanPrice  tradeSecNum  totalNewTradeMoney  \\\n",
       "0        12589.57     31147.21154          158            26293744   \n",
       "1         7612.89     57619.37976          113            23201066   \n",
       "2        17786.21     34484.01880          199          1687918516   \n",
       "3         9483.30     51538.76815          169                   0   \n",
       "4        37696.24     28869.72282          422           274032611   \n",
       "\n",
       "   totalNewTradeArea  tradeNewMeanPrice  tradeNewNum  remainNewNum  \\\n",
       "0                751        35011.64314            5           214   \n",
       "1                240        96671.10833            2            59   \n",
       "2              34610        48769.67686          301           407   \n",
       "3                  0            0.00000            0             0   \n",
       "4               6796        40322.63258           62           775   \n",
       "\n",
       "   supplyNewNum  supplyLandNum  supplyLandArea  tradeLandNum  tradeLandArea  \\\n",
       "0             0              0             0.0             0            0.0   \n",
       "1             0              0             0.0             0            0.0   \n",
       "2           371              0             0.0             0            0.0   \n",
       "3             0              0             0.0             0            0.0   \n",
       "4             0              2        138730.8             0            0.0   \n",
       "\n",
       "   landTotalPrice  landMeanPrice  totalWorkers  newWorkers  \\\n",
       "0               0            0.0          8498           0   \n",
       "1               0            0.0        120755           0   \n",
       "2               0            0.0        253330           0   \n",
       "3               0            0.0         49805         111   \n",
       "4               0            0.0         46725           0   \n",
       "\n",
       "   residentPopulation      pv     uv  lookNum  month  day  Room  Hall  Bath  \\\n",
       "0              428071   64170   6665        0      6   18     1     1     1   \n",
       "1              309216   10489   1328        0      3    2     2     0     1   \n",
       "2              165159   30581   2704        0      8    8     2     2     1   \n",
       "3               98604     293     58        0     11   11     1     0     1   \n",
       "4              928198  147575  13354        0      6    8     1     1     1   \n",
       "\n",
       "   Room_Bath  trainsportNum  all_SchoolNum  all_hospitalNum  all_mall  \\\n",
       "0   1.000000       6.861430       2.914163         3.955609  3.118232   \n",
       "1   0.666667       6.533145       2.499231         3.019493  1.399270   \n",
       "2   0.666667       2.265734       0.685633         1.106628  1.833608   \n",
       "3   1.000000       0.144510       5.921589         2.516764  0.500618   \n",
       "4   1.000000       8.763263       7.477743         8.133736  6.643515   \n",
       "\n",
       "    otherNum  count_communityName  count_buildYear  count_totalFloor  \\\n",
       "0   7.035898                   15             5659               809   \n",
       "1   4.335986                   21              320              1362   \n",
       "2   2.839831                   15             5659              3553   \n",
       "3   1.940400                   56              227              2730   \n",
       "4  13.817228                    8             1156               486   \n",
       "\n",
       "   count_communityName_totalFloor  count_communityName_newWorkers  \\\n",
       "0                              14                              10   \n",
       "1                              21                              19   \n",
       "2                              11                              11   \n",
       "3                              48                               5   \n",
       "4                               3                               7   \n",
       "\n",
       "   count_communityName_totalTradeMoney  com_area_mean  com_area_std  \\\n",
       "0                                    1      57.666667      8.005950   \n",
       "1                                    4      39.238095      7.974364   \n",
       "2                                    1      72.866667     23.191337   \n",
       "3                                    5      35.839286     18.444784   \n",
       "4                                    1      56.250000     50.609852   \n",
       "\n",
       "   comm_price_mean  comm_price_std  plate_price_mean  plate_price_std  \\\n",
       "0     56011.618848    11432.901072      95866.315739    103261.303345   \n",
       "1    140701.447242    25959.585233     154231.435167    144059.477704   \n",
       "2     64715.839564    83080.341652      74449.615731     83069.250127   \n",
       "3    169607.758678    78663.619452     142872.849542     97885.206437   \n",
       "4    104614.815020    88372.684692      77186.781252    117756.951718   \n",
       "\n",
       "   plate_area_mean  plate_area_std  plate_year_std  comm_plate_year_diff  \\\n",
       "0        67.563758       87.878800        8.720308                    -6   \n",
       "1        53.939891       33.509477       14.759094                    -3   \n",
       "2        74.935159       42.805242        9.095648                   -12   \n",
       "3        46.166352       24.522229       14.789971                   -20   \n",
       "4        77.491443       52.280512        7.267132                    -1   \n",
       "\n",
       "   trainsportNum_ratio  com_all_mall  other_ratio  sale_ratio  \\\n",
       "0                0.009     43.655253        0.012       0.014   \n",
       "1                0.047     29.384662        0.038       0.045   \n",
       "2                0.016     20.169689        0.016       0.031   \n",
       "3                0.028     27.533977        0.102       0.154   \n",
       "4                0.005     46.504606        0.005       0.013   \n",
       "\n",
       "   sale_newworker_differ  \n",
       "0                    429  \n",
       "1                    333  \n",
       "2                    189  \n",
       "3                      3  \n",
       "4                    474  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-24T13:38:33.198959Z",
     "start_time": "2019-12-24T13:38:33.193970Z"
    }
   },
   "source": [
    "## 聚类方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-24T13:41:25.894916Z",
     "start_time": "2019-12-24T13:41:25.241666Z"
    }
   },
   "outputs": [],
   "source": [
    "#聚类\n",
    "# 新增聚类算法计算的数据列\n",
    "def cluster(train,test):\n",
    "    from sklearn.mixture import GaussianMixture\n",
    "\n",
    "    train['data_type'] = 0\n",
    "    test['data_type'] = 1\n",
    "    data = pd.concat([train, test], axis=0, join='outer')\n",
    "    col = ['totalFloor',\n",
    "           'houseDecoration', 'communityName', 'region', 'plate', 'buildYear',\n",
    "\n",
    "           'tradeMeanPrice', 'tradeSecNum', 'totalNewTradeMoney',\n",
    "           'totalNewTradeArea', 'tradeNewMeanPrice', 'tradeNewNum', 'remainNewNum',\n",
    "\n",
    "           'landTotalPrice', 'landMeanPrice', 'totalWorkers',\n",
    "           'newWorkers', 'residentPopulation', 'lookNum',\n",
    "           'trainsportNum',\n",
    "           'all_SchoolNum', 'all_hospitalNum', 'all_mall', 'otherNum']\n",
    "\n",
    "    # EM\n",
    "    gmm = GaussianMixture(n_components=3, covariance_type='full', random_state=0)\n",
    "    data['cluster']= pd.DataFrame(gmm.fit_predict(data[col]))\n",
    "\n",
    "\n",
    "    col1 = ['totalFloor','houseDecoration', 'communityName', 'region', 'plate', 'buildYear']\n",
    "    col2 = ['tradeMeanPrice', 'tradeSecNum', 'totalNewTradeMoney',\n",
    "            'totalNewTradeArea', 'tradeNewMeanPrice', 'tradeNewNum', 'remainNewNum',\n",
    "            'landTotalPrice', 'landMeanPrice', 'totalWorkers',\n",
    "            'newWorkers', 'residentPopulation', 'lookNum',\n",
    "            'trainsportNum',\n",
    "            'all_SchoolNum', 'all_hospitalNum', 'all_mall', 'otherNum']\n",
    "    for feature1 in col1:\n",
    "        for feature2 in col2:\n",
    "        \n",
    "            temp = data.groupby(['cluster',feature1])[feature2].agg('mean').reset_index(name=feature2+'_'+feature1+'_cluster_mean')\n",
    "            temp.fillna(0, inplace=True)\n",
    "       \n",
    "            data = data.merge(temp, on=['cluster', feature1], how='left')\n",
    "    \n",
    "   \n",
    "    new_train = data[data['data_type'] == 0]\n",
    "    new_test = data[data['data_type'] == 1]\n",
    "    new_train.drop('data_type', axis=1, inplace=True)\n",
    "    new_test.drop(['data_type'], axis=1, inplace=True)\n",
    "    \n",
    "    return new_train, new_test\n",
    "\n",
    "train, test = cluster(train, test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>rentType</th>\n",
       "      <th>houseFloor</th>\n",
       "      <th>totalFloor</th>\n",
       "      <th>houseToward</th>\n",
       "      <th>houseDecoration</th>\n",
       "      <th>communityName</th>\n",
       "      <th>region</th>\n",
       "      <th>plate</th>\n",
       "      <th>buildYear</th>\n",
       "      <th>saleSecHouseNum</th>\n",
       "      <th>totalTradeMoney</th>\n",
       "      <th>totalTradeArea</th>\n",
       "      <th>tradeMeanPrice</th>\n",
       "      <th>tradeSecNum</th>\n",
       "      <th>totalNewTradeMoney</th>\n",
       "      <th>totalNewTradeArea</th>\n",
       "      <th>tradeNewMeanPrice</th>\n",
       "      <th>tradeNewNum</th>\n",
       "      <th>remainNewNum</th>\n",
       "      <th>supplyNewNum</th>\n",
       "      <th>supplyLandNum</th>\n",
       "      <th>supplyLandArea</th>\n",
       "      <th>tradeLandNum</th>\n",
       "      <th>tradeLandArea</th>\n",
       "      <th>landTotalPrice</th>\n",
       "      <th>landMeanPrice</th>\n",
       "      <th>totalWorkers</th>\n",
       "      <th>newWorkers</th>\n",
       "      <th>residentPopulation</th>\n",
       "      <th>pv</th>\n",
       "      <th>uv</th>\n",
       "      <th>lookNum</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>Room</th>\n",
       "      <th>Hall</th>\n",
       "      <th>Bath</th>\n",
       "      <th>Room_Bath</th>\n",
       "      <th>trainsportNum</th>\n",
       "      <th>all_SchoolNum</th>\n",
       "      <th>all_hospitalNum</th>\n",
       "      <th>all_mall</th>\n",
       "      <th>otherNum</th>\n",
       "      <th>count_communityName</th>\n",
       "      <th>count_buildYear</th>\n",
       "      <th>count_totalFloor</th>\n",
       "      <th>count_communityName_totalFloor</th>\n",
       "      <th>count_communityName_newWorkers</th>\n",
       "      <th>count_communityName_totalTradeMoney</th>\n",
       "      <th>com_area_mean</th>\n",
       "      <th>com_area_std</th>\n",
       "      <th>comm_price_mean</th>\n",
       "      <th>comm_price_std</th>\n",
       "      <th>plate_price_mean</th>\n",
       "      <th>plate_price_std</th>\n",
       "      <th>plate_area_mean</th>\n",
       "      <th>plate_area_std</th>\n",
       "      <th>plate_year_std</th>\n",
       "      <th>comm_plate_year_diff</th>\n",
       "      <th>trainsportNum_ratio</th>\n",
       "      <th>com_all_mall</th>\n",
       "      <th>other_ratio</th>\n",
       "      <th>sale_ratio</th>\n",
       "      <th>sale_newworker_differ</th>\n",
       "      <th>cluster</th>\n",
       "      <th>tradeMeanPrice_totalFloor_cluster_mean</th>\n",
       "      <th>tradeSecNum_totalFloor_cluster_mean</th>\n",
       "      <th>totalNewTradeMoney_totalFloor_cluster_mean</th>\n",
       "      <th>totalNewTradeArea_totalFloor_cluster_mean</th>\n",
       "      <th>tradeNewMeanPrice_totalFloor_cluster_mean</th>\n",
       "      <th>tradeNewNum_totalFloor_cluster_mean</th>\n",
       "      <th>remainNewNum_totalFloor_cluster_mean</th>\n",
       "      <th>landTotalPrice_totalFloor_cluster_mean</th>\n",
       "      <th>landMeanPrice_totalFloor_cluster_mean</th>\n",
       "      <th>totalWorkers_totalFloor_cluster_mean</th>\n",
       "      <th>newWorkers_totalFloor_cluster_mean</th>\n",
       "      <th>residentPopulation_totalFloor_cluster_mean</th>\n",
       "      <th>lookNum_totalFloor_cluster_mean</th>\n",
       "      <th>trainsportNum_totalFloor_cluster_mean</th>\n",
       "      <th>all_SchoolNum_totalFloor_cluster_mean</th>\n",
       "      <th>all_hospitalNum_totalFloor_cluster_mean</th>\n",
       "      <th>all_mall_totalFloor_cluster_mean</th>\n",
       "      <th>otherNum_totalFloor_cluster_mean</th>\n",
       "      <th>tradeMeanPrice_houseDecoration_cluster_mean</th>\n",
       "      <th>tradeSecNum_houseDecoration_cluster_mean</th>\n",
       "      <th>totalNewTradeMoney_houseDecoration_cluster_mean</th>\n",
       "      <th>totalNewTradeArea_houseDecoration_cluster_mean</th>\n",
       "      <th>tradeNewMeanPrice_houseDecoration_cluster_mean</th>\n",
       "      <th>tradeNewNum_houseDecoration_cluster_mean</th>\n",
       "      <th>remainNewNum_houseDecoration_cluster_mean</th>\n",
       "      <th>landTotalPrice_houseDecoration_cluster_mean</th>\n",
       "      <th>landMeanPrice_houseDecoration_cluster_mean</th>\n",
       "      <th>totalWorkers_houseDecoration_cluster_mean</th>\n",
       "      <th>newWorkers_houseDecoration_cluster_mean</th>\n",
       "      <th>residentPopulation_houseDecoration_cluster_mean</th>\n",
       "      <th>lookNum_houseDecoration_cluster_mean</th>\n",
       "      <th>trainsportNum_houseDecoration_cluster_mean</th>\n",
       "      <th>all_SchoolNum_houseDecoration_cluster_mean</th>\n",
       "      <th>all_hospitalNum_houseDecoration_cluster_mean</th>\n",
       "      <th>all_mall_houseDecoration_cluster_mean</th>\n",
       "      <th>otherNum_houseDecoration_cluster_mean</th>\n",
       "      <th>tradeMeanPrice_communityName_cluster_mean</th>\n",
       "      <th>tradeSecNum_communityName_cluster_mean</th>\n",
       "      <th>totalNewTradeMoney_communityName_cluster_mean</th>\n",
       "      <th>totalNewTradeArea_communityName_cluster_mean</th>\n",
       "      <th>tradeNewMeanPrice_communityName_cluster_mean</th>\n",
       "      <th>tradeNewNum_communityName_cluster_mean</th>\n",
       "      <th>remainNewNum_communityName_cluster_mean</th>\n",
       "      <th>landTotalPrice_communityName_cluster_mean</th>\n",
       "      <th>landMeanPrice_communityName_cluster_mean</th>\n",
       "      <th>totalWorkers_communityName_cluster_mean</th>\n",
       "      <th>newWorkers_communityName_cluster_mean</th>\n",
       "      <th>residentPopulation_communityName_cluster_mean</th>\n",
       "      <th>lookNum_communityName_cluster_mean</th>\n",
       "      <th>trainsportNum_communityName_cluster_mean</th>\n",
       "      <th>all_SchoolNum_communityName_cluster_mean</th>\n",
       "      <th>all_hospitalNum_communityName_cluster_mean</th>\n",
       "      <th>all_mall_communityName_cluster_mean</th>\n",
       "      <th>otherNum_communityName_cluster_mean</th>\n",
       "      <th>tradeMeanPrice_region_cluster_mean</th>\n",
       "      <th>tradeSecNum_region_cluster_mean</th>\n",
       "      <th>totalNewTradeMoney_region_cluster_mean</th>\n",
       "      <th>totalNewTradeArea_region_cluster_mean</th>\n",
       "      <th>tradeNewMeanPrice_region_cluster_mean</th>\n",
       "      <th>tradeNewNum_region_cluster_mean</th>\n",
       "      <th>remainNewNum_region_cluster_mean</th>\n",
       "      <th>landTotalPrice_region_cluster_mean</th>\n",
       "      <th>landMeanPrice_region_cluster_mean</th>\n",
       "      <th>totalWorkers_region_cluster_mean</th>\n",
       "      <th>newWorkers_region_cluster_mean</th>\n",
       "      <th>residentPopulation_region_cluster_mean</th>\n",
       "      <th>lookNum_region_cluster_mean</th>\n",
       "      <th>trainsportNum_region_cluster_mean</th>\n",
       "      <th>all_SchoolNum_region_cluster_mean</th>\n",
       "      <th>all_hospitalNum_region_cluster_mean</th>\n",
       "      <th>all_mall_region_cluster_mean</th>\n",
       "      <th>otherNum_region_cluster_mean</th>\n",
       "      <th>tradeMeanPrice_plate_cluster_mean</th>\n",
       "      <th>tradeSecNum_plate_cluster_mean</th>\n",
       "      <th>totalNewTradeMoney_plate_cluster_mean</th>\n",
       "      <th>totalNewTradeArea_plate_cluster_mean</th>\n",
       "      <th>tradeNewMeanPrice_plate_cluster_mean</th>\n",
       "      <th>tradeNewNum_plate_cluster_mean</th>\n",
       "      <th>remainNewNum_plate_cluster_mean</th>\n",
       "      <th>landTotalPrice_plate_cluster_mean</th>\n",
       "      <th>landMeanPrice_plate_cluster_mean</th>\n",
       "      <th>totalWorkers_plate_cluster_mean</th>\n",
       "      <th>newWorkers_plate_cluster_mean</th>\n",
       "      <th>residentPopulation_plate_cluster_mean</th>\n",
       "      <th>lookNum_plate_cluster_mean</th>\n",
       "      <th>trainsportNum_plate_cluster_mean</th>\n",
       "      <th>all_SchoolNum_plate_cluster_mean</th>\n",
       "      <th>all_hospitalNum_plate_cluster_mean</th>\n",
       "      <th>all_mall_plate_cluster_mean</th>\n",
       "      <th>otherNum_plate_cluster_mean</th>\n",
       "      <th>tradeMeanPrice_buildYear_cluster_mean</th>\n",
       "      <th>tradeSecNum_buildYear_cluster_mean</th>\n",
       "      <th>totalNewTradeMoney_buildYear_cluster_mean</th>\n",
       "      <th>totalNewTradeArea_buildYear_cluster_mean</th>\n",
       "      <th>tradeNewMeanPrice_buildYear_cluster_mean</th>\n",
       "      <th>tradeNewNum_buildYear_cluster_mean</th>\n",
       "      <th>remainNewNum_buildYear_cluster_mean</th>\n",
       "      <th>landTotalPrice_buildYear_cluster_mean</th>\n",
       "      <th>landMeanPrice_buildYear_cluster_mean</th>\n",
       "      <th>totalWorkers_buildYear_cluster_mean</th>\n",
       "      <th>newWorkers_buildYear_cluster_mean</th>\n",
       "      <th>residentPopulation_buildYear_cluster_mean</th>\n",
       "      <th>lookNum_buildYear_cluster_mean</th>\n",
       "      <th>trainsportNum_buildYear_cluster_mean</th>\n",
       "      <th>all_SchoolNum_buildYear_cluster_mean</th>\n",
       "      <th>all_hospitalNum_buildYear_cluster_mean</th>\n",
       "      <th>all_mall_buildYear_cluster_mean</th>\n",
       "      <th>otherNum_buildYear_cluster_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>646</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1994</td>\n",
       "      <td>0</td>\n",
       "      <td>392130000</td>\n",
       "      <td>12589.57</td>\n",
       "      <td>31147.21154</td>\n",
       "      <td>158</td>\n",
       "      <td>26293744</td>\n",
       "      <td>751</td>\n",
       "      <td>35011.64314</td>\n",
       "      <td>5</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8498</td>\n",
       "      <td>0</td>\n",
       "      <td>428071</td>\n",
       "      <td>64170</td>\n",
       "      <td>6665</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.861430</td>\n",
       "      <td>2.914163</td>\n",
       "      <td>3.955609</td>\n",
       "      <td>3.118232</td>\n",
       "      <td>7.035898</td>\n",
       "      <td>15</td>\n",
       "      <td>5659</td>\n",
       "      <td>809</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>57.666667</td>\n",
       "      <td>8.005950</td>\n",
       "      <td>56011.618848</td>\n",
       "      <td>11432.901072</td>\n",
       "      <td>95866.315739</td>\n",
       "      <td>103261.303345</td>\n",
       "      <td>67.563758</td>\n",
       "      <td>87.878800</td>\n",
       "      <td>8.720308</td>\n",
       "      <td>-6</td>\n",
       "      <td>0.009</td>\n",
       "      <td>43.655253</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.014</td>\n",
       "      <td>429</td>\n",
       "      <td>0</td>\n",
       "      <td>37234.390317</td>\n",
       "      <td>232.448845</td>\n",
       "      <td>2.134405e+08</td>\n",
       "      <td>4719.924092</td>\n",
       "      <td>38813.883094</td>\n",
       "      <td>41.143564</td>\n",
       "      <td>305.674917</td>\n",
       "      <td>3.745285e+07</td>\n",
       "      <td>265.775476</td>\n",
       "      <td>77849.013201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>330429.646865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.420387</td>\n",
       "      <td>3.315204</td>\n",
       "      <td>3.106066</td>\n",
       "      <td>2.327820</td>\n",
       "      <td>5.084342</td>\n",
       "      <td>40725.102969</td>\n",
       "      <td>229.518102</td>\n",
       "      <td>1.940921e+08</td>\n",
       "      <td>3806.600763</td>\n",
       "      <td>44245.116035</td>\n",
       "      <td>31.333564</td>\n",
       "      <td>271.877668</td>\n",
       "      <td>2.935649e+07</td>\n",
       "      <td>277.134168</td>\n",
       "      <td>78607.926551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>287437.223218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.608225</td>\n",
       "      <td>4.222785</td>\n",
       "      <td>2.883093</td>\n",
       "      <td>1.945022</td>\n",
       "      <td>4.747559</td>\n",
       "      <td>31079.504539</td>\n",
       "      <td>173.800000</td>\n",
       "      <td>3.818973e+07</td>\n",
       "      <td>1001.900000</td>\n",
       "      <td>35419.551532</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>217.400000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8498.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>428071.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.861430</td>\n",
       "      <td>2.914163</td>\n",
       "      <td>3.955609</td>\n",
       "      <td>3.118232</td>\n",
       "      <td>7.035898</td>\n",
       "      <td>41476.021283</td>\n",
       "      <td>321.679504</td>\n",
       "      <td>1.724097e+08</td>\n",
       "      <td>2949.490126</td>\n",
       "      <td>62580.585009</td>\n",
       "      <td>22.496382</td>\n",
       "      <td>216.609837</td>\n",
       "      <td>2.676943e+07</td>\n",
       "      <td>122.363175</td>\n",
       "      <td>151335.517601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>344045.843493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.273148</td>\n",
       "      <td>4.502851</td>\n",
       "      <td>3.550913</td>\n",
       "      <td>2.196679</td>\n",
       "      <td>6.243596</td>\n",
       "      <td>34773.122085</td>\n",
       "      <td>193.143013</td>\n",
       "      <td>1.158908e+08</td>\n",
       "      <td>2217.561135</td>\n",
       "      <td>44129.109313</td>\n",
       "      <td>14.838428</td>\n",
       "      <td>280.707424</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7763.432314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>406501.259825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.489401</td>\n",
       "      <td>2.629209</td>\n",
       "      <td>3.956709</td>\n",
       "      <td>2.870786</td>\n",
       "      <td>6.609019</td>\n",
       "      <td>38386.178484</td>\n",
       "      <td>215.547458</td>\n",
       "      <td>2.051141e+08</td>\n",
       "      <td>4220.866016</td>\n",
       "      <td>43980.696790</td>\n",
       "      <td>33.438267</td>\n",
       "      <td>314.098923</td>\n",
       "      <td>3.084462e+07</td>\n",
       "      <td>317.416683</td>\n",
       "      <td>57279.348109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>280336.653143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.524240</td>\n",
       "      <td>4.023809</td>\n",
       "      <td>2.670093</td>\n",
       "      <td>1.931252</td>\n",
       "      <td>4.448482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3470</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1986</td>\n",
       "      <td>0</td>\n",
       "      <td>438650000</td>\n",
       "      <td>7612.89</td>\n",
       "      <td>57619.37976</td>\n",
       "      <td>113</td>\n",
       "      <td>23201066</td>\n",
       "      <td>240</td>\n",
       "      <td>96671.10833</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120755</td>\n",
       "      <td>0</td>\n",
       "      <td>309216</td>\n",
       "      <td>10489</td>\n",
       "      <td>1328</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6.533145</td>\n",
       "      <td>2.499231</td>\n",
       "      <td>3.019493</td>\n",
       "      <td>1.399270</td>\n",
       "      <td>4.335986</td>\n",
       "      <td>21</td>\n",
       "      <td>320</td>\n",
       "      <td>1362</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>39.238095</td>\n",
       "      <td>7.974364</td>\n",
       "      <td>140701.447242</td>\n",
       "      <td>25959.585233</td>\n",
       "      <td>154231.435167</td>\n",
       "      <td>144059.477704</td>\n",
       "      <td>53.939891</td>\n",
       "      <td>33.509477</td>\n",
       "      <td>14.759094</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.047</td>\n",
       "      <td>29.384662</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.045</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>44629.869276</td>\n",
       "      <td>182.434742</td>\n",
       "      <td>1.662570e+08</td>\n",
       "      <td>2510.731455</td>\n",
       "      <td>48701.681393</td>\n",
       "      <td>18.217840</td>\n",
       "      <td>187.546479</td>\n",
       "      <td>2.283223e+07</td>\n",
       "      <td>254.032348</td>\n",
       "      <td>91834.026291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>242360.642254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.068509</td>\n",
       "      <td>3.548384</td>\n",
       "      <td>2.467506</td>\n",
       "      <td>1.587749</td>\n",
       "      <td>4.071131</td>\n",
       "      <td>40725.102969</td>\n",
       "      <td>229.518102</td>\n",
       "      <td>1.940921e+08</td>\n",
       "      <td>3806.600763</td>\n",
       "      <td>44245.116035</td>\n",
       "      <td>31.333564</td>\n",
       "      <td>271.877668</td>\n",
       "      <td>2.935649e+07</td>\n",
       "      <td>277.134168</td>\n",
       "      <td>78607.926551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>287437.223218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.608225</td>\n",
       "      <td>4.222785</td>\n",
       "      <td>2.883093</td>\n",
       "      <td>1.945022</td>\n",
       "      <td>4.747559</td>\n",
       "      <td>53739.820320</td>\n",
       "      <td>104.266667</td>\n",
       "      <td>4.626383e+08</td>\n",
       "      <td>4801.333333</td>\n",
       "      <td>96091.755367</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>186.733333</td>\n",
       "      <td>2.903000e+07</td>\n",
       "      <td>1442.057649</td>\n",
       "      <td>120755.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>309216.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.533145</td>\n",
       "      <td>2.499231</td>\n",
       "      <td>3.019493</td>\n",
       "      <td>1.399270</td>\n",
       "      <td>4.335986</td>\n",
       "      <td>50724.464178</td>\n",
       "      <td>164.072800</td>\n",
       "      <td>4.091667e+07</td>\n",
       "      <td>429.828685</td>\n",
       "      <td>17624.818421</td>\n",
       "      <td>2.335024</td>\n",
       "      <td>83.196306</td>\n",
       "      <td>3.416624e+06</td>\n",
       "      <td>220.008656</td>\n",
       "      <td>64477.336472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>214085.011590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.889478</td>\n",
       "      <td>3.714923</td>\n",
       "      <td>2.643469</td>\n",
       "      <td>0.963086</td>\n",
       "      <td>3.326727</td>\n",
       "      <td>52402.701262</td>\n",
       "      <td>160.326484</td>\n",
       "      <td>1.653230e+08</td>\n",
       "      <td>1722.625571</td>\n",
       "      <td>49717.365511</td>\n",
       "      <td>9.246575</td>\n",
       "      <td>82.751142</td>\n",
       "      <td>8.272968e+06</td>\n",
       "      <td>461.296022</td>\n",
       "      <td>81309.940639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>305442.808219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.207264</td>\n",
       "      <td>3.946431</td>\n",
       "      <td>3.647401</td>\n",
       "      <td>1.115555</td>\n",
       "      <td>4.408551</td>\n",
       "      <td>50108.594319</td>\n",
       "      <td>239.519231</td>\n",
       "      <td>1.181157e+08</td>\n",
       "      <td>1290.584615</td>\n",
       "      <td>43857.451243</td>\n",
       "      <td>7.357692</td>\n",
       "      <td>122.219231</td>\n",
       "      <td>7.717346e+06</td>\n",
       "      <td>333.219172</td>\n",
       "      <td>200760.196154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>216132.688462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.536364</td>\n",
       "      <td>4.198835</td>\n",
       "      <td>2.566916</td>\n",
       "      <td>1.579720</td>\n",
       "      <td>4.872755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1595</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "      <td>613340000</td>\n",
       "      <td>17786.21</td>\n",
       "      <td>34484.01880</td>\n",
       "      <td>199</td>\n",
       "      <td>1687918516</td>\n",
       "      <td>34610</td>\n",
       "      <td>48769.67686</td>\n",
       "      <td>301</td>\n",
       "      <td>407</td>\n",
       "      <td>371</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253330</td>\n",
       "      <td>0</td>\n",
       "      <td>165159</td>\n",
       "      <td>30581</td>\n",
       "      <td>2704</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.265734</td>\n",
       "      <td>0.685633</td>\n",
       "      <td>1.106628</td>\n",
       "      <td>1.833608</td>\n",
       "      <td>2.839831</td>\n",
       "      <td>15</td>\n",
       "      <td>5659</td>\n",
       "      <td>3553</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>72.866667</td>\n",
       "      <td>23.191337</td>\n",
       "      <td>64715.839564</td>\n",
       "      <td>83080.341652</td>\n",
       "      <td>74449.615731</td>\n",
       "      <td>83069.250127</td>\n",
       "      <td>74.935159</td>\n",
       "      <td>42.805242</td>\n",
       "      <td>9.095648</td>\n",
       "      <td>-12</td>\n",
       "      <td>0.016</td>\n",
       "      <td>20.169689</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.031</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>35171.928027</td>\n",
       "      <td>245.471233</td>\n",
       "      <td>2.657397e+08</td>\n",
       "      <td>5741.705284</td>\n",
       "      <td>44279.017722</td>\n",
       "      <td>49.390998</td>\n",
       "      <td>414.180039</td>\n",
       "      <td>4.973183e+07</td>\n",
       "      <td>486.120865</td>\n",
       "      <td>61481.230137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>323437.272407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.659887</td>\n",
       "      <td>3.490074</td>\n",
       "      <td>3.150568</td>\n",
       "      <td>2.272588</td>\n",
       "      <td>5.257058</td>\n",
       "      <td>41286.309465</td>\n",
       "      <td>218.818389</td>\n",
       "      <td>1.770842e+08</td>\n",
       "      <td>3310.516500</td>\n",
       "      <td>47866.995252</td>\n",
       "      <td>26.746852</td>\n",
       "      <td>249.648285</td>\n",
       "      <td>4.677131e+07</td>\n",
       "      <td>383.161679</td>\n",
       "      <td>85574.482306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>282260.154472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.634353</td>\n",
       "      <td>3.769083</td>\n",
       "      <td>2.692437</td>\n",
       "      <td>1.911154</td>\n",
       "      <td>4.726214</td>\n",
       "      <td>32511.713706</td>\n",
       "      <td>171.636364</td>\n",
       "      <td>4.766587e+08</td>\n",
       "      <td>10247.000000</td>\n",
       "      <td>45747.191029</td>\n",
       "      <td>94.727273</td>\n",
       "      <td>399.727273</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>210433.818182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>193286.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.096501</td>\n",
       "      <td>1.892693</td>\n",
       "      <td>1.115730</td>\n",
       "      <td>1.836681</td>\n",
       "      <td>3.127984</td>\n",
       "      <td>31226.586754</td>\n",
       "      <td>218.058221</td>\n",
       "      <td>2.900306e+08</td>\n",
       "      <td>6140.786308</td>\n",
       "      <td>30628.396982</td>\n",
       "      <td>57.154191</td>\n",
       "      <td>259.392194</td>\n",
       "      <td>1.657321e+07</td>\n",
       "      <td>278.448139</td>\n",
       "      <td>156349.654511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>208959.486244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.592588</td>\n",
       "      <td>0.721673</td>\n",
       "      <td>2.576660</td>\n",
       "      <td>2.143895</td>\n",
       "      <td>4.067558</td>\n",
       "      <td>32640.334288</td>\n",
       "      <td>182.613757</td>\n",
       "      <td>4.813406e+08</td>\n",
       "      <td>10349.536155</td>\n",
       "      <td>45433.926056</td>\n",
       "      <td>94.650794</td>\n",
       "      <td>461.689594</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>240414.003527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>163120.816578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.188203</td>\n",
       "      <td>0.666448</td>\n",
       "      <td>1.068570</td>\n",
       "      <td>1.776886</td>\n",
       "      <td>2.793112</td>\n",
       "      <td>38386.178484</td>\n",
       "      <td>215.547458</td>\n",
       "      <td>2.051141e+08</td>\n",
       "      <td>4220.866016</td>\n",
       "      <td>43980.696790</td>\n",
       "      <td>33.438267</td>\n",
       "      <td>314.098923</td>\n",
       "      <td>3.084462e+07</td>\n",
       "      <td>317.416683</td>\n",
       "      <td>57279.348109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>280336.653143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.524240</td>\n",
       "      <td>4.023809</td>\n",
       "      <td>2.670093</td>\n",
       "      <td>1.931252</td>\n",
       "      <td>4.448482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2466</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>1957</td>\n",
       "      <td>15</td>\n",
       "      <td>488757600</td>\n",
       "      <td>9483.30</td>\n",
       "      <td>51538.76815</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49805</td>\n",
       "      <td>111</td>\n",
       "      <td>98604</td>\n",
       "      <td>293</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.144510</td>\n",
       "      <td>5.921589</td>\n",
       "      <td>2.516764</td>\n",
       "      <td>0.500618</td>\n",
       "      <td>1.940400</td>\n",
       "      <td>56</td>\n",
       "      <td>227</td>\n",
       "      <td>2730</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>35.839286</td>\n",
       "      <td>18.444784</td>\n",
       "      <td>169607.758678</td>\n",
       "      <td>78663.619452</td>\n",
       "      <td>142872.849542</td>\n",
       "      <td>97885.206437</td>\n",
       "      <td>46.166352</td>\n",
       "      <td>24.522229</td>\n",
       "      <td>14.789971</td>\n",
       "      <td>-20</td>\n",
       "      <td>0.028</td>\n",
       "      <td>27.533977</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.154</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34434.715836</td>\n",
       "      <td>235.380610</td>\n",
       "      <td>5.689525e+08</td>\n",
       "      <td>12210.005386</td>\n",
       "      <td>39370.958305</td>\n",
       "      <td>107.405745</td>\n",
       "      <td>627.689408</td>\n",
       "      <td>6.840171e+07</td>\n",
       "      <td>516.299514</td>\n",
       "      <td>59750.588869</td>\n",
       "      <td>5223.734291</td>\n",
       "      <td>308659.649910</td>\n",
       "      <td>2.226212</td>\n",
       "      <td>5.957390</td>\n",
       "      <td>4.494712</td>\n",
       "      <td>3.593691</td>\n",
       "      <td>2.163127</td>\n",
       "      <td>5.173140</td>\n",
       "      <td>39048.366166</td>\n",
       "      <td>220.194039</td>\n",
       "      <td>8.686774e+08</td>\n",
       "      <td>14859.765117</td>\n",
       "      <td>53109.757758</td>\n",
       "      <td>127.027229</td>\n",
       "      <td>632.083895</td>\n",
       "      <td>6.349719e+07</td>\n",
       "      <td>594.119614</td>\n",
       "      <td>68146.203483</td>\n",
       "      <td>4954.728076</td>\n",
       "      <td>319652.178094</td>\n",
       "      <td>1.617073</td>\n",
       "      <td>7.150050</td>\n",
       "      <td>3.750610</td>\n",
       "      <td>3.541528</td>\n",
       "      <td>2.132350</td>\n",
       "      <td>5.580070</td>\n",
       "      <td>51547.813869</td>\n",
       "      <td>159.833333</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49805.000000</td>\n",
       "      <td>215.166667</td>\n",
       "      <td>98604.000000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0.144510</td>\n",
       "      <td>5.921589</td>\n",
       "      <td>2.516764</td>\n",
       "      <td>0.500618</td>\n",
       "      <td>1.940400</td>\n",
       "      <td>49582.684663</td>\n",
       "      <td>118.746269</td>\n",
       "      <td>1.843964e+06</td>\n",
       "      <td>18.985075</td>\n",
       "      <td>8697.944523</td>\n",
       "      <td>0.179104</td>\n",
       "      <td>59.682836</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66749.108209</td>\n",
       "      <td>508.626866</td>\n",
       "      <td>185754.809701</td>\n",
       "      <td>1.910448</td>\n",
       "      <td>1.903302</td>\n",
       "      <td>4.116650</td>\n",
       "      <td>2.717738</td>\n",
       "      <td>0.669063</td>\n",
       "      <td>2.511798</td>\n",
       "      <td>51363.458134</td>\n",
       "      <td>142.921569</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.176471</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54631.235294</td>\n",
       "      <td>248.784314</td>\n",
       "      <td>98202.588235</td>\n",
       "      <td>1.980392</td>\n",
       "      <td>0.567695</td>\n",
       "      <td>5.302866</td>\n",
       "      <td>2.522764</td>\n",
       "      <td>0.491388</td>\n",
       "      <td>1.985558</td>\n",
       "      <td>50032.941844</td>\n",
       "      <td>172.047619</td>\n",
       "      <td>3.770323e+07</td>\n",
       "      <td>413.023810</td>\n",
       "      <td>10485.232003</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>23.642857</td>\n",
       "      <td>6.802143e+06</td>\n",
       "      <td>251.370382</td>\n",
       "      <td>52923.023810</td>\n",
       "      <td>383.952381</td>\n",
       "      <td>151100.857143</td>\n",
       "      <td>2.214286</td>\n",
       "      <td>1.145965</td>\n",
       "      <td>5.813568</td>\n",
       "      <td>2.913321</td>\n",
       "      <td>0.629005</td>\n",
       "      <td>2.632741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1255</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>1088280000</td>\n",
       "      <td>37696.24</td>\n",
       "      <td>28869.72282</td>\n",
       "      <td>422</td>\n",
       "      <td>274032611</td>\n",
       "      <td>6796</td>\n",
       "      <td>40322.63258</td>\n",
       "      <td>62</td>\n",
       "      <td>775</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>138730.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46725</td>\n",
       "      <td>0</td>\n",
       "      <td>928198</td>\n",
       "      <td>147575</td>\n",
       "      <td>13354</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.763263</td>\n",
       "      <td>7.477743</td>\n",
       "      <td>8.133736</td>\n",
       "      <td>6.643515</td>\n",
       "      <td>13.817228</td>\n",
       "      <td>8</td>\n",
       "      <td>1156</td>\n",
       "      <td>486</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>56.250000</td>\n",
       "      <td>50.609852</td>\n",
       "      <td>104614.815020</td>\n",
       "      <td>88372.684692</td>\n",
       "      <td>77186.781252</td>\n",
       "      <td>117756.951718</td>\n",
       "      <td>77.491443</td>\n",
       "      <td>52.280512</td>\n",
       "      <td>7.267132</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.005</td>\n",
       "      <td>46.504606</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.013</td>\n",
       "      <td>474</td>\n",
       "      <td>0</td>\n",
       "      <td>39513.500480</td>\n",
       "      <td>207.561170</td>\n",
       "      <td>2.136534e+08</td>\n",
       "      <td>4688.476064</td>\n",
       "      <td>42025.074616</td>\n",
       "      <td>38.579787</td>\n",
       "      <td>354.800532</td>\n",
       "      <td>4.054210e+07</td>\n",
       "      <td>455.194395</td>\n",
       "      <td>65265.109043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>300035.446809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.093770</td>\n",
       "      <td>4.190226</td>\n",
       "      <td>2.961413</td>\n",
       "      <td>1.981788</td>\n",
       "      <td>4.746594</td>\n",
       "      <td>40725.102969</td>\n",
       "      <td>229.518102</td>\n",
       "      <td>1.940921e+08</td>\n",
       "      <td>3806.600763</td>\n",
       "      <td>44245.116035</td>\n",
       "      <td>31.333564</td>\n",
       "      <td>271.877668</td>\n",
       "      <td>2.935649e+07</td>\n",
       "      <td>277.134168</td>\n",
       "      <td>78607.926551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>287437.223218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.608225</td>\n",
       "      <td>4.222785</td>\n",
       "      <td>2.883093</td>\n",
       "      <td>1.945022</td>\n",
       "      <td>4.747559</td>\n",
       "      <td>28328.723792</td>\n",
       "      <td>415.166667</td>\n",
       "      <td>4.905367e+08</td>\n",
       "      <td>12090.333333</td>\n",
       "      <td>40536.723585</td>\n",
       "      <td>132.333333</td>\n",
       "      <td>935.166667</td>\n",
       "      <td>2.151067e+08</td>\n",
       "      <td>2346.122474</td>\n",
       "      <td>46725.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>928198.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.763263</td>\n",
       "      <td>7.477743</td>\n",
       "      <td>8.133736</td>\n",
       "      <td>6.643515</td>\n",
       "      <td>13.817228</td>\n",
       "      <td>30064.657225</td>\n",
       "      <td>270.324324</td>\n",
       "      <td>4.455364e+08</td>\n",
       "      <td>10554.543184</td>\n",
       "      <td>42188.647757</td>\n",
       "      <td>100.215041</td>\n",
       "      <td>751.395417</td>\n",
       "      <td>1.125546e+08</td>\n",
       "      <td>970.094310</td>\n",
       "      <td>29897.245593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>532118.696240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.013983</td>\n",
       "      <td>4.044437</td>\n",
       "      <td>4.597562</td>\n",
       "      <td>3.693982</td>\n",
       "      <td>7.178049</td>\n",
       "      <td>29546.368987</td>\n",
       "      <td>338.152284</td>\n",
       "      <td>4.119331e+08</td>\n",
       "      <td>10093.155185</td>\n",
       "      <td>40797.245546</td>\n",
       "      <td>105.546773</td>\n",
       "      <td>995.436548</td>\n",
       "      <td>1.877803e+08</td>\n",
       "      <td>1642.630417</td>\n",
       "      <td>40552.019579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>779289.135606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.168547</td>\n",
       "      <td>6.210230</td>\n",
       "      <td>6.809382</td>\n",
       "      <td>5.475701</td>\n",
       "      <td>11.064850</td>\n",
       "      <td>44450.088562</td>\n",
       "      <td>215.379152</td>\n",
       "      <td>1.757185e+08</td>\n",
       "      <td>3045.600229</td>\n",
       "      <td>53401.176003</td>\n",
       "      <td>25.135166</td>\n",
       "      <td>284.792669</td>\n",
       "      <td>3.830074e+07</td>\n",
       "      <td>331.491458</td>\n",
       "      <td>72718.476518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>306993.166094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.077823</td>\n",
       "      <td>4.483336</td>\n",
       "      <td>3.140337</td>\n",
       "      <td>1.977003</td>\n",
       "      <td>4.938298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   area  rentType  houseFloor  totalFloor  houseToward  houseDecoration  \\\n",
       "0    57         2           2          15            4                0   \n",
       "1    42         2           1           7            8                0   \n",
       "2    78         1           2          18            4                3   \n",
       "3    35         2           1           5            4                0   \n",
       "4    36         2           2           4            4                0   \n",
       "\n",
       "   communityName  region  plate  buildYear  saleSecHouseNum  totalTradeMoney  \\\n",
       "0            646       1     53       1994                0        392130000   \n",
       "1           3470      11     11       1986                0        438650000   \n",
       "2           1595       3     42       1994                1        613340000   \n",
       "3           2466       6     28       1957               15        488757600   \n",
       "4           1255       2     44       2003                0       1088280000   \n",
       "\n",
       "   totalTradeArea  tradeMeanPrice  tradeSecNum  totalNewTradeMoney  \\\n",
       "0        12589.57     31147.21154          158            26293744   \n",
       "1         7612.89     57619.37976          113            23201066   \n",
       "2        17786.21     34484.01880          199          1687918516   \n",
       "3         9483.30     51538.76815          169                   0   \n",
       "4        37696.24     28869.72282          422           274032611   \n",
       "\n",
       "   totalNewTradeArea  tradeNewMeanPrice  tradeNewNum  remainNewNum  \\\n",
       "0                751        35011.64314            5           214   \n",
       "1                240        96671.10833            2            59   \n",
       "2              34610        48769.67686          301           407   \n",
       "3                  0            0.00000            0             0   \n",
       "4               6796        40322.63258           62           775   \n",
       "\n",
       "   supplyNewNum  supplyLandNum  supplyLandArea  tradeLandNum  tradeLandArea  \\\n",
       "0             0              0             0.0             0            0.0   \n",
       "1             0              0             0.0             0            0.0   \n",
       "2           371              0             0.0             0            0.0   \n",
       "3             0              0             0.0             0            0.0   \n",
       "4             0              2        138730.8             0            0.0   \n",
       "\n",
       "   landTotalPrice  landMeanPrice  totalWorkers  newWorkers  \\\n",
       "0               0            0.0          8498           0   \n",
       "1               0            0.0        120755           0   \n",
       "2               0            0.0        253330           0   \n",
       "3               0            0.0         49805         111   \n",
       "4               0            0.0         46725           0   \n",
       "\n",
       "   residentPopulation      pv     uv  lookNum  month  day  Room  Hall  Bath  \\\n",
       "0              428071   64170   6665        0      6   18     1     1     1   \n",
       "1              309216   10489   1328        0      3    2     2     0     1   \n",
       "2              165159   30581   2704        0      8    8     2     2     1   \n",
       "3               98604     293     58        0     11   11     1     0     1   \n",
       "4              928198  147575  13354        0      6    8     1     1     1   \n",
       "\n",
       "   Room_Bath  trainsportNum  all_SchoolNum  all_hospitalNum  all_mall  \\\n",
       "0   1.000000       6.861430       2.914163         3.955609  3.118232   \n",
       "1   0.666667       6.533145       2.499231         3.019493  1.399270   \n",
       "2   0.666667       2.265734       0.685633         1.106628  1.833608   \n",
       "3   1.000000       0.144510       5.921589         2.516764  0.500618   \n",
       "4   1.000000       8.763263       7.477743         8.133736  6.643515   \n",
       "\n",
       "    otherNum  count_communityName  count_buildYear  count_totalFloor  \\\n",
       "0   7.035898                   15             5659               809   \n",
       "1   4.335986                   21              320              1362   \n",
       "2   2.839831                   15             5659              3553   \n",
       "3   1.940400                   56              227              2730   \n",
       "4  13.817228                    8             1156               486   \n",
       "\n",
       "   count_communityName_totalFloor  count_communityName_newWorkers  \\\n",
       "0                              14                              10   \n",
       "1                              21                              19   \n",
       "2                              11                              11   \n",
       "3                              48                               5   \n",
       "4                               3                               7   \n",
       "\n",
       "   count_communityName_totalTradeMoney  com_area_mean  com_area_std  \\\n",
       "0                                    1      57.666667      8.005950   \n",
       "1                                    4      39.238095      7.974364   \n",
       "2                                    1      72.866667     23.191337   \n",
       "3                                    5      35.839286     18.444784   \n",
       "4                                    1      56.250000     50.609852   \n",
       "\n",
       "   comm_price_mean  comm_price_std  plate_price_mean  plate_price_std  \\\n",
       "0     56011.618848    11432.901072      95866.315739    103261.303345   \n",
       "1    140701.447242    25959.585233     154231.435167    144059.477704   \n",
       "2     64715.839564    83080.341652      74449.615731     83069.250127   \n",
       "3    169607.758678    78663.619452     142872.849542     97885.206437   \n",
       "4    104614.815020    88372.684692      77186.781252    117756.951718   \n",
       "\n",
       "   plate_area_mean  plate_area_std  plate_year_std  comm_plate_year_diff  \\\n",
       "0        67.563758       87.878800        8.720308                    -6   \n",
       "1        53.939891       33.509477       14.759094                    -3   \n",
       "2        74.935159       42.805242        9.095648                   -12   \n",
       "3        46.166352       24.522229       14.789971                   -20   \n",
       "4        77.491443       52.280512        7.267132                    -1   \n",
       "\n",
       "   trainsportNum_ratio  com_all_mall  other_ratio  sale_ratio  \\\n",
       "0                0.009     43.655253        0.012       0.014   \n",
       "1                0.047     29.384662        0.038       0.045   \n",
       "2                0.016     20.169689        0.016       0.031   \n",
       "3                0.028     27.533977        0.102       0.154   \n",
       "4                0.005     46.504606        0.005       0.013   \n",
       "\n",
       "   sale_newworker_differ  cluster  tradeMeanPrice_totalFloor_cluster_mean  \\\n",
       "0                    429        0                            37234.390317   \n",
       "1                    333        0                            44629.869276   \n",
       "2                    189        0                            35171.928027   \n",
       "3                      3        1                            34434.715836   \n",
       "4                    474        0                            39513.500480   \n",
       "\n",
       "   tradeSecNum_totalFloor_cluster_mean  \\\n",
       "0                           232.448845   \n",
       "1                           182.434742   \n",
       "2                           245.471233   \n",
       "3                           235.380610   \n",
       "4                           207.561170   \n",
       "\n",
       "   totalNewTradeMoney_totalFloor_cluster_mean  \\\n",
       "0                                2.134405e+08   \n",
       "1                                1.662570e+08   \n",
       "2                                2.657397e+08   \n",
       "3                                5.689525e+08   \n",
       "4                                2.136534e+08   \n",
       "\n",
       "   totalNewTradeArea_totalFloor_cluster_mean  \\\n",
       "0                                4719.924092   \n",
       "1                                2510.731455   \n",
       "2                                5741.705284   \n",
       "3                               12210.005386   \n",
       "4                                4688.476064   \n",
       "\n",
       "   tradeNewMeanPrice_totalFloor_cluster_mean  \\\n",
       "0                               38813.883094   \n",
       "1                               48701.681393   \n",
       "2                               44279.017722   \n",
       "3                               39370.958305   \n",
       "4                               42025.074616   \n",
       "\n",
       "   tradeNewNum_totalFloor_cluster_mean  remainNewNum_totalFloor_cluster_mean  \\\n",
       "0                            41.143564                            305.674917   \n",
       "1                            18.217840                            187.546479   \n",
       "2                            49.390998                            414.180039   \n",
       "3                           107.405745                            627.689408   \n",
       "4                            38.579787                            354.800532   \n",
       "\n",
       "   landTotalPrice_totalFloor_cluster_mean  \\\n",
       "0                            3.745285e+07   \n",
       "1                            2.283223e+07   \n",
       "2                            4.973183e+07   \n",
       "3                            6.840171e+07   \n",
       "4                            4.054210e+07   \n",
       "\n",
       "   landMeanPrice_totalFloor_cluster_mean  \\\n",
       "0                             265.775476   \n",
       "1                             254.032348   \n",
       "2                             486.120865   \n",
       "3                             516.299514   \n",
       "4                             455.194395   \n",
       "\n",
       "   totalWorkers_totalFloor_cluster_mean  newWorkers_totalFloor_cluster_mean  \\\n",
       "0                          77849.013201                            0.000000   \n",
       "1                          91834.026291                            0.000000   \n",
       "2                          61481.230137                            0.000000   \n",
       "3                          59750.588869                         5223.734291   \n",
       "4                          65265.109043                            0.000000   \n",
       "\n",
       "   residentPopulation_totalFloor_cluster_mean  \\\n",
       "0                               330429.646865   \n",
       "1                               242360.642254   \n",
       "2                               323437.272407   \n",
       "3                               308659.649910   \n",
       "4                               300035.446809   \n",
       "\n",
       "   lookNum_totalFloor_cluster_mean  trainsportNum_totalFloor_cluster_mean  \\\n",
       "0                         0.000000                               5.420387   \n",
       "1                         0.000000                               5.068509   \n",
       "2                         0.000000                               5.659887   \n",
       "3                         2.226212                               5.957390   \n",
       "4                         0.000000                               5.093770   \n",
       "\n",
       "   all_SchoolNum_totalFloor_cluster_mean  \\\n",
       "0                               3.315204   \n",
       "1                               3.548384   \n",
       "2                               3.490074   \n",
       "3                               4.494712   \n",
       "4                               4.190226   \n",
       "\n",
       "   all_hospitalNum_totalFloor_cluster_mean  all_mall_totalFloor_cluster_mean  \\\n",
       "0                                 3.106066                          2.327820   \n",
       "1                                 2.467506                          1.587749   \n",
       "2                                 3.150568                          2.272588   \n",
       "3                                 3.593691                          2.163127   \n",
       "4                                 2.961413                          1.981788   \n",
       "\n",
       "   otherNum_totalFloor_cluster_mean  \\\n",
       "0                          5.084342   \n",
       "1                          4.071131   \n",
       "2                          5.257058   \n",
       "3                          5.173140   \n",
       "4                          4.746594   \n",
       "\n",
       "   tradeMeanPrice_houseDecoration_cluster_mean  \\\n",
       "0                                 40725.102969   \n",
       "1                                 40725.102969   \n",
       "2                                 41286.309465   \n",
       "3                                 39048.366166   \n",
       "4                                 40725.102969   \n",
       "\n",
       "   tradeSecNum_houseDecoration_cluster_mean  \\\n",
       "0                                229.518102   \n",
       "1                                229.518102   \n",
       "2                                218.818389   \n",
       "3                                220.194039   \n",
       "4                                229.518102   \n",
       "\n",
       "   totalNewTradeMoney_houseDecoration_cluster_mean  \\\n",
       "0                                     1.940921e+08   \n",
       "1                                     1.940921e+08   \n",
       "2                                     1.770842e+08   \n",
       "3                                     8.686774e+08   \n",
       "4                                     1.940921e+08   \n",
       "\n",
       "   totalNewTradeArea_houseDecoration_cluster_mean  \\\n",
       "0                                     3806.600763   \n",
       "1                                     3806.600763   \n",
       "2                                     3310.516500   \n",
       "3                                    14859.765117   \n",
       "4                                     3806.600763   \n",
       "\n",
       "   tradeNewMeanPrice_houseDecoration_cluster_mean  \\\n",
       "0                                    44245.116035   \n",
       "1                                    44245.116035   \n",
       "2                                    47866.995252   \n",
       "3                                    53109.757758   \n",
       "4                                    44245.116035   \n",
       "\n",
       "   tradeNewNum_houseDecoration_cluster_mean  \\\n",
       "0                                 31.333564   \n",
       "1                                 31.333564   \n",
       "2                                 26.746852   \n",
       "3                                127.027229   \n",
       "4                                 31.333564   \n",
       "\n",
       "   remainNewNum_houseDecoration_cluster_mean  \\\n",
       "0                                 271.877668   \n",
       "1                                 271.877668   \n",
       "2                                 249.648285   \n",
       "3                                 632.083895   \n",
       "4                                 271.877668   \n",
       "\n",
       "   landTotalPrice_houseDecoration_cluster_mean  \\\n",
       "0                                 2.935649e+07   \n",
       "1                                 2.935649e+07   \n",
       "2                                 4.677131e+07   \n",
       "3                                 6.349719e+07   \n",
       "4                                 2.935649e+07   \n",
       "\n",
       "   landMeanPrice_houseDecoration_cluster_mean  \\\n",
       "0                                  277.134168   \n",
       "1                                  277.134168   \n",
       "2                                  383.161679   \n",
       "3                                  594.119614   \n",
       "4                                  277.134168   \n",
       "\n",
       "   totalWorkers_houseDecoration_cluster_mean  \\\n",
       "0                               78607.926551   \n",
       "1                               78607.926551   \n",
       "2                               85574.482306   \n",
       "3                               68146.203483   \n",
       "4                               78607.926551   \n",
       "\n",
       "   newWorkers_houseDecoration_cluster_mean  \\\n",
       "0                                 0.000000   \n",
       "1                                 0.000000   \n",
       "2                                 0.000000   \n",
       "3                              4954.728076   \n",
       "4                                 0.000000   \n",
       "\n",
       "   residentPopulation_houseDecoration_cluster_mean  \\\n",
       "0                                    287437.223218   \n",
       "1                                    287437.223218   \n",
       "2                                    282260.154472   \n",
       "3                                    319652.178094   \n",
       "4                                    287437.223218   \n",
       "\n",
       "   lookNum_houseDecoration_cluster_mean  \\\n",
       "0                              0.000000   \n",
       "1                              0.000000   \n",
       "2                              0.000000   \n",
       "3                              1.617073   \n",
       "4                              0.000000   \n",
       "\n",
       "   trainsportNum_houseDecoration_cluster_mean  \\\n",
       "0                                    5.608225   \n",
       "1                                    5.608225   \n",
       "2                                    5.634353   \n",
       "3                                    7.150050   \n",
       "4                                    5.608225   \n",
       "\n",
       "   all_SchoolNum_houseDecoration_cluster_mean  \\\n",
       "0                                    4.222785   \n",
       "1                                    4.222785   \n",
       "2                                    3.769083   \n",
       "3                                    3.750610   \n",
       "4                                    4.222785   \n",
       "\n",
       "   all_hospitalNum_houseDecoration_cluster_mean  \\\n",
       "0                                      2.883093   \n",
       "1                                      2.883093   \n",
       "2                                      2.692437   \n",
       "3                                      3.541528   \n",
       "4                                      2.883093   \n",
       "\n",
       "   all_mall_houseDecoration_cluster_mean  \\\n",
       "0                               1.945022   \n",
       "1                               1.945022   \n",
       "2                               1.911154   \n",
       "3                               2.132350   \n",
       "4                               1.945022   \n",
       "\n",
       "   otherNum_houseDecoration_cluster_mean  \\\n",
       "0                               4.747559   \n",
       "1                               4.747559   \n",
       "2                               4.726214   \n",
       "3                               5.580070   \n",
       "4                               4.747559   \n",
       "\n",
       "   tradeMeanPrice_communityName_cluster_mean  \\\n",
       "0                               31079.504539   \n",
       "1                               53739.820320   \n",
       "2                               32511.713706   \n",
       "3                               51547.813869   \n",
       "4                               28328.723792   \n",
       "\n",
       "   tradeSecNum_communityName_cluster_mean  \\\n",
       "0                              173.800000   \n",
       "1                              104.266667   \n",
       "2                              171.636364   \n",
       "3                              159.833333   \n",
       "4                              415.166667   \n",
       "\n",
       "   totalNewTradeMoney_communityName_cluster_mean  \\\n",
       "0                                   3.818973e+07   \n",
       "1                                   4.626383e+08   \n",
       "2                                   4.766587e+08   \n",
       "3                                   0.000000e+00   \n",
       "4                                   4.905367e+08   \n",
       "\n",
       "   totalNewTradeArea_communityName_cluster_mean  \\\n",
       "0                                   1001.900000   \n",
       "1                                   4801.333333   \n",
       "2                                  10247.000000   \n",
       "3                                      0.000000   \n",
       "4                                  12090.333333   \n",
       "\n",
       "   tradeNewMeanPrice_communityName_cluster_mean  \\\n",
       "0                                  35419.551532   \n",
       "1                                  96091.755367   \n",
       "2                                  45747.191029   \n",
       "3                                      0.000000   \n",
       "4                                  40536.723585   \n",
       "\n",
       "   tradeNewNum_communityName_cluster_mean  \\\n",
       "0                                4.100000   \n",
       "1                               26.333333   \n",
       "2                               94.727273   \n",
       "3                                0.000000   \n",
       "4                              132.333333   \n",
       "\n",
       "   remainNewNum_communityName_cluster_mean  \\\n",
       "0                               217.400000   \n",
       "1                               186.733333   \n",
       "2                               399.727273   \n",
       "3                                 0.000000   \n",
       "4                               935.166667   \n",
       "\n",
       "   landTotalPrice_communityName_cluster_mean  \\\n",
       "0                               0.000000e+00   \n",
       "1                               2.903000e+07   \n",
       "2                               0.000000e+00   \n",
       "3                               0.000000e+00   \n",
       "4                               2.151067e+08   \n",
       "\n",
       "   landMeanPrice_communityName_cluster_mean  \\\n",
       "0                                  0.000000   \n",
       "1                               1442.057649   \n",
       "2                                  0.000000   \n",
       "3                                  0.000000   \n",
       "4                               2346.122474   \n",
       "\n",
       "   totalWorkers_communityName_cluster_mean  \\\n",
       "0                              8498.000000   \n",
       "1                            120755.000000   \n",
       "2                            210433.818182   \n",
       "3                             49805.000000   \n",
       "4                             46725.000000   \n",
       "\n",
       "   newWorkers_communityName_cluster_mean  \\\n",
       "0                               0.000000   \n",
       "1                               0.000000   \n",
       "2                               0.000000   \n",
       "3                             215.166667   \n",
       "4                               0.000000   \n",
       "\n",
       "   residentPopulation_communityName_cluster_mean  \\\n",
       "0                                  428071.000000   \n",
       "1                                  309216.000000   \n",
       "2                                  193286.454545   \n",
       "3                                   98604.000000   \n",
       "4                                  928198.000000   \n",
       "\n",
       "   lookNum_communityName_cluster_mean  \\\n",
       "0                            0.000000   \n",
       "1                            0.000000   \n",
       "2                            0.000000   \n",
       "3                            2.833333   \n",
       "4                            0.000000   \n",
       "\n",
       "   trainsportNum_communityName_cluster_mean  \\\n",
       "0                                  6.861430   \n",
       "1                                  6.533145   \n",
       "2                                  3.096501   \n",
       "3                                  0.144510   \n",
       "4                                  8.763263   \n",
       "\n",
       "   all_SchoolNum_communityName_cluster_mean  \\\n",
       "0                                  2.914163   \n",
       "1                                  2.499231   \n",
       "2                                  1.892693   \n",
       "3                                  5.921589   \n",
       "4                                  7.477743   \n",
       "\n",
       "   all_hospitalNum_communityName_cluster_mean  \\\n",
       "0                                    3.955609   \n",
       "1                                    3.019493   \n",
       "2                                    1.115730   \n",
       "3                                    2.516764   \n",
       "4                                    8.133736   \n",
       "\n",
       "   all_mall_communityName_cluster_mean  otherNum_communityName_cluster_mean  \\\n",
       "0                             3.118232                             7.035898   \n",
       "1                             1.399270                             4.335986   \n",
       "2                             1.836681                             3.127984   \n",
       "3                             0.500618                             1.940400   \n",
       "4                             6.643515                            13.817228   \n",
       "\n",
       "   tradeMeanPrice_region_cluster_mean  tradeSecNum_region_cluster_mean  \\\n",
       "0                        41476.021283                       321.679504   \n",
       "1                        50724.464178                       164.072800   \n",
       "2                        31226.586754                       218.058221   \n",
       "3                        49582.684663                       118.746269   \n",
       "4                        30064.657225                       270.324324   \n",
       "\n",
       "   totalNewTradeMoney_region_cluster_mean  \\\n",
       "0                            1.724097e+08   \n",
       "1                            4.091667e+07   \n",
       "2                            2.900306e+08   \n",
       "3                            1.843964e+06   \n",
       "4                            4.455364e+08   \n",
       "\n",
       "   totalNewTradeArea_region_cluster_mean  \\\n",
       "0                            2949.490126   \n",
       "1                             429.828685   \n",
       "2                            6140.786308   \n",
       "3                              18.985075   \n",
       "4                           10554.543184   \n",
       "\n",
       "   tradeNewMeanPrice_region_cluster_mean  tradeNewNum_region_cluster_mean  \\\n",
       "0                           62580.585009                        22.496382   \n",
       "1                           17624.818421                         2.335024   \n",
       "2                           30628.396982                        57.154191   \n",
       "3                            8697.944523                         0.179104   \n",
       "4                           42188.647757                       100.215041   \n",
       "\n",
       "   remainNewNum_region_cluster_mean  landTotalPrice_region_cluster_mean  \\\n",
       "0                        216.609837                        2.676943e+07   \n",
       "1                         83.196306                        3.416624e+06   \n",
       "2                        259.392194                        1.657321e+07   \n",
       "3                         59.682836                        0.000000e+00   \n",
       "4                        751.395417                        1.125546e+08   \n",
       "\n",
       "   landMeanPrice_region_cluster_mean  totalWorkers_region_cluster_mean  \\\n",
       "0                         122.363175                     151335.517601   \n",
       "1                         220.008656                      64477.336472   \n",
       "2                         278.448139                     156349.654511   \n",
       "3                           0.000000                      66749.108209   \n",
       "4                         970.094310                      29897.245593   \n",
       "\n",
       "   newWorkers_region_cluster_mean  residentPopulation_region_cluster_mean  \\\n",
       "0                        0.000000                           344045.843493   \n",
       "1                        0.000000                           214085.011590   \n",
       "2                        0.000000                           208959.486244   \n",
       "3                      508.626866                           185754.809701   \n",
       "4                        0.000000                           532118.696240   \n",
       "\n",
       "   lookNum_region_cluster_mean  trainsportNum_region_cluster_mean  \\\n",
       "0                     0.000000                           9.273148   \n",
       "1                     0.000000                           3.889478   \n",
       "2                     0.000000                           5.592588   \n",
       "3                     1.910448                           1.903302   \n",
       "4                     0.000000                           5.013983   \n",
       "\n",
       "   all_SchoolNum_region_cluster_mean  all_hospitalNum_region_cluster_mean  \\\n",
       "0                           4.502851                             3.550913   \n",
       "1                           3.714923                             2.643469   \n",
       "2                           0.721673                             2.576660   \n",
       "3                           4.116650                             2.717738   \n",
       "4                           4.044437                             4.597562   \n",
       "\n",
       "   all_mall_region_cluster_mean  otherNum_region_cluster_mean  \\\n",
       "0                      2.196679                      6.243596   \n",
       "1                      0.963086                      3.326727   \n",
       "2                      2.143895                      4.067558   \n",
       "3                      0.669063                      2.511798   \n",
       "4                      3.693982                      7.178049   \n",
       "\n",
       "   tradeMeanPrice_plate_cluster_mean  tradeSecNum_plate_cluster_mean  \\\n",
       "0                       34773.122085                      193.143013   \n",
       "1                       52402.701262                      160.326484   \n",
       "2                       32640.334288                      182.613757   \n",
       "3                       51363.458134                      142.921569   \n",
       "4                       29546.368987                      338.152284   \n",
       "\n",
       "   totalNewTradeMoney_plate_cluster_mean  \\\n",
       "0                           1.158908e+08   \n",
       "1                           1.653230e+08   \n",
       "2                           4.813406e+08   \n",
       "3                           0.000000e+00   \n",
       "4                           4.119331e+08   \n",
       "\n",
       "   totalNewTradeArea_plate_cluster_mean  tradeNewMeanPrice_plate_cluster_mean  \\\n",
       "0                           2217.561135                          44129.109313   \n",
       "1                           1722.625571                          49717.365511   \n",
       "2                          10349.536155                          45433.926056   \n",
       "3                              0.000000                              0.000000   \n",
       "4                          10093.155185                          40797.245546   \n",
       "\n",
       "   tradeNewNum_plate_cluster_mean  remainNewNum_plate_cluster_mean  \\\n",
       "0                       14.838428                       280.707424   \n",
       "1                        9.246575                        82.751142   \n",
       "2                       94.650794                       461.689594   \n",
       "3                        0.000000                         3.176471   \n",
       "4                      105.546773                       995.436548   \n",
       "\n",
       "   landTotalPrice_plate_cluster_mean  landMeanPrice_plate_cluster_mean  \\\n",
       "0                       0.000000e+00                          0.000000   \n",
       "1                       8.272968e+06                        461.296022   \n",
       "2                       0.000000e+00                          0.000000   \n",
       "3                       0.000000e+00                          0.000000   \n",
       "4                       1.877803e+08                       1642.630417   \n",
       "\n",
       "   totalWorkers_plate_cluster_mean  newWorkers_plate_cluster_mean  \\\n",
       "0                      7763.432314                       0.000000   \n",
       "1                     81309.940639                       0.000000   \n",
       "2                    240414.003527                       0.000000   \n",
       "3                     54631.235294                     248.784314   \n",
       "4                     40552.019579                       0.000000   \n",
       "\n",
       "   residentPopulation_plate_cluster_mean  lookNum_plate_cluster_mean  \\\n",
       "0                          406501.259825                    0.000000   \n",
       "1                          305442.808219                    0.000000   \n",
       "2                          163120.816578                    0.000000   \n",
       "3                           98202.588235                    1.980392   \n",
       "4                          779289.135606                    0.000000   \n",
       "\n",
       "   trainsportNum_plate_cluster_mean  all_SchoolNum_plate_cluster_mean  \\\n",
       "0                          7.489401                          2.629209   \n",
       "1                          5.207264                          3.946431   \n",
       "2                          2.188203                          0.666448   \n",
       "3                          0.567695                          5.302866   \n",
       "4                          7.168547                          6.210230   \n",
       "\n",
       "   all_hospitalNum_plate_cluster_mean  all_mall_plate_cluster_mean  \\\n",
       "0                            3.956709                     2.870786   \n",
       "1                            3.647401                     1.115555   \n",
       "2                            1.068570                     1.776886   \n",
       "3                            2.522764                     0.491388   \n",
       "4                            6.809382                     5.475701   \n",
       "\n",
       "   otherNum_plate_cluster_mean  tradeMeanPrice_buildYear_cluster_mean  \\\n",
       "0                     6.609019                           38386.178484   \n",
       "1                     4.408551                           50108.594319   \n",
       "2                     2.793112                           38386.178484   \n",
       "3                     1.985558                           50032.941844   \n",
       "4                    11.064850                           44450.088562   \n",
       "\n",
       "   tradeSecNum_buildYear_cluster_mean  \\\n",
       "0                          215.547458   \n",
       "1                          239.519231   \n",
       "2                          215.547458   \n",
       "3                          172.047619   \n",
       "4                          215.379152   \n",
       "\n",
       "   totalNewTradeMoney_buildYear_cluster_mean  \\\n",
       "0                               2.051141e+08   \n",
       "1                               1.181157e+08   \n",
       "2                               2.051141e+08   \n",
       "3                               3.770323e+07   \n",
       "4                               1.757185e+08   \n",
       "\n",
       "   totalNewTradeArea_buildYear_cluster_mean  \\\n",
       "0                               4220.866016   \n",
       "1                               1290.584615   \n",
       "2                               4220.866016   \n",
       "3                                413.023810   \n",
       "4                               3045.600229   \n",
       "\n",
       "   tradeNewMeanPrice_buildYear_cluster_mean  \\\n",
       "0                              43980.696790   \n",
       "1                              43857.451243   \n",
       "2                              43980.696790   \n",
       "3                              10485.232003   \n",
       "4                              53401.176003   \n",
       "\n",
       "   tradeNewNum_buildYear_cluster_mean  remainNewNum_buildYear_cluster_mean  \\\n",
       "0                           33.438267                           314.098923   \n",
       "1                            7.357692                           122.219231   \n",
       "2                           33.438267                           314.098923   \n",
       "3                            2.666667                            23.642857   \n",
       "4                           25.135166                           284.792669   \n",
       "\n",
       "   landTotalPrice_buildYear_cluster_mean  \\\n",
       "0                           3.084462e+07   \n",
       "1                           7.717346e+06   \n",
       "2                           3.084462e+07   \n",
       "3                           6.802143e+06   \n",
       "4                           3.830074e+07   \n",
       "\n",
       "   landMeanPrice_buildYear_cluster_mean  totalWorkers_buildYear_cluster_mean  \\\n",
       "0                            317.416683                         57279.348109   \n",
       "1                            333.219172                        200760.196154   \n",
       "2                            317.416683                         57279.348109   \n",
       "3                            251.370382                         52923.023810   \n",
       "4                            331.491458                         72718.476518   \n",
       "\n",
       "   newWorkers_buildYear_cluster_mean  \\\n",
       "0                           0.000000   \n",
       "1                           0.000000   \n",
       "2                           0.000000   \n",
       "3                         383.952381   \n",
       "4                           0.000000   \n",
       "\n",
       "   residentPopulation_buildYear_cluster_mean  lookNum_buildYear_cluster_mean  \\\n",
       "0                              280336.653143                        0.000000   \n",
       "1                              216132.688462                        0.000000   \n",
       "2                              280336.653143                        0.000000   \n",
       "3                              151100.857143                        2.214286   \n",
       "4                              306993.166094                        0.000000   \n",
       "\n",
       "   trainsportNum_buildYear_cluster_mean  all_SchoolNum_buildYear_cluster_mean  \\\n",
       "0                              5.524240                              4.023809   \n",
       "1                              4.536364                              4.198835   \n",
       "2                              5.524240                              4.023809   \n",
       "3                              1.145965                              5.813568   \n",
       "4                              6.077823                              4.483336   \n",
       "\n",
       "   all_hospitalNum_buildYear_cluster_mean  all_mall_buildYear_cluster_mean  \\\n",
       "0                                2.670093                         1.931252   \n",
       "1                                2.566916                         1.579720   \n",
       "2                                2.670093                         1.931252   \n",
       "3                                2.913321                         0.629005   \n",
       "4                                3.140337                         1.977003   \n",
       "\n",
       "   otherNum_buildYear_cluster_mean  \n",
       "0                         4.448482  \n",
       "1                         4.872755  \n",
       "2                         4.448482  \n",
       "3                         2.632741  \n",
       "4                         4.938298  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## log平滑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 过大量级值取log平滑（针对线性模型有效）\n",
    "# 连续变量做log计算\n",
    "big_num_cols = ['totalTradeMoney','totalTradeArea','tradeMeanPrice','totalNewTradeMoney', 'totalNewTradeArea',\n",
    "                'tradeNewMeanPrice','remainNewNum', 'supplyNewNum', 'supplyLandArea',\n",
    "                'tradeLandArea','landTotalPrice','landMeanPrice','totalWorkers','newWorkers',\n",
    "                'residentPopulation','pv','uv']\n",
    "for col in big_num_cols:\n",
    "        train[col] = train[col].map(lambda x: np.log1p(x))\n",
    "        test[col] = test[col].map(lambda x: np.log1p(x))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集结果： -3.5292471822430898\n",
      "测试集结果： -85652.22051941564\n"
     ]
    }
   ],
   "source": [
    "#对比特征工程前后线性模型结果情况\n",
    "test=test.fillna(0)\n",
    "# Lasso回归\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso=Lasso(alpha=0.1)\n",
    "lasso.fit(train,target_train)\n",
    "#预测测试集和训练集结果\n",
    "y_pred_train=lasso.predict(train)\n",
    "y_pred_test=lasso.predict(test)\n",
    "\n",
    "#对比结果\n",
    "from sklearn.metrics import r2_score\n",
    "score_train=r2_score(y_pred_train,target_train)\n",
    "print(\"训练集结果：\",score_train)\n",
    "score_test=r2_score(y_pred_test, target_test)\n",
    "print(\"测试集结果：\",score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-24T12:31:08.989972Z",
     "start_time": "2019-12-24T12:31:08.986978Z"
    }
   },
   "source": [
    "# 特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# #读取数据\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# origin = pd.read_csv('数据集/train_data.csv')\n",
    "# train, test, _, _ = train_test_split(origin, origin[\"tradeMoney\"], test_size=0.3, random_state=30)\n",
    "# target_train = train.pop('tradeMoney')\n",
    "# target_test = test.pop('tradeMoney')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相关系数法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不同的算法进行特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29008, 174)\n",
      "(29008, 150)\n",
      "(12432, 150)\n",
      "训练集结果： -3.578462320492129\n",
      "测试集结果： -91856.29302572335\n"
     ]
    }
   ],
   "source": [
    "#相关系数法特征选择\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "print(train.shape)\n",
    "\n",
    "sk=SelectKBest(k=150)\n",
    "new_train=sk.fit_transform(train,target_train)\n",
    "print(new_train.shape)\n",
    "\n",
    "# 获取对应列索引\n",
    "select_columns=sk.get_support(indices = True)\n",
    "# print(select_columns)\n",
    "\n",
    "# 获取对应列名\n",
    "# print(test.columns[select_columns])\n",
    "select_columns_name=test.columns[select_columns]\n",
    "new_test=test[select_columns_name]\n",
    "print(new_test.shape)\n",
    "# Lasso回归\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso=Lasso(alpha=0.1)\n",
    "lasso.fit(new_train,target_train)\n",
    "#预测测试集和训练集结果\n",
    "y_pred_train=lasso.predict(new_train)\n",
    "\n",
    "y_pred_test=lasso.predict(new_test)\n",
    "\n",
    "#对比结果\n",
    "from sklearn.metrics import r2_score\n",
    "score_train=r2_score(y_pred_train,target_train)\n",
    "print(\"训练集结果：\",score_train)\n",
    "score_test=r2_score(y_pred_test, target_test)\n",
    "print(\"测试集结果：\",score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['area', 'rentType', 'houseFloor', 'totalFloor', 'houseToward', 'houseDecoration', 'communityName', 'region', 'plate', 'buildYear', 'saleSecHouseNum', 'totalTradeMoney', 'totalTradeArea', 'tradeMeanPrice', 'tradeSecNum', 'totalNewTradeMoney', 'totalNewTradeArea', 'tradeNewMeanPrice', 'tradeNewNum', 'remainNewNum', 'supplyNewNum', 'supplyLandNum', 'supplyLandArea', 'tradeLandNum', 'tradeLandArea', 'landTotalPrice', 'landMeanPrice', 'totalWorkers', 'newWorkers', 'residentPopulation', 'pv', 'uv', 'lookNum', 'month', 'day', 'Room', 'Hall', 'Bath', 'Room_Bath', 'trainsportNum', 'all_SchoolNum', 'all_hospitalNum', 'all_mall', 'otherNum', 'count_communityName', 'count_buildYear', 'count_totalFloor', 'count_communityName_totalFloor', 'count_communityName_newWorkers', 'count_communityName_totalTradeMoney', 'com_area_mean', 'com_area_std', 'comm_price_mean', 'plate_price_mean', 'plate_price_std', 'plate_area_mean', 'plate_area_std', 'plate_year_std', 'comm_plate_year_diff', 'trainsportNum_ratio', 'com_all_mall', 'other_ratio', 'sale_ratio', 'sale_newworker_differ', 'cluster', 'tradeMeanPrice_totalFloor_cluster_mean', 'tradeSecNum_totalFloor_cluster_mean', 'totalNewTradeArea_totalFloor_cluster_mean', 'tradeNewMeanPrice_totalFloor_cluster_mean', 'tradeNewNum_totalFloor_cluster_mean', 'remainNewNum_totalFloor_cluster_mean', 'landMeanPrice_totalFloor_cluster_mean', 'totalWorkers_totalFloor_cluster_mean', 'newWorkers_totalFloor_cluster_mean', 'residentPopulation_totalFloor_cluster_mean', 'lookNum_totalFloor_cluster_mean', 'trainsportNum_totalFloor_cluster_mean', 'all_SchoolNum_totalFloor_cluster_mean', 'all_hospitalNum_totalFloor_cluster_mean', 'all_mall_totalFloor_cluster_mean', 'otherNum_totalFloor_cluster_mean', 'tradeMeanPrice_houseDecoration_cluster_mean', 'tradeSecNum_houseDecoration_cluster_mean', 'totalNewTradeArea_houseDecoration_cluster_mean', 'tradeNewMeanPrice_houseDecoration_cluster_mean', 'tradeNewNum_houseDecoration_cluster_mean', 'remainNewNum_houseDecoration_cluster_mean', 'landMeanPrice_houseDecoration_cluster_mean', 'totalWorkers_houseDecoration_cluster_mean', 'newWorkers_houseDecoration_cluster_mean', 'residentPopulation_houseDecoration_cluster_mean', 'lookNum_houseDecoration_cluster_mean', 'trainsportNum_houseDecoration_cluster_mean', 'all_SchoolNum_houseDecoration_cluster_mean', 'all_hospitalNum_houseDecoration_cluster_mean', 'all_mall_houseDecoration_cluster_mean', 'otherNum_houseDecoration_cluster_mean', 'tradeMeanPrice_communityName_cluster_mean', 'tradeSecNum_communityName_cluster_mean', 'totalNewTradeArea_communityName_cluster_mean', 'tradeNewMeanPrice_communityName_cluster_mean', 'tradeNewNum_communityName_cluster_mean', 'remainNewNum_communityName_cluster_mean', 'landMeanPrice_communityName_cluster_mean', 'totalWorkers_communityName_cluster_mean', 'newWorkers_communityName_cluster_mean', 'residentPopulation_communityName_cluster_mean', 'lookNum_communityName_cluster_mean', 'trainsportNum_communityName_cluster_mean', 'all_SchoolNum_communityName_cluster_mean', 'all_hospitalNum_communityName_cluster_mean', 'all_mall_communityName_cluster_mean', 'otherNum_communityName_cluster_mean', 'tradeMeanPrice_region_cluster_mean', 'tradeSecNum_region_cluster_mean', 'totalNewTradeArea_region_cluster_mean', 'tradeNewMeanPrice_region_cluster_mean', 'tradeNewNum_region_cluster_mean', 'remainNewNum_region_cluster_mean', 'landMeanPrice_region_cluster_mean', 'totalWorkers_region_cluster_mean', 'newWorkers_region_cluster_mean', 'residentPopulation_region_cluster_mean', 'lookNum_region_cluster_mean', 'trainsportNum_region_cluster_mean', 'all_SchoolNum_region_cluster_mean', 'all_hospitalNum_region_cluster_mean', 'all_mall_region_cluster_mean', 'otherNum_region_cluster_mean', 'tradeMeanPrice_plate_cluster_mean', 'tradeSecNum_plate_cluster_mean', 'totalNewTradeArea_plate_cluster_mean', 'tradeNewMeanPrice_plate_cluster_mean', 'tradeNewNum_plate_cluster_mean', 'remainNewNum_plate_cluster_mean', 'landMeanPrice_plate_cluster_mean', 'totalWorkers_plate_cluster_mean', 'newWorkers_plate_cluster_mean', 'residentPopulation_plate_cluster_mean', 'lookNum_plate_cluster_mean', 'trainsportNum_plate_cluster_mean', 'all_SchoolNum_plate_cluster_mean', 'all_hospitalNum_plate_cluster_mean', 'all_mall_plate_cluster_mean', 'otherNum_plate_cluster_mean', 'tradeMeanPrice_buildYear_cluster_mean', 'tradeSecNum_buildYear_cluster_mean', 'totalNewTradeArea_buildYear_cluster_mean', 'tradeNewNum_buildYear_cluster_mean', 'remainNewNum_buildYear_cluster_mean', 'landMeanPrice_buildYear_cluster_mean', 'totalWorkers_buildYear_cluster_mean', 'newWorkers_buildYear_cluster_mean', 'residentPopulation_buildYear_cluster_mean', 'lookNum_buildYear_cluster_mean', 'trainsportNum_buildYear_cluster_mean', 'all_SchoolNum_buildYear_cluster_mean', 'all_hospitalNum_buildYear_cluster_mean', 'all_mall_buildYear_cluster_mean', 'otherNum_buildYear_cluster_mean']\n",
      "训练集结果： -3.53908232168242\n",
      "测试集结果： -86428.45340355093\n"
     ]
    }
   ],
   "source": [
    "# Wrapper\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "rfe = RFE(lr, n_features_to_select=160)\n",
    "rfe.fit(train,target_train)\n",
    "\n",
    "RFE(estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
    "                               normalize=False),\n",
    "    n_features_to_select=40, step=1, verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "select_columns = [f for f, s in zip(train.columns, rfe.support_) if s]\n",
    "print(select_columns)\n",
    "new_train = train[select_columns]\n",
    "new_test = test[select_columns]\n",
    "\n",
    "# Lasso回归\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso=Lasso(alpha=0.1)\n",
    "lasso.fit(new_train,target_train)\n",
    "#预测测试集和训练集结果\n",
    "y_pred_train=lasso.predict(new_train)\n",
    "\n",
    "y_pred_test=lasso.predict(new_test)\n",
    "\n",
    "#对比结果\n",
    "from sklearn.metrics import r2_score\n",
    "score_train=r2_score(y_pred_train,target_train)\n",
    "print(\"训练集结果：\",score_train)\n",
    "score_test=r2_score(y_pred_test, target_test)\n",
    "print(\"测试集结果：\",score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedded\n",
    "### 基于惩罚项的特征选择法\n",
    "### Lasso(l1)和Ridge(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 38 136  60  81  42 155  29  63  23  41 133  30  35  26  16  21 152  13\n",
      " 150  78 151 114 134 173  17 115  58   9 170 119  28 143 116 161 169  51\n",
      "  49  48  71  57  67  98 126  85 121  14 144  96 108 105 162  92 101  76\n",
      "  66  93 123 110  74 124 148 131  77 129  46 113 167 111 165 147  53 160\n",
      "  86 140 122  73 163 109 158  68 145 127  91 104  52 149 106 112  75  54\n",
      "  55  64 142 102  70 146 156 138  95 120  45 166 128 100  69  72  94 164\n",
      " 159  61  84   6 141 130  65  87  88  99 157  18  97  47 139   0 103  90\n",
      "  25  44 125   5  34  89  22 107  79   2  10  19  33  50   3  56  20   4\n",
      "  59  11  27  32 172   8  12  40  15 118 132 135  39 168 117  80 153   7\n",
      "  83  31  24  82 171  36  43   1 154 137  62  37]\n",
      "[-4.37637509e+03 -1.61645161e+03 -1.13777239e+03 -1.11710503e+03\n",
      " -1.07433944e+03 -9.15885783e+02 -7.63499983e+02 -7.09493705e+02\n",
      " -6.23313357e+02 -6.00180696e+02 -5.63264637e+02 -5.40593882e+02\n",
      " -4.72195970e+02 -4.70459457e+02 -3.90380349e+02 -3.67814456e+02\n",
      " -2.83311906e+02 -2.79249057e+02 -2.18579313e+02 -2.12011315e+02\n",
      " -2.06399621e+02 -1.86414282e+02 -1.72513731e+02 -1.15157842e+02\n",
      " -9.10429052e+01 -9.08886675e+01 -7.94085372e+01 -7.25356625e+01\n",
      " -5.04369719e+01 -3.01418334e+01 -2.22176430e+01 -1.86535598e+01\n",
      " -1.64269975e+01 -1.27143049e+01 -1.20649585e+01 -1.13628958e+01\n",
      " -1.06361229e+01 -8.51124224e+00 -4.58020186e+00 -3.52990493e+00\n",
      " -2.66076077e+00 -2.37677076e+00 -1.63135912e+00 -1.51139480e+00\n",
      " -1.41655223e+00 -1.36244136e+00 -1.04300038e+00 -4.50790448e-01\n",
      " -2.95299993e-01 -2.79451785e-01 -1.54529904e-01 -1.31205883e-01\n",
      " -1.24914449e-01 -9.93938733e-02 -6.74205375e-02 -5.18758608e-02\n",
      " -3.67358027e-02 -3.57262075e-02 -3.28887585e-02 -1.86405987e-02\n",
      " -1.58964923e-02 -1.30722114e-02 -8.88158406e-03 -5.98468770e-03\n",
      " -5.61372422e-03 -4.54493115e-03 -3.28602054e-03 -2.36943576e-03\n",
      " -2.26857466e-03 -2.17496749e-03 -1.17092622e-03 -4.18708652e-04\n",
      " -2.01625164e-05 -1.59067338e-06 -1.31772019e-06 -1.06150564e-06\n",
      " -6.13720517e-07 -4.97433024e-07  2.76962911e-08  7.84043778e-08\n",
      "  1.25720331e-07  1.03411338e-06  1.45801129e-06  2.16772553e-06\n",
      "  1.81204516e-03  2.21600993e-03  2.44393413e-03  3.76299412e-03\n",
      "  4.27847958e-03  6.00772069e-03  1.06299931e-02  1.06315088e-02\n",
      "  1.07685137e-02  1.27031864e-02  1.44046122e-02  1.91938830e-02\n",
      "  1.92912539e-02  2.05792844e-02  2.39880635e-02  2.54081011e-02\n",
      "  2.99087012e-02  3.78742072e-02  4.56410535e-02  7.00845853e-02\n",
      "  9.34922696e-02  1.03259516e-01  1.73504592e-01  1.74804204e-01\n",
      "  1.93841879e-01  2.19115734e-01  2.29560331e-01  2.35409399e-01\n",
      "  2.56221181e-01  2.79090999e-01  3.54739139e-01  3.63396371e-01\n",
      "  3.72514903e-01  5.93424618e-01  1.19608859e+00  1.22519156e+00\n",
      "  1.76180667e+00  2.05200499e+00  2.50609801e+00  2.64518071e+00\n",
      "  2.67991841e+00  3.58250275e+00  3.68699932e+00  5.22682286e+00\n",
      "  5.26755708e+00  6.53481700e+00  1.01712728e+01  1.48656708e+01\n",
      "  1.51868764e+01  1.80960644e+01  1.83294126e+01  2.52692014e+01\n",
      "  2.76100392e+01  2.90081189e+01  3.22346113e+01  3.45063483e+01\n",
      "  3.83734786e+01  5.91355501e+01  6.34662402e+01  7.70524710e+01\n",
      "  7.71784564e+01  8.96023981e+01  9.34311556e+01  1.28119480e+02\n",
      "  1.40869526e+02  1.43941987e+02  1.64234505e+02  1.78219548e+02\n",
      "  2.07998882e+02  2.59944470e+02  2.92861981e+02  3.00801307e+02\n",
      "  3.18214165e+02  3.73222906e+02  3.82268718e+02  3.90890777e+02\n",
      "  4.02535542e+02  4.36418731e+02  4.49339055e+02  4.53793399e+02\n",
      "  4.68293672e+02  4.94193310e+02  5.40156814e+02  5.71983486e+02\n",
      "  7.58441766e+02  1.32727156e+03  1.82530490e+03  1.93354764e+03\n",
      "  2.21533873e+03  4.01089344e+03]\n",
      "训练集结果： -3.5404747502831535\n",
      "测试集结果： -85805.85150006511\n"
     ]
    }
   ],
   "source": [
    "# Embedded\n",
    "# 基于惩罚项的特征选择法\n",
    "# Lasso(l1)和Ridge(l2)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha=5)\n",
    "ridge.fit(train,target_train)\n",
    "\n",
    "Ridge(alpha=5, copy_X=True, fit_intercept=True, max_iter=None, normalize=False,\n",
    "      random_state=None, solver='auto', tol=0.001)\n",
    "\n",
    "# 特征系数排序\n",
    "coefSort = ridge.coef_.argsort()\n",
    "print(coefSort)\n",
    "\n",
    "\n",
    "# 特征系数\n",
    "featureCoefSore=ridge.coef_[coefSort]\n",
    "print(featureCoefSore)\n",
    "\n",
    "\n",
    "select_columns = [f for f, s in zip(train.columns, featureCoefSore) if abs(s)> 0.0000005 ] \n",
    "# 选择绝对值大于0.0000005的特征\n",
    "\n",
    "new_train = train[select_columns]\n",
    "new_test = test[select_columns]\n",
    "# Lasso回归\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso=Lasso(alpha=0.1)\n",
    "lasso.fit(new_train,target_train)\n",
    "#预测测试集和训练集结果\n",
    "y_pred_train=lasso.predict(new_train)\n",
    "\n",
    "y_pred_test=lasso.predict(new_test)\n",
    "\n",
    "#对比结果\n",
    "from sklearn.metrics import r2_score\n",
    "score_train=r2_score(y_pred_train,target_train)\n",
    "print(\"训练集结果：\",score_train)\n",
    "score_test=r2_score(y_pred_test, target_test)\n",
    "print(\"测试集结果：\",score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于树模型的特征选择法\n",
    "### 随机森林 平均不纯度减少（mean decrease impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.1748, 'area'), (0.0593, 'houseFloor'), (0.0498, 'tradeMeanPrice'), (0.0374, 'tradeMeanPrice_totalFloor_cluster_mean'), (0.0314, 'count_communityName_newWorkers'), (0.0293, 'pv'), (0.0266, 'remainNewNum_buildYear_cluster_mean'), (0.0234, 'totalTradeArea'), (0.0223, 'lookNum'), (0.0215, 'day'), (0.0205, 'com_area_mean'), (0.0195, 'tradeNewMeanPrice_communityName_cluster_mean'), (0.0188, 'all_SchoolNum_communityName_cluster_mean'), (0.0177, 'sale_ratio'), (0.0175, 'Room_Bath'), (0.0174, 'lookNum_totalFloor_cluster_mean'), (0.0167, 'landTotalPrice_plate_cluster_mean'), (0.0165, 'trainsportNum_ratio'), (0.0163, 'saleSecHouseNum'), (0.0154, 'Room'), (0.0139, 'tradeMeanPrice_plate_cluster_mean'), (0.0137, 'all_hospitalNum_communityName_cluster_mean'), (0.0133, 'totalFloor'), (0.0122, 'all_hospitalNum_totalFloor_cluster_mean'), (0.0122, 'all_hospitalNum_buildYear_cluster_mean'), (0.0118, 'tradeMeanPrice_buildYear_cluster_mean'), (0.0116, 'tradeMeanPrice_communityName_cluster_mean'), (0.0111, 'totalWorkers_plate_cluster_mean'), (0.0108, 'tradeSecNum_communityName_cluster_mean'), (0.0108, 'remainNewNum'), (0.0104, 'supplyNewNum'), (0.0103, 'remainNewNum_communityName_cluster_mean'), (0.01, 'totalWorkers_totalFloor_cluster_mean'), (0.01, 'landTotalPrice_buildYear_cluster_mean'), (0.0088, 'tradeLandArea'), (0.0086, 'residentPopulation_totalFloor_cluster_mean'), (0.0085, 'plate_year_std'), (0.0084, 'trainsportNum_totalFloor_cluster_mean'), (0.0077, 'totalNewTradeArea_buildYear_cluster_mean'), (0.0073, 'all_SchoolNum_plate_cluster_mean'), (0.0065, 'totalWorkers_communityName_cluster_mean'), (0.0064, 'remainNewNum_totalFloor_cluster_mean'), (0.0063, 'tradeNewMeanPrice_totalFloor_cluster_mean'), (0.0063, 'sale_newworker_differ'), (0.0061, 'Hall'), (0.006, 'tradeNewMeanPrice'), (0.0059, 'otherNum_totalFloor_cluster_mean'), (0.0057, 'trainsportNum_buildYear_cluster_mean'), (0.0056, 'plate'), (0.0054, 'tradeNewNum'), (0.0052, 'com_area_std'), (0.0047, 'totalNewTradeArea_region_cluster_mean'), (0.0045, 'trainsportNum_region_cluster_mean'), (0.0039, 'totalNewTradeMoney'), (0.0035, 'plate_area_mean'), (0.0033, 'month'), (0.0031, 'all_mall_communityName_cluster_mean'), (0.0024, 'tradeNewMeanPrice_plate_cluster_mean'), (0.0022, 'comm_price_mean'), (0.002, 'totalNewTradeArea'), (0.0019, 'otherNum_plate_cluster_mean'), (0.0019, 'all_mall_plate_cluster_mean'), (0.0018, 'Bath'), (0.0017, 'comm_plate_year_diff'), (0.0017, 'all_mall_buildYear_cluster_mean'), (0.0016, 'tradeNewMeanPrice_region_cluster_mean'), (0.0013, 'trainsportNum_communityName_cluster_mean'), (0.0013, 'totalWorkers'), (0.0012, 'plate_area_std'), (0.0012, 'communityName'), (0.0011, 'comm_price_std'), (0.0011, 'all_SchoolNum_buildYear_cluster_mean'), (0.001, 'residentPopulation'), (0.001, 'count_communityName'), (0.0009, 'tradeSecNum_buildYear_cluster_mean'), (0.0009, 'totalWorkers_buildYear_cluster_mean'), (0.0009, 'all_SchoolNum'), (0.0008, 'count_totalFloor'), (0.0008, 'com_all_mall'), (0.0008, 'buildYear'), (0.0007, 'tradeSecNum_plate_cluster_mean'), (0.0006, 'totalNewTradeMoney_communityName_cluster_mean'), (0.0006, 'landMeanPrice_totalFloor_cluster_mean'), (0.0006, 'landMeanPrice_buildYear_cluster_mean'), (0.0005, 'trainsportNum_plate_cluster_mean'), (0.0005, 'plate_price_std'), (0.0005, 'other_ratio'), (0.0005, 'otherNum_communityName_cluster_mean'), (0.0005, 'otherNum_buildYear_cluster_mean'), (0.0004, 'tradeSecNum_region_cluster_mean'), (0.0004, 'tradeNewMeanPrice_buildYear_cluster_mean'), (0.0004, 'remainNewNum_region_cluster_mean'), (0.0004, 'count_buildYear'), (0.0004, 'all_hospitalNum'), (0.0004, 'all_SchoolNum_totalFloor_cluster_mean'), (0.0003, 'tradeSecNum_totalFloor_cluster_mean'), (0.0003, 'tradeSecNum'), (0.0003, 'tradeNewNum_communityName_cluster_mean'), (0.0003, 'tradeMeanPrice_houseDecoration_cluster_mean'), (0.0003, 'totalTradeMoney'), (0.0003, 'residentPopulation_communityName_cluster_mean'), (0.0003, 'residentPopulation_buildYear_cluster_mean'), (0.0003, 'plate_price_mean'), (0.0003, 'landTotalPrice_totalFloor_cluster_mean'), (0.0003, 'houseToward'), (0.0003, 'all_mall_totalFloor_cluster_mean'), (0.0002, 'uv'), (0.0002, 'trainsportNum'), (0.0002, 'tradeNewMeanPrice_houseDecoration_cluster_mean'), (0.0002, 'totalWorkers_region_cluster_mean'), (0.0002, 'totalWorkers_houseDecoration_cluster_mean'), (0.0002, 'totalNewTradeMoney_totalFloor_cluster_mean'), (0.0002, 'totalNewTradeMoney_buildYear_cluster_mean'), (0.0002, 'totalNewTradeArea_totalFloor_cluster_mean'), (0.0002, 'totalNewTradeArea_plate_cluster_mean'), (0.0002, 'totalNewTradeArea_communityName_cluster_mean'), (0.0002, 'remainNewNum_plate_cluster_mean'), (0.0002, 'count_communityName_totalTradeMoney'), (0.0002, 'count_communityName_totalFloor'), (0.0002, 'all_mall_houseDecoration_cluster_mean'), (0.0002, 'all_mall'), (0.0002, 'all_SchoolNum_region_cluster_mean'), (0.0001, 'tradeSecNum_houseDecoration_cluster_mean'), (0.0001, 'tradeNewNum_totalFloor_cluster_mean'), (0.0001, 'tradeNewNum_plate_cluster_mean'), (0.0001, 'tradeNewNum_buildYear_cluster_mean'), (0.0001, 'tradeMeanPrice_region_cluster_mean'), (0.0001, 'totalNewTradeMoney_region_cluster_mean'), (0.0001, 'totalNewTradeMoney_plate_cluster_mean'), (0.0001, 'totalNewTradeArea_houseDecoration_cluster_mean'), (0.0001, 'supplyLandArea'), (0.0001, 'residentPopulation_plate_cluster_mean'), (0.0001, 'rentType'), (0.0001, 'otherNum_region_cluster_mean'), (0.0001, 'otherNum'), (0.0001, 'newWorkers_communityName_cluster_mean'), (0.0001, 'newWorkers_buildYear_cluster_mean'), (0.0001, 'landTotalPrice_communityName_cluster_mean'), (0.0001, 'landMeanPrice_region_cluster_mean'), (0.0001, 'landMeanPrice_plate_cluster_mean'), (0.0001, 'landMeanPrice_houseDecoration_cluster_mean'), (0.0001, 'landMeanPrice_communityName_cluster_mean'), (0.0001, 'all_mall_region_cluster_mean'), (0.0001, 'all_hospitalNum_plate_cluster_mean'), (0.0001, 'all_SchoolNum_houseDecoration_cluster_mean'), (0.0, 'trainsportNum_houseDecoration_cluster_mean'), (0.0, 'tradeNewNum_region_cluster_mean'), (0.0, 'tradeNewNum_houseDecoration_cluster_mean'), (0.0, 'tradeLandNum'), (0.0, 'totalNewTradeMoney_houseDecoration_cluster_mean'), (0.0, 'supplyLandNum'), (0.0, 'residentPopulation_region_cluster_mean'), (0.0, 'residentPopulation_houseDecoration_cluster_mean'), (0.0, 'remainNewNum_houseDecoration_cluster_mean'), (0.0, 'region'), (0.0, 'otherNum_houseDecoration_cluster_mean'), (0.0, 'newWorkers_totalFloor_cluster_mean'), (0.0, 'newWorkers_region_cluster_mean'), (0.0, 'newWorkers_plate_cluster_mean'), (0.0, 'newWorkers_houseDecoration_cluster_mean'), (0.0, 'newWorkers'), (0.0, 'lookNum_region_cluster_mean'), (0.0, 'lookNum_plate_cluster_mean'), (0.0, 'lookNum_houseDecoration_cluster_mean'), (0.0, 'lookNum_communityName_cluster_mean'), (0.0, 'lookNum_buildYear_cluster_mean'), (0.0, 'landTotalPrice_region_cluster_mean'), (0.0, 'landTotalPrice_houseDecoration_cluster_mean'), (0.0, 'landTotalPrice'), (0.0, 'landMeanPrice'), (0.0, 'houseDecoration'), (0.0, 'cluster'), (0.0, 'all_hospitalNum_region_cluster_mean'), (0.0, 'all_hospitalNum_houseDecoration_cluster_mean')]\n",
      "训练集结果： -3.577470611494576\n",
      "测试集结果： -84922.2580444392\n"
     ]
    }
   ],
   "source": [
    "# Embedded\n",
    "# 基于树模型的特征选择法\n",
    "# 随机森林 平均不纯度减少（mean decrease impurity\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "# 训练随机森林模型，并通过feature_importances_属性获取每个特征的重要性分数。rf = RandomForestRegressor()\n",
    "rf.fit(train,target_train)\n",
    "print(\"Features sorted by their score:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), train.columns),\n",
    "             reverse=True))\n",
    "\n",
    "select_columns = [f for f, s in zip(train.columns, rf.feature_importances_) if abs(s)> 0.00005 ] \n",
    "# 选择绝对值大于0.00005的特征\n",
    "\n",
    "new_train = train[select_columns]\n",
    "new_test = test[select_columns]\n",
    "\n",
    "# Lasso回归\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso=Lasso(alpha=0.1)\n",
    "lasso.fit(new_train,target_train)\n",
    "#预测测试集和训练集结果\n",
    "y_pred_train=lasso.predict(new_train)\n",
    "\n",
    "y_pred_test=lasso.predict(new_test)\n",
    "\n",
    "#对比结果\n",
    "from sklearn.metrics import r2_score\n",
    "score_train=r2_score(y_pred_train,target_train)\n",
    "print(\"训练集结果：\",score_train)\n",
    "score_test=r2_score(y_pred_test, target_test)\n",
    "print(\"测试集结果：\",score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train\n",
    "X_test = test\n",
    "Y_train = target_train\n",
    "Y_test = target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>rentType</th>\n",
       "      <th>houseFloor</th>\n",
       "      <th>totalFloor</th>\n",
       "      <th>houseToward</th>\n",
       "      <th>houseDecoration</th>\n",
       "      <th>communityName</th>\n",
       "      <th>region</th>\n",
       "      <th>plate</th>\n",
       "      <th>buildYear</th>\n",
       "      <th>saleSecHouseNum</th>\n",
       "      <th>totalTradeMoney</th>\n",
       "      <th>totalTradeArea</th>\n",
       "      <th>tradeMeanPrice</th>\n",
       "      <th>tradeSecNum</th>\n",
       "      <th>totalNewTradeMoney</th>\n",
       "      <th>totalNewTradeArea</th>\n",
       "      <th>tradeNewMeanPrice</th>\n",
       "      <th>tradeNewNum</th>\n",
       "      <th>remainNewNum</th>\n",
       "      <th>supplyNewNum</th>\n",
       "      <th>supplyLandNum</th>\n",
       "      <th>supplyLandArea</th>\n",
       "      <th>tradeLandNum</th>\n",
       "      <th>tradeLandArea</th>\n",
       "      <th>landTotalPrice</th>\n",
       "      <th>landMeanPrice</th>\n",
       "      <th>totalWorkers</th>\n",
       "      <th>newWorkers</th>\n",
       "      <th>residentPopulation</th>\n",
       "      <th>pv</th>\n",
       "      <th>uv</th>\n",
       "      <th>lookNum</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>Room</th>\n",
       "      <th>Hall</th>\n",
       "      <th>Bath</th>\n",
       "      <th>Room_Bath</th>\n",
       "      <th>trainsportNum</th>\n",
       "      <th>all_SchoolNum</th>\n",
       "      <th>all_hospitalNum</th>\n",
       "      <th>all_mall</th>\n",
       "      <th>otherNum</th>\n",
       "      <th>count_communityName</th>\n",
       "      <th>count_buildYear</th>\n",
       "      <th>count_totalFloor</th>\n",
       "      <th>count_communityName_totalFloor</th>\n",
       "      <th>count_communityName_newWorkers</th>\n",
       "      <th>count_communityName_totalTradeMoney</th>\n",
       "      <th>com_area_mean</th>\n",
       "      <th>com_area_std</th>\n",
       "      <th>comm_price_mean</th>\n",
       "      <th>comm_price_std</th>\n",
       "      <th>plate_price_mean</th>\n",
       "      <th>plate_price_std</th>\n",
       "      <th>plate_area_mean</th>\n",
       "      <th>plate_area_std</th>\n",
       "      <th>plate_year_std</th>\n",
       "      <th>comm_plate_year_diff</th>\n",
       "      <th>trainsportNum_ratio</th>\n",
       "      <th>com_all_mall</th>\n",
       "      <th>other_ratio</th>\n",
       "      <th>sale_ratio</th>\n",
       "      <th>sale_newworker_differ</th>\n",
       "      <th>cluster</th>\n",
       "      <th>tradeMeanPrice_totalFloor_cluster_mean</th>\n",
       "      <th>tradeSecNum_totalFloor_cluster_mean</th>\n",
       "      <th>totalNewTradeMoney_totalFloor_cluster_mean</th>\n",
       "      <th>totalNewTradeArea_totalFloor_cluster_mean</th>\n",
       "      <th>tradeNewMeanPrice_totalFloor_cluster_mean</th>\n",
       "      <th>tradeNewNum_totalFloor_cluster_mean</th>\n",
       "      <th>remainNewNum_totalFloor_cluster_mean</th>\n",
       "      <th>landTotalPrice_totalFloor_cluster_mean</th>\n",
       "      <th>landMeanPrice_totalFloor_cluster_mean</th>\n",
       "      <th>totalWorkers_totalFloor_cluster_mean</th>\n",
       "      <th>newWorkers_totalFloor_cluster_mean</th>\n",
       "      <th>residentPopulation_totalFloor_cluster_mean</th>\n",
       "      <th>lookNum_totalFloor_cluster_mean</th>\n",
       "      <th>trainsportNum_totalFloor_cluster_mean</th>\n",
       "      <th>all_SchoolNum_totalFloor_cluster_mean</th>\n",
       "      <th>all_hospitalNum_totalFloor_cluster_mean</th>\n",
       "      <th>all_mall_totalFloor_cluster_mean</th>\n",
       "      <th>otherNum_totalFloor_cluster_mean</th>\n",
       "      <th>tradeMeanPrice_houseDecoration_cluster_mean</th>\n",
       "      <th>tradeSecNum_houseDecoration_cluster_mean</th>\n",
       "      <th>totalNewTradeMoney_houseDecoration_cluster_mean</th>\n",
       "      <th>totalNewTradeArea_houseDecoration_cluster_mean</th>\n",
       "      <th>tradeNewMeanPrice_houseDecoration_cluster_mean</th>\n",
       "      <th>tradeNewNum_houseDecoration_cluster_mean</th>\n",
       "      <th>remainNewNum_houseDecoration_cluster_mean</th>\n",
       "      <th>landTotalPrice_houseDecoration_cluster_mean</th>\n",
       "      <th>landMeanPrice_houseDecoration_cluster_mean</th>\n",
       "      <th>totalWorkers_houseDecoration_cluster_mean</th>\n",
       "      <th>newWorkers_houseDecoration_cluster_mean</th>\n",
       "      <th>residentPopulation_houseDecoration_cluster_mean</th>\n",
       "      <th>lookNum_houseDecoration_cluster_mean</th>\n",
       "      <th>trainsportNum_houseDecoration_cluster_mean</th>\n",
       "      <th>all_SchoolNum_houseDecoration_cluster_mean</th>\n",
       "      <th>all_hospitalNum_houseDecoration_cluster_mean</th>\n",
       "      <th>all_mall_houseDecoration_cluster_mean</th>\n",
       "      <th>otherNum_houseDecoration_cluster_mean</th>\n",
       "      <th>tradeMeanPrice_communityName_cluster_mean</th>\n",
       "      <th>tradeSecNum_communityName_cluster_mean</th>\n",
       "      <th>totalNewTradeMoney_communityName_cluster_mean</th>\n",
       "      <th>totalNewTradeArea_communityName_cluster_mean</th>\n",
       "      <th>tradeNewMeanPrice_communityName_cluster_mean</th>\n",
       "      <th>tradeNewNum_communityName_cluster_mean</th>\n",
       "      <th>remainNewNum_communityName_cluster_mean</th>\n",
       "      <th>landTotalPrice_communityName_cluster_mean</th>\n",
       "      <th>landMeanPrice_communityName_cluster_mean</th>\n",
       "      <th>totalWorkers_communityName_cluster_mean</th>\n",
       "      <th>newWorkers_communityName_cluster_mean</th>\n",
       "      <th>residentPopulation_communityName_cluster_mean</th>\n",
       "      <th>lookNum_communityName_cluster_mean</th>\n",
       "      <th>trainsportNum_communityName_cluster_mean</th>\n",
       "      <th>all_SchoolNum_communityName_cluster_mean</th>\n",
       "      <th>all_hospitalNum_communityName_cluster_mean</th>\n",
       "      <th>all_mall_communityName_cluster_mean</th>\n",
       "      <th>otherNum_communityName_cluster_mean</th>\n",
       "      <th>tradeMeanPrice_region_cluster_mean</th>\n",
       "      <th>tradeSecNum_region_cluster_mean</th>\n",
       "      <th>totalNewTradeMoney_region_cluster_mean</th>\n",
       "      <th>totalNewTradeArea_region_cluster_mean</th>\n",
       "      <th>tradeNewMeanPrice_region_cluster_mean</th>\n",
       "      <th>tradeNewNum_region_cluster_mean</th>\n",
       "      <th>remainNewNum_region_cluster_mean</th>\n",
       "      <th>landTotalPrice_region_cluster_mean</th>\n",
       "      <th>landMeanPrice_region_cluster_mean</th>\n",
       "      <th>totalWorkers_region_cluster_mean</th>\n",
       "      <th>newWorkers_region_cluster_mean</th>\n",
       "      <th>residentPopulation_region_cluster_mean</th>\n",
       "      <th>lookNum_region_cluster_mean</th>\n",
       "      <th>trainsportNum_region_cluster_mean</th>\n",
       "      <th>all_SchoolNum_region_cluster_mean</th>\n",
       "      <th>all_hospitalNum_region_cluster_mean</th>\n",
       "      <th>all_mall_region_cluster_mean</th>\n",
       "      <th>otherNum_region_cluster_mean</th>\n",
       "      <th>tradeMeanPrice_plate_cluster_mean</th>\n",
       "      <th>tradeSecNum_plate_cluster_mean</th>\n",
       "      <th>totalNewTradeMoney_plate_cluster_mean</th>\n",
       "      <th>totalNewTradeArea_plate_cluster_mean</th>\n",
       "      <th>tradeNewMeanPrice_plate_cluster_mean</th>\n",
       "      <th>tradeNewNum_plate_cluster_mean</th>\n",
       "      <th>remainNewNum_plate_cluster_mean</th>\n",
       "      <th>landTotalPrice_plate_cluster_mean</th>\n",
       "      <th>landMeanPrice_plate_cluster_mean</th>\n",
       "      <th>totalWorkers_plate_cluster_mean</th>\n",
       "      <th>newWorkers_plate_cluster_mean</th>\n",
       "      <th>residentPopulation_plate_cluster_mean</th>\n",
       "      <th>lookNum_plate_cluster_mean</th>\n",
       "      <th>trainsportNum_plate_cluster_mean</th>\n",
       "      <th>all_SchoolNum_plate_cluster_mean</th>\n",
       "      <th>all_hospitalNum_plate_cluster_mean</th>\n",
       "      <th>all_mall_plate_cluster_mean</th>\n",
       "      <th>otherNum_plate_cluster_mean</th>\n",
       "      <th>tradeMeanPrice_buildYear_cluster_mean</th>\n",
       "      <th>tradeSecNum_buildYear_cluster_mean</th>\n",
       "      <th>totalNewTradeMoney_buildYear_cluster_mean</th>\n",
       "      <th>totalNewTradeArea_buildYear_cluster_mean</th>\n",
       "      <th>tradeNewMeanPrice_buildYear_cluster_mean</th>\n",
       "      <th>tradeNewNum_buildYear_cluster_mean</th>\n",
       "      <th>remainNewNum_buildYear_cluster_mean</th>\n",
       "      <th>landTotalPrice_buildYear_cluster_mean</th>\n",
       "      <th>landMeanPrice_buildYear_cluster_mean</th>\n",
       "      <th>totalWorkers_buildYear_cluster_mean</th>\n",
       "      <th>newWorkers_buildYear_cluster_mean</th>\n",
       "      <th>residentPopulation_buildYear_cluster_mean</th>\n",
       "      <th>lookNum_buildYear_cluster_mean</th>\n",
       "      <th>trainsportNum_buildYear_cluster_mean</th>\n",
       "      <th>all_SchoolNum_buildYear_cluster_mean</th>\n",
       "      <th>all_hospitalNum_buildYear_cluster_mean</th>\n",
       "      <th>all_mall_buildYear_cluster_mean</th>\n",
       "      <th>otherNum_buildYear_cluster_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>646</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1994</td>\n",
       "      <td>0</td>\n",
       "      <td>19.787104</td>\n",
       "      <td>9.440703</td>\n",
       "      <td>10.346512</td>\n",
       "      <td>158</td>\n",
       "      <td>17.084842</td>\n",
       "      <td>6.622736</td>\n",
       "      <td>10.463465</td>\n",
       "      <td>5</td>\n",
       "      <td>5.370638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.047704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.967047</td>\n",
       "      <td>11.069307</td>\n",
       "      <td>8.804775</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.861430</td>\n",
       "      <td>2.914163</td>\n",
       "      <td>3.955609</td>\n",
       "      <td>3.118232</td>\n",
       "      <td>7.035898</td>\n",
       "      <td>15</td>\n",
       "      <td>5659</td>\n",
       "      <td>809</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>57.666667</td>\n",
       "      <td>8.005950</td>\n",
       "      <td>56011.618848</td>\n",
       "      <td>11432.901072</td>\n",
       "      <td>95866.315739</td>\n",
       "      <td>103261.303345</td>\n",
       "      <td>67.563758</td>\n",
       "      <td>87.878800</td>\n",
       "      <td>8.720308</td>\n",
       "      <td>-6</td>\n",
       "      <td>0.009</td>\n",
       "      <td>43.655253</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.014</td>\n",
       "      <td>429</td>\n",
       "      <td>0</td>\n",
       "      <td>37234.390317</td>\n",
       "      <td>232.448845</td>\n",
       "      <td>2.134405e+08</td>\n",
       "      <td>4719.924092</td>\n",
       "      <td>38813.883094</td>\n",
       "      <td>41.143564</td>\n",
       "      <td>305.674917</td>\n",
       "      <td>3.745285e+07</td>\n",
       "      <td>265.775476</td>\n",
       "      <td>77849.013201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>330429.646865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.420387</td>\n",
       "      <td>3.315204</td>\n",
       "      <td>3.106066</td>\n",
       "      <td>2.327820</td>\n",
       "      <td>5.084342</td>\n",
       "      <td>40725.102969</td>\n",
       "      <td>229.518102</td>\n",
       "      <td>1.940921e+08</td>\n",
       "      <td>3806.600763</td>\n",
       "      <td>44245.116035</td>\n",
       "      <td>31.333564</td>\n",
       "      <td>271.877668</td>\n",
       "      <td>2.935649e+07</td>\n",
       "      <td>277.134168</td>\n",
       "      <td>78607.926551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>287437.223218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.608225</td>\n",
       "      <td>4.222785</td>\n",
       "      <td>2.883093</td>\n",
       "      <td>1.945022</td>\n",
       "      <td>4.747559</td>\n",
       "      <td>31079.504539</td>\n",
       "      <td>173.800000</td>\n",
       "      <td>3.818973e+07</td>\n",
       "      <td>1001.900000</td>\n",
       "      <td>35419.551532</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>217.400000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8498.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>428071.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.861430</td>\n",
       "      <td>2.914163</td>\n",
       "      <td>3.955609</td>\n",
       "      <td>3.118232</td>\n",
       "      <td>7.035898</td>\n",
       "      <td>41476.021283</td>\n",
       "      <td>321.679504</td>\n",
       "      <td>1.724097e+08</td>\n",
       "      <td>2949.490126</td>\n",
       "      <td>62580.585009</td>\n",
       "      <td>22.496382</td>\n",
       "      <td>216.609837</td>\n",
       "      <td>2.676943e+07</td>\n",
       "      <td>122.363175</td>\n",
       "      <td>151335.517601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>344045.843493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.273148</td>\n",
       "      <td>4.502851</td>\n",
       "      <td>3.550913</td>\n",
       "      <td>2.196679</td>\n",
       "      <td>6.243596</td>\n",
       "      <td>34773.122085</td>\n",
       "      <td>193.143013</td>\n",
       "      <td>1.158908e+08</td>\n",
       "      <td>2217.561135</td>\n",
       "      <td>44129.109313</td>\n",
       "      <td>14.838428</td>\n",
       "      <td>280.707424</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7763.432314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>406501.259825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.489401</td>\n",
       "      <td>2.629209</td>\n",
       "      <td>3.956709</td>\n",
       "      <td>2.870786</td>\n",
       "      <td>6.609019</td>\n",
       "      <td>38386.178484</td>\n",
       "      <td>215.547458</td>\n",
       "      <td>2.051141e+08</td>\n",
       "      <td>4220.866016</td>\n",
       "      <td>43980.696790</td>\n",
       "      <td>33.438267</td>\n",
       "      <td>314.098923</td>\n",
       "      <td>3.084462e+07</td>\n",
       "      <td>317.416683</td>\n",
       "      <td>57279.348109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>280336.653143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.524240</td>\n",
       "      <td>4.023809</td>\n",
       "      <td>2.670093</td>\n",
       "      <td>1.931252</td>\n",
       "      <td>4.448482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3470</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1986</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899212</td>\n",
       "      <td>8.937729</td>\n",
       "      <td>10.961632</td>\n",
       "      <td>113</td>\n",
       "      <td>16.959709</td>\n",
       "      <td>5.484797</td>\n",
       "      <td>11.479080</td>\n",
       "      <td>2</td>\n",
       "      <td>4.094345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.701527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.641799</td>\n",
       "      <td>9.258178</td>\n",
       "      <td>7.192182</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6.533145</td>\n",
       "      <td>2.499231</td>\n",
       "      <td>3.019493</td>\n",
       "      <td>1.399270</td>\n",
       "      <td>4.335986</td>\n",
       "      <td>21</td>\n",
       "      <td>320</td>\n",
       "      <td>1362</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>39.238095</td>\n",
       "      <td>7.974364</td>\n",
       "      <td>140701.447242</td>\n",
       "      <td>25959.585233</td>\n",
       "      <td>154231.435167</td>\n",
       "      <td>144059.477704</td>\n",
       "      <td>53.939891</td>\n",
       "      <td>33.509477</td>\n",
       "      <td>14.759094</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.047</td>\n",
       "      <td>29.384662</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.045</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>44629.869276</td>\n",
       "      <td>182.434742</td>\n",
       "      <td>1.662570e+08</td>\n",
       "      <td>2510.731455</td>\n",
       "      <td>48701.681393</td>\n",
       "      <td>18.217840</td>\n",
       "      <td>187.546479</td>\n",
       "      <td>2.283223e+07</td>\n",
       "      <td>254.032348</td>\n",
       "      <td>91834.026291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>242360.642254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.068509</td>\n",
       "      <td>3.548384</td>\n",
       "      <td>2.467506</td>\n",
       "      <td>1.587749</td>\n",
       "      <td>4.071131</td>\n",
       "      <td>40725.102969</td>\n",
       "      <td>229.518102</td>\n",
       "      <td>1.940921e+08</td>\n",
       "      <td>3806.600763</td>\n",
       "      <td>44245.116035</td>\n",
       "      <td>31.333564</td>\n",
       "      <td>271.877668</td>\n",
       "      <td>2.935649e+07</td>\n",
       "      <td>277.134168</td>\n",
       "      <td>78607.926551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>287437.223218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.608225</td>\n",
       "      <td>4.222785</td>\n",
       "      <td>2.883093</td>\n",
       "      <td>1.945022</td>\n",
       "      <td>4.747559</td>\n",
       "      <td>53739.820320</td>\n",
       "      <td>104.266667</td>\n",
       "      <td>4.626383e+08</td>\n",
       "      <td>4801.333333</td>\n",
       "      <td>96091.755367</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>186.733333</td>\n",
       "      <td>2.903000e+07</td>\n",
       "      <td>1442.057649</td>\n",
       "      <td>120755.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>309216.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.533145</td>\n",
       "      <td>2.499231</td>\n",
       "      <td>3.019493</td>\n",
       "      <td>1.399270</td>\n",
       "      <td>4.335986</td>\n",
       "      <td>50724.464178</td>\n",
       "      <td>164.072800</td>\n",
       "      <td>4.091667e+07</td>\n",
       "      <td>429.828685</td>\n",
       "      <td>17624.818421</td>\n",
       "      <td>2.335024</td>\n",
       "      <td>83.196306</td>\n",
       "      <td>3.416624e+06</td>\n",
       "      <td>220.008656</td>\n",
       "      <td>64477.336472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>214085.011590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.889478</td>\n",
       "      <td>3.714923</td>\n",
       "      <td>2.643469</td>\n",
       "      <td>0.963086</td>\n",
       "      <td>3.326727</td>\n",
       "      <td>52402.701262</td>\n",
       "      <td>160.326484</td>\n",
       "      <td>1.653230e+08</td>\n",
       "      <td>1722.625571</td>\n",
       "      <td>49717.365511</td>\n",
       "      <td>9.246575</td>\n",
       "      <td>82.751142</td>\n",
       "      <td>8.272968e+06</td>\n",
       "      <td>461.296022</td>\n",
       "      <td>81309.940639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>305442.808219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.207264</td>\n",
       "      <td>3.946431</td>\n",
       "      <td>3.647401</td>\n",
       "      <td>1.115555</td>\n",
       "      <td>4.408551</td>\n",
       "      <td>50108.594319</td>\n",
       "      <td>239.519231</td>\n",
       "      <td>1.181157e+08</td>\n",
       "      <td>1290.584615</td>\n",
       "      <td>43857.451243</td>\n",
       "      <td>7.357692</td>\n",
       "      <td>122.219231</td>\n",
       "      <td>7.717346e+06</td>\n",
       "      <td>333.219172</td>\n",
       "      <td>200760.196154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>216132.688462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.536364</td>\n",
       "      <td>4.198835</td>\n",
       "      <td>2.566916</td>\n",
       "      <td>1.579720</td>\n",
       "      <td>4.872755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1595</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "      <td>20.234430</td>\n",
       "      <td>9.786235</td>\n",
       "      <td>10.448280</td>\n",
       "      <td>199</td>\n",
       "      <td>21.246762</td>\n",
       "      <td>10.451927</td>\n",
       "      <td>10.794885</td>\n",
       "      <td>301</td>\n",
       "      <td>6.011267</td>\n",
       "      <td>5.918894</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.442452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.014670</td>\n",
       "      <td>10.328167</td>\n",
       "      <td>7.902857</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.265734</td>\n",
       "      <td>0.685633</td>\n",
       "      <td>1.106628</td>\n",
       "      <td>1.833608</td>\n",
       "      <td>2.839831</td>\n",
       "      <td>15</td>\n",
       "      <td>5659</td>\n",
       "      <td>3553</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>72.866667</td>\n",
       "      <td>23.191337</td>\n",
       "      <td>64715.839564</td>\n",
       "      <td>83080.341652</td>\n",
       "      <td>74449.615731</td>\n",
       "      <td>83069.250127</td>\n",
       "      <td>74.935159</td>\n",
       "      <td>42.805242</td>\n",
       "      <td>9.095648</td>\n",
       "      <td>-12</td>\n",
       "      <td>0.016</td>\n",
       "      <td>20.169689</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.031</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>35171.928027</td>\n",
       "      <td>245.471233</td>\n",
       "      <td>2.657397e+08</td>\n",
       "      <td>5741.705284</td>\n",
       "      <td>44279.017722</td>\n",
       "      <td>49.390998</td>\n",
       "      <td>414.180039</td>\n",
       "      <td>4.973183e+07</td>\n",
       "      <td>486.120865</td>\n",
       "      <td>61481.230137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>323437.272407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.659887</td>\n",
       "      <td>3.490074</td>\n",
       "      <td>3.150568</td>\n",
       "      <td>2.272588</td>\n",
       "      <td>5.257058</td>\n",
       "      <td>41286.309465</td>\n",
       "      <td>218.818389</td>\n",
       "      <td>1.770842e+08</td>\n",
       "      <td>3310.516500</td>\n",
       "      <td>47866.995252</td>\n",
       "      <td>26.746852</td>\n",
       "      <td>249.648285</td>\n",
       "      <td>4.677131e+07</td>\n",
       "      <td>383.161679</td>\n",
       "      <td>85574.482306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>282260.154472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.634353</td>\n",
       "      <td>3.769083</td>\n",
       "      <td>2.692437</td>\n",
       "      <td>1.911154</td>\n",
       "      <td>4.726214</td>\n",
       "      <td>32511.713706</td>\n",
       "      <td>171.636364</td>\n",
       "      <td>4.766587e+08</td>\n",
       "      <td>10247.000000</td>\n",
       "      <td>45747.191029</td>\n",
       "      <td>94.727273</td>\n",
       "      <td>399.727273</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>210433.818182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>193286.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.096501</td>\n",
       "      <td>1.892693</td>\n",
       "      <td>1.115730</td>\n",
       "      <td>1.836681</td>\n",
       "      <td>3.127984</td>\n",
       "      <td>31226.586754</td>\n",
       "      <td>218.058221</td>\n",
       "      <td>2.900306e+08</td>\n",
       "      <td>6140.786308</td>\n",
       "      <td>30628.396982</td>\n",
       "      <td>57.154191</td>\n",
       "      <td>259.392194</td>\n",
       "      <td>1.657321e+07</td>\n",
       "      <td>278.448139</td>\n",
       "      <td>156349.654511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>208959.486244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.592588</td>\n",
       "      <td>0.721673</td>\n",
       "      <td>2.576660</td>\n",
       "      <td>2.143895</td>\n",
       "      <td>4.067558</td>\n",
       "      <td>32640.334288</td>\n",
       "      <td>182.613757</td>\n",
       "      <td>4.813406e+08</td>\n",
       "      <td>10349.536155</td>\n",
       "      <td>45433.926056</td>\n",
       "      <td>94.650794</td>\n",
       "      <td>461.689594</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>240414.003527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>163120.816578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.188203</td>\n",
       "      <td>0.666448</td>\n",
       "      <td>1.068570</td>\n",
       "      <td>1.776886</td>\n",
       "      <td>2.793112</td>\n",
       "      <td>38386.178484</td>\n",
       "      <td>215.547458</td>\n",
       "      <td>2.051141e+08</td>\n",
       "      <td>4220.866016</td>\n",
       "      <td>43980.696790</td>\n",
       "      <td>33.438267</td>\n",
       "      <td>314.098923</td>\n",
       "      <td>3.084462e+07</td>\n",
       "      <td>317.416683</td>\n",
       "      <td>57279.348109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>280336.653143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.524240</td>\n",
       "      <td>4.023809</td>\n",
       "      <td>2.670093</td>\n",
       "      <td>1.931252</td>\n",
       "      <td>4.448482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2466</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>1957</td>\n",
       "      <td>15</td>\n",
       "      <td>20.007377</td>\n",
       "      <td>9.157393</td>\n",
       "      <td>10.850109</td>\n",
       "      <td>169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.815891</td>\n",
       "      <td>4.718499</td>\n",
       "      <td>11.498877</td>\n",
       "      <td>5.683580</td>\n",
       "      <td>4.077537</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.144510</td>\n",
       "      <td>5.921589</td>\n",
       "      <td>2.516764</td>\n",
       "      <td>0.500618</td>\n",
       "      <td>1.940400</td>\n",
       "      <td>56</td>\n",
       "      <td>227</td>\n",
       "      <td>2730</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>35.839286</td>\n",
       "      <td>18.444784</td>\n",
       "      <td>169607.758678</td>\n",
       "      <td>78663.619452</td>\n",
       "      <td>142872.849542</td>\n",
       "      <td>97885.206437</td>\n",
       "      <td>46.166352</td>\n",
       "      <td>24.522229</td>\n",
       "      <td>14.789971</td>\n",
       "      <td>-20</td>\n",
       "      <td>0.028</td>\n",
       "      <td>27.533977</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.154</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34434.715836</td>\n",
       "      <td>235.380610</td>\n",
       "      <td>5.689525e+08</td>\n",
       "      <td>12210.005386</td>\n",
       "      <td>39370.958305</td>\n",
       "      <td>107.405745</td>\n",
       "      <td>627.689408</td>\n",
       "      <td>6.840171e+07</td>\n",
       "      <td>516.299514</td>\n",
       "      <td>59750.588869</td>\n",
       "      <td>5223.734291</td>\n",
       "      <td>308659.649910</td>\n",
       "      <td>2.226212</td>\n",
       "      <td>5.957390</td>\n",
       "      <td>4.494712</td>\n",
       "      <td>3.593691</td>\n",
       "      <td>2.163127</td>\n",
       "      <td>5.173140</td>\n",
       "      <td>39048.366166</td>\n",
       "      <td>220.194039</td>\n",
       "      <td>8.686774e+08</td>\n",
       "      <td>14859.765117</td>\n",
       "      <td>53109.757758</td>\n",
       "      <td>127.027229</td>\n",
       "      <td>632.083895</td>\n",
       "      <td>6.349719e+07</td>\n",
       "      <td>594.119614</td>\n",
       "      <td>68146.203483</td>\n",
       "      <td>4954.728076</td>\n",
       "      <td>319652.178094</td>\n",
       "      <td>1.617073</td>\n",
       "      <td>7.150050</td>\n",
       "      <td>3.750610</td>\n",
       "      <td>3.541528</td>\n",
       "      <td>2.132350</td>\n",
       "      <td>5.580070</td>\n",
       "      <td>51547.813869</td>\n",
       "      <td>159.833333</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49805.000000</td>\n",
       "      <td>215.166667</td>\n",
       "      <td>98604.000000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0.144510</td>\n",
       "      <td>5.921589</td>\n",
       "      <td>2.516764</td>\n",
       "      <td>0.500618</td>\n",
       "      <td>1.940400</td>\n",
       "      <td>49582.684663</td>\n",
       "      <td>118.746269</td>\n",
       "      <td>1.843964e+06</td>\n",
       "      <td>18.985075</td>\n",
       "      <td>8697.944523</td>\n",
       "      <td>0.179104</td>\n",
       "      <td>59.682836</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66749.108209</td>\n",
       "      <td>508.626866</td>\n",
       "      <td>185754.809701</td>\n",
       "      <td>1.910448</td>\n",
       "      <td>1.903302</td>\n",
       "      <td>4.116650</td>\n",
       "      <td>2.717738</td>\n",
       "      <td>0.669063</td>\n",
       "      <td>2.511798</td>\n",
       "      <td>51363.458134</td>\n",
       "      <td>142.921569</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.176471</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54631.235294</td>\n",
       "      <td>248.784314</td>\n",
       "      <td>98202.588235</td>\n",
       "      <td>1.980392</td>\n",
       "      <td>0.567695</td>\n",
       "      <td>5.302866</td>\n",
       "      <td>2.522764</td>\n",
       "      <td>0.491388</td>\n",
       "      <td>1.985558</td>\n",
       "      <td>50032.941844</td>\n",
       "      <td>172.047619</td>\n",
       "      <td>3.770323e+07</td>\n",
       "      <td>413.023810</td>\n",
       "      <td>10485.232003</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>23.642857</td>\n",
       "      <td>6.802143e+06</td>\n",
       "      <td>251.370382</td>\n",
       "      <td>52923.023810</td>\n",
       "      <td>383.952381</td>\n",
       "      <td>151100.857143</td>\n",
       "      <td>2.214286</td>\n",
       "      <td>1.145965</td>\n",
       "      <td>5.813568</td>\n",
       "      <td>2.913321</td>\n",
       "      <td>0.629005</td>\n",
       "      <td>2.632741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1255</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>20.807864</td>\n",
       "      <td>10.537342</td>\n",
       "      <td>10.270583</td>\n",
       "      <td>422</td>\n",
       "      <td>19.428758</td>\n",
       "      <td>8.824237</td>\n",
       "      <td>10.604693</td>\n",
       "      <td>62</td>\n",
       "      <td>6.654153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>11.840298</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.752056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.741001</td>\n",
       "      <td>11.902099</td>\n",
       "      <td>9.499646</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.763263</td>\n",
       "      <td>7.477743</td>\n",
       "      <td>8.133736</td>\n",
       "      <td>6.643515</td>\n",
       "      <td>13.817228</td>\n",
       "      <td>8</td>\n",
       "      <td>1156</td>\n",
       "      <td>486</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>56.250000</td>\n",
       "      <td>50.609852</td>\n",
       "      <td>104614.815020</td>\n",
       "      <td>88372.684692</td>\n",
       "      <td>77186.781252</td>\n",
       "      <td>117756.951718</td>\n",
       "      <td>77.491443</td>\n",
       "      <td>52.280512</td>\n",
       "      <td>7.267132</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.005</td>\n",
       "      <td>46.504606</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.013</td>\n",
       "      <td>474</td>\n",
       "      <td>0</td>\n",
       "      <td>39513.500480</td>\n",
       "      <td>207.561170</td>\n",
       "      <td>2.136534e+08</td>\n",
       "      <td>4688.476064</td>\n",
       "      <td>42025.074616</td>\n",
       "      <td>38.579787</td>\n",
       "      <td>354.800532</td>\n",
       "      <td>4.054210e+07</td>\n",
       "      <td>455.194395</td>\n",
       "      <td>65265.109043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>300035.446809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.093770</td>\n",
       "      <td>4.190226</td>\n",
       "      <td>2.961413</td>\n",
       "      <td>1.981788</td>\n",
       "      <td>4.746594</td>\n",
       "      <td>40725.102969</td>\n",
       "      <td>229.518102</td>\n",
       "      <td>1.940921e+08</td>\n",
       "      <td>3806.600763</td>\n",
       "      <td>44245.116035</td>\n",
       "      <td>31.333564</td>\n",
       "      <td>271.877668</td>\n",
       "      <td>2.935649e+07</td>\n",
       "      <td>277.134168</td>\n",
       "      <td>78607.926551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>287437.223218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.608225</td>\n",
       "      <td>4.222785</td>\n",
       "      <td>2.883093</td>\n",
       "      <td>1.945022</td>\n",
       "      <td>4.747559</td>\n",
       "      <td>28328.723792</td>\n",
       "      <td>415.166667</td>\n",
       "      <td>4.905367e+08</td>\n",
       "      <td>12090.333333</td>\n",
       "      <td>40536.723585</td>\n",
       "      <td>132.333333</td>\n",
       "      <td>935.166667</td>\n",
       "      <td>2.151067e+08</td>\n",
       "      <td>2346.122474</td>\n",
       "      <td>46725.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>928198.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.763263</td>\n",
       "      <td>7.477743</td>\n",
       "      <td>8.133736</td>\n",
       "      <td>6.643515</td>\n",
       "      <td>13.817228</td>\n",
       "      <td>30064.657225</td>\n",
       "      <td>270.324324</td>\n",
       "      <td>4.455364e+08</td>\n",
       "      <td>10554.543184</td>\n",
       "      <td>42188.647757</td>\n",
       "      <td>100.215041</td>\n",
       "      <td>751.395417</td>\n",
       "      <td>1.125546e+08</td>\n",
       "      <td>970.094310</td>\n",
       "      <td>29897.245593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>532118.696240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.013983</td>\n",
       "      <td>4.044437</td>\n",
       "      <td>4.597562</td>\n",
       "      <td>3.693982</td>\n",
       "      <td>7.178049</td>\n",
       "      <td>29546.368987</td>\n",
       "      <td>338.152284</td>\n",
       "      <td>4.119331e+08</td>\n",
       "      <td>10093.155185</td>\n",
       "      <td>40797.245546</td>\n",
       "      <td>105.546773</td>\n",
       "      <td>995.436548</td>\n",
       "      <td>1.877803e+08</td>\n",
       "      <td>1642.630417</td>\n",
       "      <td>40552.019579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>779289.135606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.168547</td>\n",
       "      <td>6.210230</td>\n",
       "      <td>6.809382</td>\n",
       "      <td>5.475701</td>\n",
       "      <td>11.064850</td>\n",
       "      <td>44450.088562</td>\n",
       "      <td>215.379152</td>\n",
       "      <td>1.757185e+08</td>\n",
       "      <td>3045.600229</td>\n",
       "      <td>53401.176003</td>\n",
       "      <td>25.135166</td>\n",
       "      <td>284.792669</td>\n",
       "      <td>3.830074e+07</td>\n",
       "      <td>331.491458</td>\n",
       "      <td>72718.476518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>306993.166094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.077823</td>\n",
       "      <td>4.483336</td>\n",
       "      <td>3.140337</td>\n",
       "      <td>1.977003</td>\n",
       "      <td>4.938298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   area  rentType  houseFloor  totalFloor  houseToward  houseDecoration  \\\n",
       "0    57         2           2          15            4                0   \n",
       "1    42         2           1           7            8                0   \n",
       "2    78         1           2          18            4                3   \n",
       "3    35         2           1           5            4                0   \n",
       "4    36         2           2           4            4                0   \n",
       "\n",
       "   communityName  region  plate  buildYear  saleSecHouseNum  totalTradeMoney  \\\n",
       "0            646       1     53       1994                0        19.787104   \n",
       "1           3470      11     11       1986                0        19.899212   \n",
       "2           1595       3     42       1994                1        20.234430   \n",
       "3           2466       6     28       1957               15        20.007377   \n",
       "4           1255       2     44       2003                0        20.807864   \n",
       "\n",
       "   totalTradeArea  tradeMeanPrice  tradeSecNum  totalNewTradeMoney  \\\n",
       "0        9.440703       10.346512          158           17.084842   \n",
       "1        8.937729       10.961632          113           16.959709   \n",
       "2        9.786235       10.448280          199           21.246762   \n",
       "3        9.157393       10.850109          169            0.000000   \n",
       "4       10.537342       10.270583          422           19.428758   \n",
       "\n",
       "   totalNewTradeArea  tradeNewMeanPrice  tradeNewNum  remainNewNum  \\\n",
       "0           6.622736          10.463465            5      5.370638   \n",
       "1           5.484797          11.479080            2      4.094345   \n",
       "2          10.451927          10.794885          301      6.011267   \n",
       "3           0.000000           0.000000            0      0.000000   \n",
       "4           8.824237          10.604693           62      6.654153   \n",
       "\n",
       "   supplyNewNum  supplyLandNum  supplyLandArea  tradeLandNum  tradeLandArea  \\\n",
       "0      0.000000              0        0.000000             0            0.0   \n",
       "1      0.000000              0        0.000000             0            0.0   \n",
       "2      5.918894              0        0.000000             0            0.0   \n",
       "3      0.000000              0        0.000000             0            0.0   \n",
       "4      0.000000              2       11.840298             0            0.0   \n",
       "\n",
       "   landTotalPrice  landMeanPrice  totalWorkers  newWorkers  \\\n",
       "0             0.0            0.0      9.047704    0.000000   \n",
       "1             0.0            0.0     11.701527    0.000000   \n",
       "2             0.0            0.0     12.442452    0.000000   \n",
       "3             0.0            0.0     10.815891    4.718499   \n",
       "4             0.0            0.0     10.752056    0.000000   \n",
       "\n",
       "   residentPopulation         pv        uv  lookNum  month  day  Room  Hall  \\\n",
       "0           12.967047  11.069307  8.804775        0      6   18     1     1   \n",
       "1           12.641799   9.258178  7.192182        0      3    2     2     0   \n",
       "2           12.014670  10.328167  7.902857        0      8    8     2     2   \n",
       "3           11.498877   5.683580  4.077537        0     11   11     1     0   \n",
       "4           13.741001  11.902099  9.499646        0      6    8     1     1   \n",
       "\n",
       "   Bath  Room_Bath  trainsportNum  all_SchoolNum  all_hospitalNum  all_mall  \\\n",
       "0     1   1.000000       6.861430       2.914163         3.955609  3.118232   \n",
       "1     1   0.666667       6.533145       2.499231         3.019493  1.399270   \n",
       "2     1   0.666667       2.265734       0.685633         1.106628  1.833608   \n",
       "3     1   1.000000       0.144510       5.921589         2.516764  0.500618   \n",
       "4     1   1.000000       8.763263       7.477743         8.133736  6.643515   \n",
       "\n",
       "    otherNum  count_communityName  count_buildYear  count_totalFloor  \\\n",
       "0   7.035898                   15             5659               809   \n",
       "1   4.335986                   21              320              1362   \n",
       "2   2.839831                   15             5659              3553   \n",
       "3   1.940400                   56              227              2730   \n",
       "4  13.817228                    8             1156               486   \n",
       "\n",
       "   count_communityName_totalFloor  count_communityName_newWorkers  \\\n",
       "0                              14                              10   \n",
       "1                              21                              19   \n",
       "2                              11                              11   \n",
       "3                              48                               5   \n",
       "4                               3                               7   \n",
       "\n",
       "   count_communityName_totalTradeMoney  com_area_mean  com_area_std  \\\n",
       "0                                    1      57.666667      8.005950   \n",
       "1                                    4      39.238095      7.974364   \n",
       "2                                    1      72.866667     23.191337   \n",
       "3                                    5      35.839286     18.444784   \n",
       "4                                    1      56.250000     50.609852   \n",
       "\n",
       "   comm_price_mean  comm_price_std  plate_price_mean  plate_price_std  \\\n",
       "0     56011.618848    11432.901072      95866.315739    103261.303345   \n",
       "1    140701.447242    25959.585233     154231.435167    144059.477704   \n",
       "2     64715.839564    83080.341652      74449.615731     83069.250127   \n",
       "3    169607.758678    78663.619452     142872.849542     97885.206437   \n",
       "4    104614.815020    88372.684692      77186.781252    117756.951718   \n",
       "\n",
       "   plate_area_mean  plate_area_std  plate_year_std  comm_plate_year_diff  \\\n",
       "0        67.563758       87.878800        8.720308                    -6   \n",
       "1        53.939891       33.509477       14.759094                    -3   \n",
       "2        74.935159       42.805242        9.095648                   -12   \n",
       "3        46.166352       24.522229       14.789971                   -20   \n",
       "4        77.491443       52.280512        7.267132                    -1   \n",
       "\n",
       "   trainsportNum_ratio  com_all_mall  other_ratio  sale_ratio  \\\n",
       "0                0.009     43.655253        0.012       0.014   \n",
       "1                0.047     29.384662        0.038       0.045   \n",
       "2                0.016     20.169689        0.016       0.031   \n",
       "3                0.028     27.533977        0.102       0.154   \n",
       "4                0.005     46.504606        0.005       0.013   \n",
       "\n",
       "   sale_newworker_differ  cluster  tradeMeanPrice_totalFloor_cluster_mean  \\\n",
       "0                    429        0                            37234.390317   \n",
       "1                    333        0                            44629.869276   \n",
       "2                    189        0                            35171.928027   \n",
       "3                      3        1                            34434.715836   \n",
       "4                    474        0                            39513.500480   \n",
       "\n",
       "   tradeSecNum_totalFloor_cluster_mean  \\\n",
       "0                           232.448845   \n",
       "1                           182.434742   \n",
       "2                           245.471233   \n",
       "3                           235.380610   \n",
       "4                           207.561170   \n",
       "\n",
       "   totalNewTradeMoney_totalFloor_cluster_mean  \\\n",
       "0                                2.134405e+08   \n",
       "1                                1.662570e+08   \n",
       "2                                2.657397e+08   \n",
       "3                                5.689525e+08   \n",
       "4                                2.136534e+08   \n",
       "\n",
       "   totalNewTradeArea_totalFloor_cluster_mean  \\\n",
       "0                                4719.924092   \n",
       "1                                2510.731455   \n",
       "2                                5741.705284   \n",
       "3                               12210.005386   \n",
       "4                                4688.476064   \n",
       "\n",
       "   tradeNewMeanPrice_totalFloor_cluster_mean  \\\n",
       "0                               38813.883094   \n",
       "1                               48701.681393   \n",
       "2                               44279.017722   \n",
       "3                               39370.958305   \n",
       "4                               42025.074616   \n",
       "\n",
       "   tradeNewNum_totalFloor_cluster_mean  remainNewNum_totalFloor_cluster_mean  \\\n",
       "0                            41.143564                            305.674917   \n",
       "1                            18.217840                            187.546479   \n",
       "2                            49.390998                            414.180039   \n",
       "3                           107.405745                            627.689408   \n",
       "4                            38.579787                            354.800532   \n",
       "\n",
       "   landTotalPrice_totalFloor_cluster_mean  \\\n",
       "0                            3.745285e+07   \n",
       "1                            2.283223e+07   \n",
       "2                            4.973183e+07   \n",
       "3                            6.840171e+07   \n",
       "4                            4.054210e+07   \n",
       "\n",
       "   landMeanPrice_totalFloor_cluster_mean  \\\n",
       "0                             265.775476   \n",
       "1                             254.032348   \n",
       "2                             486.120865   \n",
       "3                             516.299514   \n",
       "4                             455.194395   \n",
       "\n",
       "   totalWorkers_totalFloor_cluster_mean  newWorkers_totalFloor_cluster_mean  \\\n",
       "0                          77849.013201                            0.000000   \n",
       "1                          91834.026291                            0.000000   \n",
       "2                          61481.230137                            0.000000   \n",
       "3                          59750.588869                         5223.734291   \n",
       "4                          65265.109043                            0.000000   \n",
       "\n",
       "   residentPopulation_totalFloor_cluster_mean  \\\n",
       "0                               330429.646865   \n",
       "1                               242360.642254   \n",
       "2                               323437.272407   \n",
       "3                               308659.649910   \n",
       "4                               300035.446809   \n",
       "\n",
       "   lookNum_totalFloor_cluster_mean  trainsportNum_totalFloor_cluster_mean  \\\n",
       "0                         0.000000                               5.420387   \n",
       "1                         0.000000                               5.068509   \n",
       "2                         0.000000                               5.659887   \n",
       "3                         2.226212                               5.957390   \n",
       "4                         0.000000                               5.093770   \n",
       "\n",
       "   all_SchoolNum_totalFloor_cluster_mean  \\\n",
       "0                               3.315204   \n",
       "1                               3.548384   \n",
       "2                               3.490074   \n",
       "3                               4.494712   \n",
       "4                               4.190226   \n",
       "\n",
       "   all_hospitalNum_totalFloor_cluster_mean  all_mall_totalFloor_cluster_mean  \\\n",
       "0                                 3.106066                          2.327820   \n",
       "1                                 2.467506                          1.587749   \n",
       "2                                 3.150568                          2.272588   \n",
       "3                                 3.593691                          2.163127   \n",
       "4                                 2.961413                          1.981788   \n",
       "\n",
       "   otherNum_totalFloor_cluster_mean  \\\n",
       "0                          5.084342   \n",
       "1                          4.071131   \n",
       "2                          5.257058   \n",
       "3                          5.173140   \n",
       "4                          4.746594   \n",
       "\n",
       "   tradeMeanPrice_houseDecoration_cluster_mean  \\\n",
       "0                                 40725.102969   \n",
       "1                                 40725.102969   \n",
       "2                                 41286.309465   \n",
       "3                                 39048.366166   \n",
       "4                                 40725.102969   \n",
       "\n",
       "   tradeSecNum_houseDecoration_cluster_mean  \\\n",
       "0                                229.518102   \n",
       "1                                229.518102   \n",
       "2                                218.818389   \n",
       "3                                220.194039   \n",
       "4                                229.518102   \n",
       "\n",
       "   totalNewTradeMoney_houseDecoration_cluster_mean  \\\n",
       "0                                     1.940921e+08   \n",
       "1                                     1.940921e+08   \n",
       "2                                     1.770842e+08   \n",
       "3                                     8.686774e+08   \n",
       "4                                     1.940921e+08   \n",
       "\n",
       "   totalNewTradeArea_houseDecoration_cluster_mean  \\\n",
       "0                                     3806.600763   \n",
       "1                                     3806.600763   \n",
       "2                                     3310.516500   \n",
       "3                                    14859.765117   \n",
       "4                                     3806.600763   \n",
       "\n",
       "   tradeNewMeanPrice_houseDecoration_cluster_mean  \\\n",
       "0                                    44245.116035   \n",
       "1                                    44245.116035   \n",
       "2                                    47866.995252   \n",
       "3                                    53109.757758   \n",
       "4                                    44245.116035   \n",
       "\n",
       "   tradeNewNum_houseDecoration_cluster_mean  \\\n",
       "0                                 31.333564   \n",
       "1                                 31.333564   \n",
       "2                                 26.746852   \n",
       "3                                127.027229   \n",
       "4                                 31.333564   \n",
       "\n",
       "   remainNewNum_houseDecoration_cluster_mean  \\\n",
       "0                                 271.877668   \n",
       "1                                 271.877668   \n",
       "2                                 249.648285   \n",
       "3                                 632.083895   \n",
       "4                                 271.877668   \n",
       "\n",
       "   landTotalPrice_houseDecoration_cluster_mean  \\\n",
       "0                                 2.935649e+07   \n",
       "1                                 2.935649e+07   \n",
       "2                                 4.677131e+07   \n",
       "3                                 6.349719e+07   \n",
       "4                                 2.935649e+07   \n",
       "\n",
       "   landMeanPrice_houseDecoration_cluster_mean  \\\n",
       "0                                  277.134168   \n",
       "1                                  277.134168   \n",
       "2                                  383.161679   \n",
       "3                                  594.119614   \n",
       "4                                  277.134168   \n",
       "\n",
       "   totalWorkers_houseDecoration_cluster_mean  \\\n",
       "0                               78607.926551   \n",
       "1                               78607.926551   \n",
       "2                               85574.482306   \n",
       "3                               68146.203483   \n",
       "4                               78607.926551   \n",
       "\n",
       "   newWorkers_houseDecoration_cluster_mean  \\\n",
       "0                                 0.000000   \n",
       "1                                 0.000000   \n",
       "2                                 0.000000   \n",
       "3                              4954.728076   \n",
       "4                                 0.000000   \n",
       "\n",
       "   residentPopulation_houseDecoration_cluster_mean  \\\n",
       "0                                    287437.223218   \n",
       "1                                    287437.223218   \n",
       "2                                    282260.154472   \n",
       "3                                    319652.178094   \n",
       "4                                    287437.223218   \n",
       "\n",
       "   lookNum_houseDecoration_cluster_mean  \\\n",
       "0                              0.000000   \n",
       "1                              0.000000   \n",
       "2                              0.000000   \n",
       "3                              1.617073   \n",
       "4                              0.000000   \n",
       "\n",
       "   trainsportNum_houseDecoration_cluster_mean  \\\n",
       "0                                    5.608225   \n",
       "1                                    5.608225   \n",
       "2                                    5.634353   \n",
       "3                                    7.150050   \n",
       "4                                    5.608225   \n",
       "\n",
       "   all_SchoolNum_houseDecoration_cluster_mean  \\\n",
       "0                                    4.222785   \n",
       "1                                    4.222785   \n",
       "2                                    3.769083   \n",
       "3                                    3.750610   \n",
       "4                                    4.222785   \n",
       "\n",
       "   all_hospitalNum_houseDecoration_cluster_mean  \\\n",
       "0                                      2.883093   \n",
       "1                                      2.883093   \n",
       "2                                      2.692437   \n",
       "3                                      3.541528   \n",
       "4                                      2.883093   \n",
       "\n",
       "   all_mall_houseDecoration_cluster_mean  \\\n",
       "0                               1.945022   \n",
       "1                               1.945022   \n",
       "2                               1.911154   \n",
       "3                               2.132350   \n",
       "4                               1.945022   \n",
       "\n",
       "   otherNum_houseDecoration_cluster_mean  \\\n",
       "0                               4.747559   \n",
       "1                               4.747559   \n",
       "2                               4.726214   \n",
       "3                               5.580070   \n",
       "4                               4.747559   \n",
       "\n",
       "   tradeMeanPrice_communityName_cluster_mean  \\\n",
       "0                               31079.504539   \n",
       "1                               53739.820320   \n",
       "2                               32511.713706   \n",
       "3                               51547.813869   \n",
       "4                               28328.723792   \n",
       "\n",
       "   tradeSecNum_communityName_cluster_mean  \\\n",
       "0                              173.800000   \n",
       "1                              104.266667   \n",
       "2                              171.636364   \n",
       "3                              159.833333   \n",
       "4                              415.166667   \n",
       "\n",
       "   totalNewTradeMoney_communityName_cluster_mean  \\\n",
       "0                                   3.818973e+07   \n",
       "1                                   4.626383e+08   \n",
       "2                                   4.766587e+08   \n",
       "3                                   0.000000e+00   \n",
       "4                                   4.905367e+08   \n",
       "\n",
       "   totalNewTradeArea_communityName_cluster_mean  \\\n",
       "0                                   1001.900000   \n",
       "1                                   4801.333333   \n",
       "2                                  10247.000000   \n",
       "3                                      0.000000   \n",
       "4                                  12090.333333   \n",
       "\n",
       "   tradeNewMeanPrice_communityName_cluster_mean  \\\n",
       "0                                  35419.551532   \n",
       "1                                  96091.755367   \n",
       "2                                  45747.191029   \n",
       "3                                      0.000000   \n",
       "4                                  40536.723585   \n",
       "\n",
       "   tradeNewNum_communityName_cluster_mean  \\\n",
       "0                                4.100000   \n",
       "1                               26.333333   \n",
       "2                               94.727273   \n",
       "3                                0.000000   \n",
       "4                              132.333333   \n",
       "\n",
       "   remainNewNum_communityName_cluster_mean  \\\n",
       "0                               217.400000   \n",
       "1                               186.733333   \n",
       "2                               399.727273   \n",
       "3                                 0.000000   \n",
       "4                               935.166667   \n",
       "\n",
       "   landTotalPrice_communityName_cluster_mean  \\\n",
       "0                               0.000000e+00   \n",
       "1                               2.903000e+07   \n",
       "2                               0.000000e+00   \n",
       "3                               0.000000e+00   \n",
       "4                               2.151067e+08   \n",
       "\n",
       "   landMeanPrice_communityName_cluster_mean  \\\n",
       "0                                  0.000000   \n",
       "1                               1442.057649   \n",
       "2                                  0.000000   \n",
       "3                                  0.000000   \n",
       "4                               2346.122474   \n",
       "\n",
       "   totalWorkers_communityName_cluster_mean  \\\n",
       "0                              8498.000000   \n",
       "1                            120755.000000   \n",
       "2                            210433.818182   \n",
       "3                             49805.000000   \n",
       "4                             46725.000000   \n",
       "\n",
       "   newWorkers_communityName_cluster_mean  \\\n",
       "0                               0.000000   \n",
       "1                               0.000000   \n",
       "2                               0.000000   \n",
       "3                             215.166667   \n",
       "4                               0.000000   \n",
       "\n",
       "   residentPopulation_communityName_cluster_mean  \\\n",
       "0                                  428071.000000   \n",
       "1                                  309216.000000   \n",
       "2                                  193286.454545   \n",
       "3                                   98604.000000   \n",
       "4                                  928198.000000   \n",
       "\n",
       "   lookNum_communityName_cluster_mean  \\\n",
       "0                            0.000000   \n",
       "1                            0.000000   \n",
       "2                            0.000000   \n",
       "3                            2.833333   \n",
       "4                            0.000000   \n",
       "\n",
       "   trainsportNum_communityName_cluster_mean  \\\n",
       "0                                  6.861430   \n",
       "1                                  6.533145   \n",
       "2                                  3.096501   \n",
       "3                                  0.144510   \n",
       "4                                  8.763263   \n",
       "\n",
       "   all_SchoolNum_communityName_cluster_mean  \\\n",
       "0                                  2.914163   \n",
       "1                                  2.499231   \n",
       "2                                  1.892693   \n",
       "3                                  5.921589   \n",
       "4                                  7.477743   \n",
       "\n",
       "   all_hospitalNum_communityName_cluster_mean  \\\n",
       "0                                    3.955609   \n",
       "1                                    3.019493   \n",
       "2                                    1.115730   \n",
       "3                                    2.516764   \n",
       "4                                    8.133736   \n",
       "\n",
       "   all_mall_communityName_cluster_mean  otherNum_communityName_cluster_mean  \\\n",
       "0                             3.118232                             7.035898   \n",
       "1                             1.399270                             4.335986   \n",
       "2                             1.836681                             3.127984   \n",
       "3                             0.500618                             1.940400   \n",
       "4                             6.643515                            13.817228   \n",
       "\n",
       "   tradeMeanPrice_region_cluster_mean  tradeSecNum_region_cluster_mean  \\\n",
       "0                        41476.021283                       321.679504   \n",
       "1                        50724.464178                       164.072800   \n",
       "2                        31226.586754                       218.058221   \n",
       "3                        49582.684663                       118.746269   \n",
       "4                        30064.657225                       270.324324   \n",
       "\n",
       "   totalNewTradeMoney_region_cluster_mean  \\\n",
       "0                            1.724097e+08   \n",
       "1                            4.091667e+07   \n",
       "2                            2.900306e+08   \n",
       "3                            1.843964e+06   \n",
       "4                            4.455364e+08   \n",
       "\n",
       "   totalNewTradeArea_region_cluster_mean  \\\n",
       "0                            2949.490126   \n",
       "1                             429.828685   \n",
       "2                            6140.786308   \n",
       "3                              18.985075   \n",
       "4                           10554.543184   \n",
       "\n",
       "   tradeNewMeanPrice_region_cluster_mean  tradeNewNum_region_cluster_mean  \\\n",
       "0                           62580.585009                        22.496382   \n",
       "1                           17624.818421                         2.335024   \n",
       "2                           30628.396982                        57.154191   \n",
       "3                            8697.944523                         0.179104   \n",
       "4                           42188.647757                       100.215041   \n",
       "\n",
       "   remainNewNum_region_cluster_mean  landTotalPrice_region_cluster_mean  \\\n",
       "0                        216.609837                        2.676943e+07   \n",
       "1                         83.196306                        3.416624e+06   \n",
       "2                        259.392194                        1.657321e+07   \n",
       "3                         59.682836                        0.000000e+00   \n",
       "4                        751.395417                        1.125546e+08   \n",
       "\n",
       "   landMeanPrice_region_cluster_mean  totalWorkers_region_cluster_mean  \\\n",
       "0                         122.363175                     151335.517601   \n",
       "1                         220.008656                      64477.336472   \n",
       "2                         278.448139                     156349.654511   \n",
       "3                           0.000000                      66749.108209   \n",
       "4                         970.094310                      29897.245593   \n",
       "\n",
       "   newWorkers_region_cluster_mean  residentPopulation_region_cluster_mean  \\\n",
       "0                        0.000000                           344045.843493   \n",
       "1                        0.000000                           214085.011590   \n",
       "2                        0.000000                           208959.486244   \n",
       "3                      508.626866                           185754.809701   \n",
       "4                        0.000000                           532118.696240   \n",
       "\n",
       "   lookNum_region_cluster_mean  trainsportNum_region_cluster_mean  \\\n",
       "0                     0.000000                           9.273148   \n",
       "1                     0.000000                           3.889478   \n",
       "2                     0.000000                           5.592588   \n",
       "3                     1.910448                           1.903302   \n",
       "4                     0.000000                           5.013983   \n",
       "\n",
       "   all_SchoolNum_region_cluster_mean  all_hospitalNum_region_cluster_mean  \\\n",
       "0                           4.502851                             3.550913   \n",
       "1                           3.714923                             2.643469   \n",
       "2                           0.721673                             2.576660   \n",
       "3                           4.116650                             2.717738   \n",
       "4                           4.044437                             4.597562   \n",
       "\n",
       "   all_mall_region_cluster_mean  otherNum_region_cluster_mean  \\\n",
       "0                      2.196679                      6.243596   \n",
       "1                      0.963086                      3.326727   \n",
       "2                      2.143895                      4.067558   \n",
       "3                      0.669063                      2.511798   \n",
       "4                      3.693982                      7.178049   \n",
       "\n",
       "   tradeMeanPrice_plate_cluster_mean  tradeSecNum_plate_cluster_mean  \\\n",
       "0                       34773.122085                      193.143013   \n",
       "1                       52402.701262                      160.326484   \n",
       "2                       32640.334288                      182.613757   \n",
       "3                       51363.458134                      142.921569   \n",
       "4                       29546.368987                      338.152284   \n",
       "\n",
       "   totalNewTradeMoney_plate_cluster_mean  \\\n",
       "0                           1.158908e+08   \n",
       "1                           1.653230e+08   \n",
       "2                           4.813406e+08   \n",
       "3                           0.000000e+00   \n",
       "4                           4.119331e+08   \n",
       "\n",
       "   totalNewTradeArea_plate_cluster_mean  tradeNewMeanPrice_plate_cluster_mean  \\\n",
       "0                           2217.561135                          44129.109313   \n",
       "1                           1722.625571                          49717.365511   \n",
       "2                          10349.536155                          45433.926056   \n",
       "3                              0.000000                              0.000000   \n",
       "4                          10093.155185                          40797.245546   \n",
       "\n",
       "   tradeNewNum_plate_cluster_mean  remainNewNum_plate_cluster_mean  \\\n",
       "0                       14.838428                       280.707424   \n",
       "1                        9.246575                        82.751142   \n",
       "2                       94.650794                       461.689594   \n",
       "3                        0.000000                         3.176471   \n",
       "4                      105.546773                       995.436548   \n",
       "\n",
       "   landTotalPrice_plate_cluster_mean  landMeanPrice_plate_cluster_mean  \\\n",
       "0                       0.000000e+00                          0.000000   \n",
       "1                       8.272968e+06                        461.296022   \n",
       "2                       0.000000e+00                          0.000000   \n",
       "3                       0.000000e+00                          0.000000   \n",
       "4                       1.877803e+08                       1642.630417   \n",
       "\n",
       "   totalWorkers_plate_cluster_mean  newWorkers_plate_cluster_mean  \\\n",
       "0                      7763.432314                       0.000000   \n",
       "1                     81309.940639                       0.000000   \n",
       "2                    240414.003527                       0.000000   \n",
       "3                     54631.235294                     248.784314   \n",
       "4                     40552.019579                       0.000000   \n",
       "\n",
       "   residentPopulation_plate_cluster_mean  lookNum_plate_cluster_mean  \\\n",
       "0                          406501.259825                    0.000000   \n",
       "1                          305442.808219                    0.000000   \n",
       "2                          163120.816578                    0.000000   \n",
       "3                           98202.588235                    1.980392   \n",
       "4                          779289.135606                    0.000000   \n",
       "\n",
       "   trainsportNum_plate_cluster_mean  all_SchoolNum_plate_cluster_mean  \\\n",
       "0                          7.489401                          2.629209   \n",
       "1                          5.207264                          3.946431   \n",
       "2                          2.188203                          0.666448   \n",
       "3                          0.567695                          5.302866   \n",
       "4                          7.168547                          6.210230   \n",
       "\n",
       "   all_hospitalNum_plate_cluster_mean  all_mall_plate_cluster_mean  \\\n",
       "0                            3.956709                     2.870786   \n",
       "1                            3.647401                     1.115555   \n",
       "2                            1.068570                     1.776886   \n",
       "3                            2.522764                     0.491388   \n",
       "4                            6.809382                     5.475701   \n",
       "\n",
       "   otherNum_plate_cluster_mean  tradeMeanPrice_buildYear_cluster_mean  \\\n",
       "0                     6.609019                           38386.178484   \n",
       "1                     4.408551                           50108.594319   \n",
       "2                     2.793112                           38386.178484   \n",
       "3                     1.985558                           50032.941844   \n",
       "4                    11.064850                           44450.088562   \n",
       "\n",
       "   tradeSecNum_buildYear_cluster_mean  \\\n",
       "0                          215.547458   \n",
       "1                          239.519231   \n",
       "2                          215.547458   \n",
       "3                          172.047619   \n",
       "4                          215.379152   \n",
       "\n",
       "   totalNewTradeMoney_buildYear_cluster_mean  \\\n",
       "0                               2.051141e+08   \n",
       "1                               1.181157e+08   \n",
       "2                               2.051141e+08   \n",
       "3                               3.770323e+07   \n",
       "4                               1.757185e+08   \n",
       "\n",
       "   totalNewTradeArea_buildYear_cluster_mean  \\\n",
       "0                               4220.866016   \n",
       "1                               1290.584615   \n",
       "2                               4220.866016   \n",
       "3                                413.023810   \n",
       "4                               3045.600229   \n",
       "\n",
       "   tradeNewMeanPrice_buildYear_cluster_mean  \\\n",
       "0                              43980.696790   \n",
       "1                              43857.451243   \n",
       "2                              43980.696790   \n",
       "3                              10485.232003   \n",
       "4                              53401.176003   \n",
       "\n",
       "   tradeNewNum_buildYear_cluster_mean  remainNewNum_buildYear_cluster_mean  \\\n",
       "0                           33.438267                           314.098923   \n",
       "1                            7.357692                           122.219231   \n",
       "2                           33.438267                           314.098923   \n",
       "3                            2.666667                            23.642857   \n",
       "4                           25.135166                           284.792669   \n",
       "\n",
       "   landTotalPrice_buildYear_cluster_mean  \\\n",
       "0                           3.084462e+07   \n",
       "1                           7.717346e+06   \n",
       "2                           3.084462e+07   \n",
       "3                           6.802143e+06   \n",
       "4                           3.830074e+07   \n",
       "\n",
       "   landMeanPrice_buildYear_cluster_mean  totalWorkers_buildYear_cluster_mean  \\\n",
       "0                            317.416683                         57279.348109   \n",
       "1                            333.219172                        200760.196154   \n",
       "2                            317.416683                         57279.348109   \n",
       "3                            251.370382                         52923.023810   \n",
       "4                            331.491458                         72718.476518   \n",
       "\n",
       "   newWorkers_buildYear_cluster_mean  \\\n",
       "0                           0.000000   \n",
       "1                           0.000000   \n",
       "2                           0.000000   \n",
       "3                         383.952381   \n",
       "4                           0.000000   \n",
       "\n",
       "   residentPopulation_buildYear_cluster_mean  lookNum_buildYear_cluster_mean  \\\n",
       "0                              280336.653143                        0.000000   \n",
       "1                              216132.688462                        0.000000   \n",
       "2                              280336.653143                        0.000000   \n",
       "3                              151100.857143                        2.214286   \n",
       "4                              306993.166094                        0.000000   \n",
       "\n",
       "   trainsportNum_buildYear_cluster_mean  all_SchoolNum_buildYear_cluster_mean  \\\n",
       "0                              5.524240                              4.023809   \n",
       "1                              4.536364                              4.198835   \n",
       "2                              5.524240                              4.023809   \n",
       "3                              1.145965                              5.813568   \n",
       "4                              6.077823                              4.483336   \n",
       "\n",
       "   all_hospitalNum_buildYear_cluster_mean  all_mall_buildYear_cluster_mean  \\\n",
       "0                                2.670093                         1.931252   \n",
       "1                                2.566916                         1.579720   \n",
       "2                                2.670093                         1.931252   \n",
       "3                                2.913321                         0.629005   \n",
       "4                                3.140337                         1.977003   \n",
       "\n",
       "   otherNum_buildYear_cluster_mean  \n",
       "0                         4.448482  \n",
       "1                         4.872755  \n",
       "2                         4.448482  \n",
       "3                         2.632741  \n",
       "4                         4.938298  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "LightGBM objective call #1 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9901523137621939 bagging_freq=8.0 feature_fraction=0.9794803683645283 lambda_l1=2.403666923687541 lambda_l2=7.626310436598386 learning_rate=0.0032899076107307168 max_bin=144.0 min_data_in_leaf=70.0 min_sum_hessian_in_leaf=3.70520397201021 num_leaves=59.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                      \n",
      "nb_trees=1 val_loss={'rmse': nan}                      \n",
      "nb_trees=1 val_loss={'rmse': nan}                      \n",
      "val_r2_score=0.0                                       \n",
      "                                                                   \n",
      "LightGBM objective call #2 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8598496696761041 bagging_freq=5.0 feature_fraction=0.8272229296246083 lambda_l1=9.551904833217172 lambda_l2=1.8071409895509916 learning_rate=0.002973333900220331 max_bin=139.0 min_data_in_leaf=70.0 min_sum_hessian_in_leaf=6.9076369697363456 num_leaves=50.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "val_r2_score=0.0                                                   \n",
      "                                                                   \n",
      "LightGBM objective call #3 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9150024338491968 bagging_freq=13.0 feature_fraction=0.808314591647068 lambda_l1=3.4138937855325135 lambda_l2=7.243956711064987 learning_rate=0.005622588508815338 max_bin=145.0 min_data_in_leaf=32.0 min_sum_hessian_in_leaf=2.1386867437747967 num_leaves=32.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "val_r2_score=0.0                                                   \n",
      "                                                                   \n",
      "LightGBM objective call #4 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9582546484495501 bagging_freq=11.0 feature_fraction=0.9602773385169288 lambda_l1=3.985104532522359 lambda_l2=4.164350620960036 learning_rate=0.0022887012858019075 max_bin=118.0 min_data_in_leaf=39.0 min_sum_hessian_in_leaf=1.1363647978042488 num_leaves=88.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "val_r2_score=0.0                                                   \n",
      "                                                                   \n",
      "LightGBM objective call #5 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9242465828471136 bagging_freq=5.0 feature_fraction=0.9735110786413012 lambda_l1=3.4611024138129176 lambda_l2=5.7445016569100265 learning_rate=0.009406820022336951 max_bin=185.0 min_data_in_leaf=84.0 min_sum_hessian_in_leaf=3.3481446851165875 num_leaves=66.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "val_r2_score=0.0                                                   \n",
      "                                                                   \n",
      "LightGBM objective call #6 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8029187536460498 bagging_freq=10.0 feature_fraction=0.9859589934261911 lambda_l1=3.4994725781726768 lambda_l2=7.413991206213119 learning_rate=0.0003881748152043507 max_bin=91.0 min_data_in_leaf=64.0 min_sum_hessian_in_leaf=2.1524247617159458 num_leaves=16.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "val_r2_score=0.0                                                   \n",
      "                                                                   \n",
      "LightGBM objective call #7 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9670028654519005 bagging_freq=8.0 feature_fraction=0.9537161434984243 lambda_l1=4.877555427294714 lambda_l2=4.555658432282609 learning_rate=0.006782976053315689 max_bin=108.0 min_data_in_leaf=99.0 min_sum_hessian_in_leaf=1.3841208533289964 num_leaves=33.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "val_r2_score=0.0                                                   \n",
      "                                                                   \n",
      "LightGBM objective call #8 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8283107286978474 bagging_freq=9.0 feature_fraction=0.8636617115451705 lambda_l1=8.298026860400261 lambda_l2=1.5882948522805773 learning_rate=0.004373465246627167 max_bin=104.0 min_data_in_leaf=72.0 min_sum_hessian_in_leaf=1.796210859435026 num_leaves=62.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "val_r2_score=0.0                                                   \n",
      "                                                                   \n",
      "LightGBM objective call #9 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9034212393490546 bagging_freq=12.0 feature_fraction=0.7785183129594105 lambda_l1=5.3082589718027995 lambda_l2=6.786552725949877 learning_rate=0.0029891993008788298 max_bin=101.0 min_data_in_leaf=96.0 min_sum_hessian_in_leaf=7.985869875732814 num_leaves=47.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "val_r2_score=0.0                                                   \n",
      "                                                                   \n",
      "LightGBM objective call #10 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9163738890163493 bagging_freq=6.0 feature_fraction=0.8311361314820085 lambda_l1=0.12177646937362896 lambda_l2=1.2016597978438803 learning_rate=0.00029642022504412834 max_bin=178.0 min_data_in_leaf=63.0 min_sum_hessian_in_leaf=9.728436074768176 num_leaves=18.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "nb_trees=1 val_loss={'rmse': nan}                                  \n",
      "val_r2_score=0.0                                                   \n",
      "                                                                    \n",
      "LightGBM objective call #11 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8369593607166664 bagging_freq=10.0 feature_fraction=0.9215181807657856 lambda_l1=0.4971734465856259 lambda_l2=4.420977291007318 learning_rate=0.006546964521608426 max_bin=164.0 min_data_in_leaf=60.0 min_sum_hessian_in_leaf=5.981414840722668 num_leaves=90.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #12 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7627368223984115 bagging_freq=15.0 feature_fraction=0.7683776284492174 lambda_l1=3.56286477431241 lambda_l2=8.135203499896566 learning_rate=0.006991914311542463 max_bin=123.0 min_data_in_leaf=34.0 min_sum_hessian_in_leaf=1.2392453879672016 num_leaves=32.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #13 cur_best_score=0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: bagging_fraction=0.9301243385151665 bagging_freq=2.0 feature_fraction=0.8076357365675955 lambda_l1=8.54231636504997 lambda_l2=2.589716079504006 learning_rate=0.0034731547187990663 max_bin=121.0 min_data_in_leaf=84.0 min_sum_hessian_in_leaf=1.9247136250943089 num_leaves=46.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #14 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.989661587691275 bagging_freq=5.0 feature_fraction=0.7660007680734319 lambda_l1=0.7253920097194255 lambda_l2=0.49766931375786694 learning_rate=0.004054388183557478 max_bin=182.0 min_data_in_leaf=66.0 min_sum_hessian_in_leaf=4.119173866058244 num_leaves=56.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #15 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.791450396400258 bagging_freq=7.0 feature_fraction=0.9307600564171689 lambda_l1=1.4175134637752362 lambda_l2=9.214335856297435 learning_rate=0.007119263273035327 max_bin=166.0 min_data_in_leaf=36.0 min_sum_hessian_in_leaf=1.918362723457499 num_leaves=16.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #16 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7683020728031198 bagging_freq=8.0 feature_fraction=0.768981735056448 lambda_l1=7.297672085172237 lambda_l2=5.275155898589095 learning_rate=0.009952391071503107 max_bin=127.0 min_data_in_leaf=85.0 min_sum_hessian_in_leaf=5.846848198426692 num_leaves=76.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #17 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8679554969730088 bagging_freq=10.0 feature_fraction=0.9513824225200784 lambda_l1=7.72772195733471 lambda_l2=2.6987374171806913 learning_rate=0.0071187392323429875 max_bin=147.0 min_data_in_leaf=84.0 min_sum_hessian_in_leaf=6.857934034657969 num_leaves=97.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #18 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8751940545872311 bagging_freq=7.0 feature_fraction=0.7994257563704638 lambda_l1=1.2387859734430473 lambda_l2=4.7544909071942865 learning_rate=0.007795863295575954 max_bin=146.0 min_data_in_leaf=53.0 min_sum_hessian_in_leaf=4.560000119374882 num_leaves=83.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #19 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9907210773920474 bagging_freq=9.0 feature_fraction=0.9293600364299636 lambda_l1=5.631582500161299 lambda_l2=2.2448965018866485 learning_rate=0.00798860003284714 max_bin=122.0 min_data_in_leaf=32.0 min_sum_hessian_in_leaf=2.4837906580726226 num_leaves=50.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #20 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7787813482004332 bagging_freq=14.0 feature_fraction=0.9119274059110679 lambda_l1=5.965142820947022 lambda_l2=3.0815180494249885 learning_rate=0.0007507365055347304 max_bin=140.0 min_data_in_leaf=53.0 min_sum_hessian_in_leaf=3.049811941580928 num_leaves=34.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #21 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8944234783329436 bagging_freq=3.0 feature_fraction=0.8794331733101528 lambda_l1=2.1727790034682974 lambda_l2=9.510242223560635 learning_rate=0.0016737183056785253 max_bin=198.0 min_data_in_leaf=19.0 min_sum_hessian_in_leaf=4.100846782361917 num_leaves=76.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #22 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9996328732402494 bagging_freq=12.0 feature_fraction=0.9980802790311832 lambda_l1=6.465341446212596 lambda_l2=0.11201719699944279 learning_rate=0.008733129652444167 max_bin=158.0 min_data_in_leaf=10.0 min_sum_hessian_in_leaf=2.8398519363585626 num_leaves=67.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #23 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7917013206813199 bagging_freq=14.0 feature_fraction=0.8917298302719808 lambda_l1=2.442853723758462 lambda_l2=3.4499714147784606 learning_rate=0.0012680476143808427 max_bin=134.0 min_data_in_leaf=47.0 min_sum_hessian_in_leaf=3.581253218744045 num_leaves=39.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #24 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9591942405229519 bagging_freq=3.0 feature_fraction=0.8693015116024552 lambda_l1=2.343836818680332 lambda_l2=9.984278292479738 learning_rate=0.0020847308429818613 max_bin=197.0 min_data_in_leaf=10.0 min_sum_hessian_in_leaf=4.904699295056449 num_leaves=75.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #25 cur_best_score=0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: bagging_fraction=0.9999191201937013 bagging_freq=12.0 feature_fraction=0.9932561843460795 lambda_l1=6.8346383672724205 lambda_l2=8.511198338816873 learning_rate=0.005392845023444993 max_bin=158.0 min_data_in_leaf=19.0 min_sum_hessian_in_leaf=2.6860926977316897 num_leaves=65.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #26 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8173151899805091 bagging_freq=15.0 feature_fraction=0.9011192220371712 lambda_l1=2.5532387124954656 lambda_l2=3.614766614870482 learning_rate=0.0010955019389955723 max_bin=132.0 min_data_in_leaf=49.0 min_sum_hessian_in_leaf=3.5701180587910137 num_leaves=24.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #27 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9600612545441646 bagging_freq=3.0 feature_fraction=0.8601671915013035 lambda_l1=4.671895667411201 lambda_l2=6.143715380736558 learning_rate=0.0020492367880177893 max_bin=200.0 min_data_in_leaf=76.0 min_sum_hessian_in_leaf=5.031128245994278 num_leaves=100.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #28 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9423797919740723 bagging_freq=12.0 feature_fraction=0.9997415720570029 lambda_l1=9.419288680954484 lambda_l2=8.295995556371782 learning_rate=0.005502698011654245 max_bin=154.0 min_data_in_leaf=26.0 min_sum_hessian_in_leaf=1.5857365691513547 num_leaves=59.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #29 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.841099491977098 bagging_freq=1.0 feature_fraction=0.8955604708533487 lambda_l1=1.8286473008258106 lambda_l2=3.7694987857742013 learning_rate=0.002813143706959683 max_bin=133.0 min_data_in_leaf=41.0 min_sum_hessian_in_leaf=3.5944450303529685 num_leaves=25.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #30 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9799197086847782 bagging_freq=4.0 feature_fraction=0.8480821510650076 lambda_l1=4.8378649433188405 lambda_l2=6.193669710681684 learning_rate=0.003959402991282356 max_bin=174.0 min_data_in_leaf=77.0 min_sum_hessian_in_leaf=8.164145359478304 num_leaves=97.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #31 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9377249750098613 bagging_freq=13.0 feature_fraction=0.975585270514978 lambda_l1=9.935644233689425 lambda_l2=8.217985622732833 learning_rate=0.0048723868304219745 max_bin=155.0 min_data_in_leaf=23.0 min_sum_hessian_in_leaf=1.027553812255988 num_leaves=55.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #32 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.852583173241088 bagging_freq=6.0 feature_fraction=0.8300698399375215 lambda_l1=1.4029287519470832 lambda_l2=5.216589928006482 learning_rate=0.0032714642899131794 max_bin=113.0 min_data_in_leaf=44.0 min_sum_hessian_in_leaf=2.558162883225328 num_leaves=22.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #33 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.976393966071719 bagging_freq=4.0 feature_fraction=0.8529819417270486 lambda_l1=4.524315411872718 lambda_l2=6.543562960297875 learning_rate=0.006065084424289989 max_bin=188.0 min_data_in_leaf=92.0 min_sum_hessian_in_leaf=9.569178538955468 num_leaves=91.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #34 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.940916755463912 bagging_freq=13.0 feature_fraction=0.9824646317752956 lambda_l1=2.965343667932571 lambda_l2=7.449591719505488 learning_rate=0.005272801752539039 max_bin=169.0 min_data_in_leaf=26.0 min_sum_hessian_in_leaf=2.199472244197382 num_leaves=42.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #35 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8560652463957108 bagging_freq=6.0 feature_fraction=0.8283720191073003 lambda_l1=0.04323272716042825 lambda_l2=5.365959314411267 learning_rate=0.0032607707386508524 max_bin=115.0 min_data_in_leaf=43.0 min_sum_hessian_in_leaf=2.4527731579422234 num_leaves=11.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #36 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8796983406107698 bagging_freq=14.0 feature_fraction=0.912029369148197 lambda_l1=6.180972661153033 lambda_l2=3.072718092865504 learning_rate=0.000725286442681221 max_bin=139.0 min_data_in_leaf=59.0 min_sum_hessian_in_leaf=3.0465680966532043 num_leaves=37.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #37 cur_best_score=0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: bagging_fraction=0.9023431189561885 bagging_freq=1.0 feature_fraction=0.9592072565148442 lambda_l1=4.187248066711238 lambda_l2=9.632516555277729 learning_rate=0.0015877571272064636 max_bin=90.0 min_data_in_leaf=69.0 min_sum_hessian_in_leaf=5.8537011770635035 num_leaves=73.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #38 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8883440837060986 bagging_freq=9.0 feature_fraction=0.8814131086906896 lambda_l1=3.099911291021127 lambda_l2=8.96091705156075 learning_rate=0.0025320164105480337 max_bin=194.0 min_data_in_leaf=75.0 min_sum_hessian_in_leaf=4.213055502781881 num_leaves=84.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #39 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9964108436729319 bagging_freq=11.0 feature_fraction=0.9443771099674172 lambda_l1=9.122746360649078 lambda_l2=0.04523983148689936 learning_rate=0.008436545031514956 max_bin=151.0 min_data_in_leaf=13.0 min_sum_hessian_in_leaf=2.917913541767917 num_leaves=68.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #40 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7501254748246924 bagging_freq=11.0 feature_fraction=0.9635006115581785 lambda_l1=6.4226624893752895 lambda_l2=1.3495142976058354 learning_rate=0.009424311238070492 max_bin=161.0 min_data_in_leaf=89.0 min_sum_hessian_in_leaf=1.2926044182694132 num_leaves=61.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #41 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8101733836464754 bagging_freq=14.0 feature_fraction=0.9408746808817776 lambda_l1=3.973495009338295 lambda_l2=7.30256539394849 learning_rate=0.0001392709763836067 max_bin=95.0 min_data_in_leaf=46.0 min_sum_hessian_in_leaf=3.4679327990144206 num_leaves=42.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #42 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.789768480714566 bagging_freq=7.0 feature_fraction=0.8916114776070492 lambda_l1=0.5016174083530966 lambda_l2=4.072840147481515 learning_rate=0.004736327342238521 max_bin=133.0 min_data_in_leaf=57.0 min_sum_hessian_in_leaf=1.5994928791973169 num_leaves=28.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #43 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9522111260140911 bagging_freq=5.0 feature_fraction=0.7948954353112058 lambda_l1=0.9453399114313163 lambda_l2=9.962546696788118 learning_rate=0.0037320530656995876 max_bin=191.0 min_data_in_leaf=70.0 min_sum_hessian_in_leaf=4.9379975966688034 num_leaves=81.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #44 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9185524336253207 bagging_freq=2.0 feature_fraction=0.841942892222302 lambda_l1=3.7456522159544896 lambda_l2=8.743367746064758 learning_rate=0.002118895731535825 max_bin=176.0 min_data_in_leaf=80.0 min_sum_hessian_in_leaf=6.997941663356216 num_leaves=72.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #45 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9791570203097091 bagging_freq=8.0 feature_fraction=0.9892476901343121 lambda_l1=6.990756920061782 lambda_l2=7.684684374155 learning_rate=0.006150854026097666 max_bin=169.0 min_data_in_leaf=99.0 min_sum_hessian_in_leaf=1.706264614926312 num_leaves=49.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #46 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9747884396237829 bagging_freq=10.0 feature_fraction=0.9676114289351461 lambda_l1=5.314965484431562 lambda_l2=6.849457757423634 learning_rate=0.004352441719473141 max_bin=183.0 min_data_in_leaf=38.0 min_sum_hessian_in_leaf=2.034949734065408 num_leaves=52.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #47 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8162582244170926 bagging_freq=15.0 feature_fraction=0.9080038463263916 lambda_l1=2.789747989933962 lambda_l2=0.9357536579432622 learning_rate=0.0011952203956724873 max_bin=108.0 min_data_in_leaf=63.0 min_sum_hessian_in_leaf=2.227949697510373 num_leaves=12.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #48 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8227513575982428 bagging_freq=9.0 feature_fraction=0.8165880056049598 lambda_l1=4.283910625368021 lambda_l2=1.839762840053004 learning_rate=0.0026492997007722175 max_bin=129.0 min_data_in_leaf=49.0 min_sum_hessian_in_leaf=4.004262454890424 num_leaves=28.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #49 cur_best_score=0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: bagging_fraction=0.956334796718374 bagging_freq=7.0 feature_fraction=0.8615503278727201 lambda_l1=5.171749323404127 lambda_l2=6.173786026455048 learning_rate=0.001851302750410065 max_bin=140.0 min_data_in_leaf=94.0 min_sum_hessian_in_leaf=5.347780084799137 num_leaves=94.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #50 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.909747800131817 bagging_freq=4.0 feature_fraction=0.8138094496221692 lambda_l1=3.3086622649588646 lambda_l2=5.770238780923002 learning_rate=0.004371385227892983 max_bin=97.0 min_data_in_leaf=67.0 min_sum_hessian_in_leaf=7.039783421282347 num_leaves=87.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #51 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9417452051424233 bagging_freq=12.0 feature_fraction=0.9981761138955783 lambda_l1=8.244543003828607 lambda_l2=7.945608027928055 learning_rate=0.005855276149063253 max_bin=148.0 min_data_in_leaf=28.0 min_sum_hessian_in_leaf=1.4049962731703265 num_leaves=58.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #52 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9293295603033829 bagging_freq=10.0 feature_fraction=0.9785824325270688 lambda_l1=1.8277945284390809 lambda_l2=6.947872029544058 learning_rate=0.006433415504865963 max_bin=143.0 min_data_in_leaf=54.0 min_sum_hessian_in_leaf=1.4950486279644186 num_leaves=45.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #53 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8381425448451336 bagging_freq=8.0 feature_fraction=0.9259311121500732 lambda_l1=1.5821479180391045 lambda_l2=3.9814608310775674 learning_rate=0.0030156917710429864 max_bin=105.0 min_data_in_leaf=41.0 min_sum_hessian_in_leaf=3.2680061783050567 num_leaves=18.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #54 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8385195560203116 bagging_freq=1.0 feature_fraction=0.9392689421156672 lambda_l1=1.9057866075072616 lambda_l2=4.756199705002729 learning_rate=0.0024502618673644468 max_bin=124.0 min_data_in_leaf=34.0 min_sum_hessian_in_leaf=3.7297217921195243 num_leaves=53.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #55 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9830092902450128 bagging_freq=4.0 feature_fraction=0.7809869183802395 lambda_l1=5.589767290892132 lambda_l2=6.425620155037114 learning_rate=0.0038411342605852838 max_bin=176.0 min_data_in_leaf=80.0 min_sum_hessian_in_leaf=9.954574477823583 num_leaves=99.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #56 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9648871616941131 bagging_freq=5.0 feature_fraction=0.8449640872952933 lambda_l1=7.576481775426596 lambda_l2=5.659290186609992 learning_rate=0.004027769958024278 max_bin=172.0 min_data_in_leaf=76.0 min_sum_hessian_in_leaf=8.264178172881488 num_leaves=79.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #57 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9489711341255727 bagging_freq=13.0 feature_fraction=0.9749749826965592 lambda_l1=8.941926325916707 lambda_l2=9.272471482401642 learning_rate=0.004751741181864211 max_bin=154.0 min_data_in_leaf=16.0 min_sum_hessian_in_leaf=1.0936727364033147 num_leaves=70.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #58 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9333516328852237 bagging_freq=11.0 feature_fraction=0.9170746407493386 lambda_l1=9.705092507994006 lambda_l2=7.851741119484767 learning_rate=0.007454560493344453 max_bin=163.0 min_data_in_leaf=30.0 min_sum_hessian_in_leaf=1.004803599174696 num_leaves=54.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #59 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8563119917253955 bagging_freq=6.0 feature_fraction=0.7520597017643368 lambda_l1=0.9619158338182379 lambda_l2=4.444929891397869 learning_rate=0.0031114560655232737 max_bin=115.0 min_data_in_leaf=65.0 min_sum_hessian_in_leaf=4.6873632477269584 num_leaves=63.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #60 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8633437473751862 bagging_freq=6.0 feature_fraction=0.8002615766742063 lambda_l1=0.19604437172092926 lambda_l2=5.04523956692343 learning_rate=0.0035420051277925356 max_bin=118.0 min_data_in_leaf=61.0 min_sum_hessian_in_leaf=2.427805553120652 num_leaves=22.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #61 cur_best_score=0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: bagging_fraction=0.990211202447755 bagging_freq=2.0 feature_fraction=0.851051086810869 lambda_l1=4.439595850876182 lambda_l2=7.09026996910084 learning_rate=0.005136004859682682 max_bin=187.0 min_data_in_leaf=88.0 min_sum_hessian_in_leaf=8.943704572969114 num_leaves=92.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #62 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9693747852533395 bagging_freq=7.0 feature_fraction=0.8732516060415835 lambda_l1=3.5318365534254292 lambda_l2=6.691804244396195 learning_rate=0.005821865618671441 max_bin=181.0 min_data_in_leaf=95.0 min_sum_hessian_in_leaf=6.4371192250974 num_leaves=88.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #63 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9216415767805684 bagging_freq=13.0 feature_fraction=0.9817424145903553 lambda_l1=2.897622853881394 lambda_l2=7.355968008152836 learning_rate=0.006793310137471193 max_bin=167.0 min_data_in_leaf=24.0 min_sum_hessian_in_leaf=2.1969658951754756 num_leaves=43.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #64 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8919521012071587 bagging_freq=11.0 feature_fraction=0.9514403666400455 lambda_l1=2.2371597902501823 lambda_l2=5.836948258023675 learning_rate=0.005243583993740211 max_bin=137.0 min_data_in_leaf=72.0 min_sum_hessian_in_leaf=1.8426159514873497 num_leaves=35.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #65 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8516254164588978 bagging_freq=9.0 feature_fraction=0.8374436753073453 lambda_l1=0.05582102248909848 lambda_l2=5.436244199001248 learning_rate=0.0033888502715538854 max_bin=127.0 min_data_in_leaf=51.0 min_sum_hessian_in_leaf=2.6931068604124992 num_leaves=32.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #66 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8712851779030888 bagging_freq=10.0 feature_fraction=0.82461054495609 lambda_l1=6.188473034983962 lambda_l2=3.2510097420728585 learning_rate=0.0005937128954904267 max_bin=110.0 min_data_in_leaf=57.0 min_sum_hessian_in_leaf=3.1777564333527244 num_leaves=13.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #67 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8776422277618386 bagging_freq=14.0 feature_fraction=0.9545715640544338 lambda_l1=4.1224223720792255 lambda_l2=9.425156119274979 learning_rate=0.0016269127535586902 max_bin=91.0 min_data_in_leaf=68.0 min_sum_hessian_in_leaf=5.803673294548868 num_leaves=64.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #68 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9018143511528037 bagging_freq=15.0 feature_fraction=0.9596324633115308 lambda_l1=5.739799031726846 lambda_l2=2.661512494508923 learning_rate=5.2515980645576944e-05 max_bin=145.0 min_data_in_leaf=59.0 min_sum_hessian_in_leaf=4.424514140850209 num_leaves=38.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #69 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8875042154051236 bagging_freq=8.0 feature_fraction=0.8871048623877605 lambda_l1=3.0223755327697646 lambda_l2=8.942215145449548 learning_rate=0.0015674805525420386 max_bin=194.0 min_data_in_leaf=73.0 min_sum_hessian_in_leaf=5.41271151476925 num_leaves=83.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #70 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9118597614043303 bagging_freq=9.0 feature_fraction=0.8825792371139389 lambda_l1=3.8587331165776506 lambda_l2=9.649986428582098 learning_rate=0.0024513011631881023 max_bin=103.0 min_data_in_leaf=81.0 min_sum_hessian_in_leaf=6.1977418506136726 num_leaves=78.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #71 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9935804391109866 bagging_freq=11.0 feature_fraction=0.9325169865806223 lambda_l1=3.375456104177783 lambda_l2=8.66841594754138 learning_rate=0.008441295842059476 max_bin=152.0 min_data_in_leaf=87.0 min_sum_hessian_in_leaf=2.891250121459929 num_leaves=69.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #72 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9089494986902117 bagging_freq=12.0 feature_fraction=0.7890199239766358 lambda_l1=8.198100315731569 lambda_l2=8.072246709296802 learning_rate=0.004343133850438547 max_bin=96.0 min_data_in_leaf=67.0 min_sum_hessian_in_leaf=7.284836555596416 num_leaves=59.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #73 cur_best_score=0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: bagging_fraction=0.9262998380461174 bagging_freq=12.0 feature_fraction=0.9979825783790135 lambda_l1=2.0300756225580785 lambda_l2=7.691467435335692 learning_rate=0.0065116292284249574 max_bin=150.0 min_data_in_leaf=29.0 min_sum_hessian_in_leaf=1.4562761275840628 num_leaves=48.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #74 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9429197945255576 bagging_freq=10.0 feature_fraction=0.9692075606283153 lambda_l1=8.124835501109503 lambda_l2=8.384829613987494 learning_rate=0.007521529323883358 max_bin=142.0 min_data_in_leaf=54.0 min_sum_hessian_in_leaf=1.1846326719850901 num_leaves=58.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #75 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8000166270229082 bagging_freq=8.0 feature_fraction=0.9287301240824688 lambda_l1=1.6981848972820477 lambda_l2=2.239662481867715 learning_rate=0.006512426412220007 max_bin=136.0 min_data_in_leaf=43.0 min_sum_hessian_in_leaf=3.251528388659636 num_leaves=18.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #76 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8363369405682731 bagging_freq=8.0 feature_fraction=0.9018783593389367 lambda_l1=2.592705630285973 lambda_l2=4.052752017896986 learning_rate=0.0024239474668641013 max_bin=123.0 min_data_in_leaf=35.0 min_sum_hessian_in_leaf=3.826716151769602 num_leaves=30.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #77 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7667276264361775 bagging_freq=1.0 feature_fraction=0.7506074712845832 lambda_l1=4.814942087008126 lambda_l2=6.40674819581781 learning_rate=0.003808251878579986 max_bin=128.0 min_data_in_leaf=81.0 min_sum_hessian_in_leaf=3.7819594135376122 num_leaves=99.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #78 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7813198969131789 bagging_freq=3.0 feature_fraction=0.9438447847456264 lambda_l1=1.0980993965312562 lambda_l2=4.729931525289993 learning_rate=0.004582650095523359 max_bin=159.0 min_data_in_leaf=91.0 min_sum_hessian_in_leaf=7.501752137001222 num_leaves=53.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #79 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9635940758013242 bagging_freq=5.0 feature_fraction=0.779902786250471 lambda_l1=7.570001396045711 lambda_l2=6.389419196660923 learning_rate=0.004071310074517026 max_bin=173.0 min_data_in_leaf=77.0 min_sum_hessian_in_leaf=9.932115193088373 num_leaves=94.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #80 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9521953602592785 bagging_freq=5.0 feature_fraction=0.8561992199875136 lambda_l1=8.78661181310224 lambda_l2=9.101031145730149 learning_rate=0.005653995980502358 max_bin=155.0 min_data_in_leaf=84.0 min_sum_hessian_in_leaf=1.0944471798983533 num_leaves=78.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #81 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9358486848197243 bagging_freq=13.0 feature_fraction=0.9739357458732287 lambda_l1=9.067270782980664 lambda_l2=7.831341849729111 learning_rate=0.009897250016875154 max_bin=161.0 min_data_in_leaf=16.0 min_sum_hessian_in_leaf=1.3244414687552444 num_leaves=70.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #82 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9849739541107971 bagging_freq=11.0 feature_fraction=0.987372592977552 lambda_l1=9.848148705531646 lambda_l2=9.74309253813346 learning_rate=0.007483195167831417 max_bin=163.0 min_data_in_leaf=21.0 min_sum_hessian_in_leaf=1.0896873441897106 num_leaves=72.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #83 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8987156514783073 bagging_freq=6.0 feature_fraction=0.9174438213351942 lambda_l1=0.7740293082341819 lambda_l2=4.631397001840212 learning_rate=0.0030631978939816076 max_bin=116.0 min_data_in_leaf=61.0 min_sum_hessian_in_leaf=4.6718382526396045 num_leaves=63.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #84 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8267093654853752 bagging_freq=6.0 feature_fraction=0.7527700826749881 lambda_l1=0.37319725145266425 lambda_l2=5.016742586417276 learning_rate=0.003607687346313198 max_bin=119.0 min_data_in_leaf=64.0 min_sum_hessian_in_leaf=4.287376327540729 num_leaves=61.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #85 cur_best_score=0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: bagging_fraction=0.9704152883624292 bagging_freq=2.0 feature_fraction=0.8045853292353616 lambda_l1=1.308812248314377 lambda_l2=5.9444554527202085 learning_rate=0.005043952931562744 max_bin=187.0 min_data_in_leaf=97.0 min_sum_hessian_in_leaf=2.4612161196407714 num_leaves=24.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #86 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8656634264319515 bagging_freq=2.0 feature_fraction=0.867710379116965 lambda_l1=4.548358243432731 lambda_l2=6.979187694170478 learning_rate=0.005061373852852365 max_bin=112.0 min_data_in_leaf=88.0 min_sum_hessian_in_leaf=8.797465854950483 num_leaves=21.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #87 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9896331415931975 bagging_freq=7.0 feature_fraction=0.8753797064810813 lambda_l1=3.5904713287747616 lambda_l2=7.044369322328507 learning_rate=0.007020051938744403 max_bin=182.0 min_data_in_leaf=95.0 min_sum_hessian_in_leaf=6.322944362194504 num_leaves=85.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #88 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9197725279028555 bagging_freq=7.0 feature_fraction=0.9004471399149284 lambda_l1=2.5450531901651745 lambda_l2=6.563003101523455 learning_rate=0.008984029677249962 max_bin=179.0 min_data_in_leaf=97.0 min_sum_hessian_in_leaf=2.2631131269646065 num_leaves=44.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #89 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8892868870987197 bagging_freq=13.0 feature_fraction=0.9824336260215558 lambda_l1=2.1499292434370227 lambda_l2=7.418480296606196 learning_rate=0.006068765972249282 max_bin=136.0 min_data_in_leaf=74.0 min_sum_hessian_in_leaf=1.939845318841996 num_leaves=35.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #90 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8473463496577398 bagging_freq=14.0 feature_fraction=0.950633001764988 lambda_l1=2.7314883637451817 lambda_l2=5.584686765891355 learning_rate=0.008254522749803513 max_bin=167.0 min_data_in_leaf=71.0 min_sum_hessian_in_leaf=1.7561473951673863 num_leaves=40.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #91 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7557219136227675 bagging_freq=9.0 feature_fraction=0.8157451159187818 lambda_l1=0.05960322821003716 lambda_l2=4.275425295029479 learning_rate=0.002808291622549312 max_bin=130.0 min_data_in_leaf=51.0 min_sum_hessian_in_leaf=2.5834582698741815 num_leaves=32.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #92 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8690447696977036 bagging_freq=9.0 feature_fraction=0.8219576958483453 lambda_l1=6.523062479846565 lambda_l2=3.2697849897097635 learning_rate=0.0006028404229214031 max_bin=125.0 min_data_in_leaf=50.0 min_sum_hessian_in_leaf=2.747969208628537 num_leaves=16.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #93 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8785828499372952 bagging_freq=10.0 feature_fraction=0.77385535667911 lambda_l1=5.1698249585844565 lambda_l2=2.9175717521599274 learning_rate=0.0010596487526171965 max_bin=100.0 min_data_in_leaf=56.0 min_sum_hessian_in_leaf=5.566569443484201 num_leaves=51.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #94 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8728648009728013 bagging_freq=15.0 feature_fraction=0.935302712670671 lambda_l1=4.173661525961835 lambda_l2=2.3582739586356807 learning_rate=0.0003521363630031428 max_bin=89.0 min_data_in_leaf=68.0 min_sum_hessian_in_leaf=5.127187099691298 num_leaves=56.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #95 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8812891815881139 bagging_freq=14.0 feature_fraction=0.9593507373295092 lambda_l1=5.663838674954057 lambda_l2=0.6849114749924341 learning_rate=9.385656837485631e-05 max_bin=147.0 min_data_in_leaf=59.0 min_sum_hessian_in_leaf=4.398898274871674 num_leaves=66.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #96 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9028594400995286 bagging_freq=4.0 feature_fraction=0.9922627722850982 lambda_l1=3.232966360641391 lambda_l2=3.6948503013683305 learning_rate=0.0009622008952255729 max_bin=195.0 min_data_in_leaf=47.0 min_sum_hessian_in_leaf=3.959502633055787 num_leaves=38.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #97 cur_best_score=0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: bagging_fraction=0.9109367665876117 bagging_freq=9.0 feature_fraction=0.8828772870776683 lambda_l1=3.765898581274512 lambda_l2=9.850747054019882 learning_rate=0.0013393017282836755 max_bin=106.0 min_data_in_leaf=73.0 min_sum_hessian_in_leaf=5.289683612705302 num_leaves=82.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #98 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8949095653269235 bagging_freq=8.0 feature_fraction=0.8914792212932133 lambda_l1=3.9105465749380306 lambda_l2=8.82351609666742 learning_rate=0.0018953553345005122 max_bin=101.0 min_data_in_leaf=81.0 min_sum_hessian_in_leaf=6.284720663767361 num_leaves=74.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #99 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9965842402586215 bagging_freq=11.0 feature_fraction=0.9229605850738782 lambda_l1=1.5067653585266267 lambda_l2=8.495806733088404 learning_rate=0.002136508378490703 max_bin=152.0 min_data_in_leaf=100.0 min_sum_hessian_in_leaf=3.0130624761615206 num_leaves=78.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                    \n",
      "LightGBM objective call #100 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.973275333380554 bagging_freq=12.0 feature_fraction=0.7596741363358215 lambda_l1=4.954565589505906 lambda_l2=8.126816508114787 learning_rate=0.009511687736860728 max_bin=170.0 min_data_in_leaf=78.0 min_sum_hessian_in_leaf=2.063241002015468 num_leaves=68.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "nb_trees=1 val_loss={'rmse': nan}                                   \n",
      "val_r2_score=0.0                                                    \n",
      "                                                                     \n",
      "LightGBM objective call #101 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9258200678054241 bagging_freq=12.0 feature_fraction=0.7854035789442138 lambda_l1=7.181537034496416 lambda_l2=7.69492343857674 learning_rate=0.0041926664047759405 max_bin=131.0 min_data_in_leaf=37.0 min_sum_hessian_in_leaf=7.562221907316882 num_leaves=46.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #102 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9474900563738688 bagging_freq=12.0 feature_fraction=0.8346227813691981 lambda_l1=8.568941789825084 lambda_l2=7.610848164730531 learning_rate=0.006351635843282518 max_bin=149.0 min_data_in_leaf=66.0 min_sum_hessian_in_leaf=1.5776460803865775 num_leaves=48.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #103 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9265379872337351 bagging_freq=10.0 feature_fraction=0.9705648278023257 lambda_l1=7.952087051240254 lambda_l2=9.443518362962005 learning_rate=0.007842034798835846 max_bin=140.0 min_data_in_leaf=31.0 min_sum_hessian_in_leaf=1.1997374038636988 num_leaves=41.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #104 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7996355385685444 bagging_freq=8.0 feature_fraction=0.967883423621225 lambda_l1=6.723352598489832 lambda_l2=0.2765417387943505 learning_rate=0.007309375944322416 max_bin=121.0 min_data_in_leaf=42.0 min_sum_hessian_in_leaf=3.3780942685118194 num_leaves=58.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #105 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8335182911136608 bagging_freq=7.0 feature_fraction=0.9067398253414966 lambda_l1=1.6735546428477854 lambda_l2=1.797602994799579 learning_rate=0.0067525242477221555 max_bin=135.0 min_data_in_leaf=34.0 min_sum_hessian_in_leaf=2.3572327184896005 num_leaves=28.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #106 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8008009194301766 bagging_freq=8.0 feature_fraction=0.9174411908852139 lambda_l1=0.6528985999232539 lambda_l2=2.080817751453328 learning_rate=0.005459694423118704 max_bin=125.0 min_data_in_leaf=45.0 min_sum_hessian_in_leaf=3.9042830515262743 num_leaves=30.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #107 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7659483968323942 bagging_freq=7.0 feature_fraction=0.9014430807414058 lambda_l1=4.733204049088696 lambda_l2=6.077615597545179 learning_rate=0.0037806563936850284 max_bin=142.0 min_data_in_leaf=92.0 min_sum_hessian_in_leaf=3.6508347300105615 num_leaves=10.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #108 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7760010135116513 bagging_freq=3.0 feature_fraction=0.9440172794323193 lambda_l1=5.404408080699835 lambda_l2=5.405363394043013 learning_rate=0.0045823130705741665 max_bin=158.0 min_data_in_leaf=91.0 min_sum_hessian_in_leaf=6.557415060238287 num_leaves=99.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM objective call #109 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7880457024874955 bagging_freq=5.0 feature_fraction=0.9632439560615585 lambda_l1=1.1933589542413188 lambda_l2=4.733083129481933 learning_rate=0.004561317156689996 max_bin=159.0 min_data_in_leaf=86.0 min_sum_hessian_in_leaf=7.877015316616964 num_leaves=93.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #110 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9634796369840237 bagging_freq=3.0 feature_fraction=0.9496012772083842 lambda_l1=7.422783684829264 lambda_l2=5.130319876903231 learning_rate=0.0028543196279020126 max_bin=174.0 min_data_in_leaf=78.0 min_sum_hessian_in_leaf=9.143249194460946 num_leaves=50.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #111 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9570880581615357 bagging_freq=5.0 feature_fraction=0.8566367955475547 lambda_l1=9.412809662797706 lambda_l2=9.179922930358384 learning_rate=0.0056605682858113975 max_bin=155.0 min_data_in_leaf=84.0 min_sum_hessian_in_leaf=8.570274890993758 num_leaves=89.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #112 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9340055248703003 bagging_freq=4.0 feature_fraction=0.8645258337539465 lambda_l1=9.21854692412523 lambda_l2=9.205447071866468 learning_rate=0.0098709067767823 max_bin=165.0 min_data_in_leaf=15.0 min_sum_hessian_in_leaf=1.1040896886760472 num_leaves=70.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #113 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9838118595630654 bagging_freq=13.0 feature_fraction=0.9898284325840486 lambda_l1=9.885246072001149 lambda_l2=9.76330804104655 learning_rate=0.009998492100131248 max_bin=161.0 min_data_in_leaf=21.0 min_sum_hessian_in_leaf=1.0371881734227968 num_leaves=76.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #114 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9809323813299266 bagging_freq=11.0 feature_fraction=0.9996970869686261 lambda_l1=8.478711760596042 lambda_l2=9.971375328964692 learning_rate=0.008878281302267107 max_bin=163.0 min_data_in_leaf=17.0 min_sum_hessian_in_leaf=1.2687010491362836 num_leaves=72.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #115 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8075256375555817 bagging_freq=10.0 feature_fraction=0.985731297949051 lambda_l1=0.7947090117229274 lambda_l2=3.903054066250884 learning_rate=0.003218826742344431 max_bin=138.0 min_data_in_leaf=62.0 min_sum_hessian_in_leaf=4.64306816507647 num_leaves=63.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #116 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8235046330923345 bagging_freq=6.0 feature_fraction=0.9360080803568287 lambda_l1=0.5526180976497649 lambda_l2=1.3108244597210965 learning_rate=0.003640660587240032 max_bin=119.0 min_data_in_leaf=63.0 min_sum_hessian_in_leaf=4.304916008846773 num_leaves=61.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #117 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8301322336236716 bagging_freq=1.0 feature_fraction=0.763148318287163 lambda_l1=1.3286692040948551 lambda_l2=6.020425674106403 learning_rate=0.004792872420501436 max_bin=199.0 min_data_in_leaf=98.0 min_sum_hessian_in_leaf=4.178562989801473 num_leaves=60.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #118 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7941226550003625 bagging_freq=6.0 feature_fraction=0.7579534081672407 lambda_l1=0.23988639349732868 lambda_l2=4.865478641776223 learning_rate=0.0026775041051278837 max_bin=98.0 min_data_in_leaf=70.0 min_sum_hessian_in_leaf=3.425456859252237 num_leaves=36.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #119 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8614071271855299 bagging_freq=2.0 feature_fraction=0.8116671654468972 lambda_l1=3.1676107243821114 lambda_l2=5.901726213255042 learning_rate=0.004985866762374141 max_bin=93.0 min_data_in_leaf=93.0 min_sum_hessian_in_leaf=1.8832251202748418 num_leaves=22.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #120 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8425663570325215 bagging_freq=7.0 feature_fraction=0.8408007584052726 lambda_l1=3.5431276043577147 lambda_l2=6.665865281869213 learning_rate=0.007144309046937439 max_bin=190.0 min_data_in_leaf=90.0 min_sum_hessian_in_leaf=9.337583909791437 num_leaves=87.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                     \n",
      "LightGBM objective call #121 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9197070648894159 bagging_freq=7.0 feature_fraction=0.8754726894819437 lambda_l1=2.3795688067417466 lambda_l2=7.174424916841756 learning_rate=0.009001463502709866 max_bin=184.0 min_data_in_leaf=95.0 min_sum_hessian_in_leaf=3.092997503196123 num_leaves=44.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #122 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9896990340806429 bagging_freq=7.0 feature_fraction=0.8955029357192738 lambda_l1=2.578957374512788 lambda_l2=6.759132240543813 learning_rate=0.009072140575260717 max_bin=180.0 min_data_in_leaf=83.0 min_sum_hessian_in_leaf=1.6529014416977192 num_leaves=85.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #123 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.884819580910841 bagging_freq=9.0 feature_fraction=0.9791733668247583 lambda_l1=2.043948757192432 lambda_l2=7.453084276144758 learning_rate=0.00613546169845487 max_bin=178.0 min_data_in_leaf=57.0 min_sum_hessian_in_leaf=2.104367839307749 num_leaves=26.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #124 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8438681471576372 bagging_freq=15.0 feature_fraction=0.9538240053261074 lambda_l1=2.169951414837009 lambda_l2=5.665442537139223 learning_rate=0.008222268156063898 max_bin=168.0 min_data_in_leaf=74.0 min_sum_hessian_in_leaf=1.7600168755591865 num_leaves=41.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #125 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7523707920235719 bagging_freq=14.0 feature_fraction=0.817654271868663 lambda_l1=2.820083907068226 lambda_l2=4.235234601475111 learning_rate=0.0022813153788583734 max_bin=144.0 min_data_in_leaf=54.0 min_sum_hessian_in_leaf=2.59381259767386 num_leaves=32.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #126 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.75578694758366 bagging_freq=9.0 feature_fraction=0.7923327382693534 lambda_l1=1.0515651464896643 lambda_l2=3.470548827130659 learning_rate=0.0018009087212065623 max_bin=130.0 min_data_in_leaf=52.0 min_sum_hessian_in_leaf=1.3799100752258888 num_leaves=39.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #127 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7718704272191201 bagging_freq=9.0 feature_fraction=0.8218712916368672 lambda_l1=6.691241322713172 lambda_l2=3.002218658274035 learning_rate=0.0006776839348422084 max_bin=111.0 min_data_in_leaf=48.0 min_sum_hessian_in_leaf=2.7637767820740415 num_leaves=15.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #128 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8098883944192407 bagging_freq=10.0 feature_fraction=0.8058071366871237 lambda_l1=5.942624517575886 lambda_l2=1.5414024450612653 learning_rate=0.0009779712725456985 max_bin=108.0 min_data_in_leaf=49.0 min_sum_hessian_in_leaf=4.878811674298301 num_leaves=56.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #129 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8584260436206603 bagging_freq=10.0 feature_fraction=0.9096998912347126 lambda_l1=4.161490402880092 lambda_l2=2.8521102405261676 learning_rate=0.00023344212319595468 max_bin=100.0 min_data_in_leaf=57.0 min_sum_hessian_in_leaf=5.96171386739983 num_leaves=56.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #130 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8170562678489524 bagging_freq=15.0 feature_fraction=0.9330535061864805 lambda_l1=5.053418088712389 lambda_l2=2.054527440961052 learning_rate=0.0014770812223630179 max_bin=94.0 min_data_in_leaf=56.0 min_sum_hessian_in_leaf=5.655368260498447 num_leaves=52.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #131 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8731503210073764 bagging_freq=14.0 feature_fraction=0.9620040399297938 lambda_l1=6.267474344845681 lambda_l2=0.8119286328839947 learning_rate=0.000414108850346968 max_bin=147.0 min_data_in_leaf=59.0 min_sum_hessian_in_leaf=5.159042485386687 num_leaves=65.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #132 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8809167000227993 bagging_freq=3.0 feature_fraction=0.9958212623810335 lambda_l1=5.610271277277215 lambda_l2=1.0205046935313693 learning_rate=0.0013563663545858784 max_bin=147.0 min_data_in_leaf=46.0 min_sum_hessian_in_leaf=2.9610558626326586 num_leaves=65.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #133 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9047700100180529 bagging_freq=4.0 feature_fraction=0.9925859664304755 lambda_l1=3.26559990989131 lambda_l2=3.313041495424219 learning_rate=0.0008190906965456546 max_bin=106.0 min_data_in_leaf=39.0 min_sum_hessian_in_leaf=6.630996595196097 num_leaves=47.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #134 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9149873945261562 bagging_freq=8.0 feature_fraction=0.8839546052005393 lambda_l1=4.5426843719183765 lambda_l2=3.7841132904454806 learning_rate=0.0009575962366918699 max_bin=103.0 min_data_in_leaf=40.0 min_sum_hessian_in_leaf=4.0012352714776185 num_leaves=81.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #135 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9460182186009413 bagging_freq=9.0 feature_fraction=0.8880574179590789 lambda_l1=3.70033908733443 lambda_l2=8.582981643972914 learning_rate=0.0019096082087685243 max_bin=106.0 min_data_in_leaf=80.0 min_sum_hessian_in_leaf=7.164743465384315 num_leaves=95.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #136 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9766106267987918 bagging_freq=11.0 feature_fraction=0.913732618881879 lambda_l1=1.495132439268714 lambda_l2=9.051840090543008 learning_rate=0.0020359416338665308 max_bin=133.0 min_data_in_leaf=100.0 min_sum_hessian_in_leaf=2.3312235129141654 num_leaves=74.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #137 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9707049393315876 bagging_freq=11.0 feature_fraction=0.9215623336495692 lambda_l1=4.994296300751969 lambda_l2=8.81286437981079 learning_rate=0.003311268564301922 max_bin=152.0 min_data_in_leaf=79.0 min_sum_hessian_in_leaf=2.0944149713049214 num_leaves=68.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #138 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9978337063731626 bagging_freq=12.0 feature_fraction=0.9275958252241102 lambda_l1=1.7256738244894008 lambda_l2=8.219913092753313 learning_rate=0.0034375820517400717 max_bin=170.0 min_data_in_leaf=100.0 min_sum_hessian_in_leaf=3.564499597235721 num_leaves=79.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #139 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9551860488010642 bagging_freq=13.0 feature_fraction=0.7844777572307722 lambda_l1=7.203992230254518 lambda_l2=8.103674076857171 learning_rate=0.0039805880564611675 max_bin=171.0 min_data_in_leaf=32.0 min_sum_hessian_in_leaf=2.0306198382901304 num_leaves=53.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #140 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.946816110253009 bagging_freq=13.0 feature_fraction=0.8351969483917415 lambda_l1=7.861815344048153 lambda_l2=7.833484497617259 learning_rate=0.005926867935412292 max_bin=149.0 min_data_in_leaf=37.0 min_sum_hessian_in_leaf=1.5998426783521076 num_leaves=46.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #141 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9306195363954852 bagging_freq=12.0 feature_fraction=0.8434841107234923 lambda_l1=8.001188272193504 lambda_l2=9.494393654309352 learning_rate=0.007796360850283049 max_bin=140.0 min_data_in_leaf=26.0 min_sum_hessian_in_leaf=1.1749548356693695 num_leaves=42.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #142 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9406296188389911 bagging_freq=10.0 feature_fraction=0.8296671308976895 lambda_l1=9.589223274172149 lambda_l2=9.413256617743487 learning_rate=0.0077391899469338435 max_bin=127.0 min_data_in_leaf=12.0 min_sum_hessian_in_leaf=1.5284075307202922 num_leaves=48.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #143 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8979466354988207 bagging_freq=8.0 feature_fraction=0.9672845246390587 lambda_l1=6.968973058130568 lambda_l2=0.5080630137168827 learning_rate=0.007307387521997946 max_bin=114.0 min_data_in_leaf=42.0 min_sum_hessian_in_leaf=3.3467523267111887 num_leaves=58.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #144 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7832777410546561 bagging_freq=10.0 feature_fraction=0.7736783448279501 lambda_l1=5.920701219691438 lambda_l2=2.512285724253223 learning_rate=0.0005555415920015479 max_bin=124.0 min_data_in_leaf=55.0 min_sum_hessian_in_leaf=4.875218295021507 num_leaves=26.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #145 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8662174056803708 bagging_freq=15.0 feature_fraction=0.937893173309778 lambda_l1=4.290849540518449 lambda_l2=2.37609327426076 learning_rate=0.0003330905689497932 max_bin=99.0 min_data_in_leaf=65.0 min_sum_hessian_in_leaf=5.475159945206229 num_leaves=52.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #146 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8507976947067459 bagging_freq=14.0 feature_fraction=0.9567138242470337 lambda_l1=5.483488766034255 lambda_l2=0.4756883501420375 learning_rate=0.0011169779034553625 max_bin=145.0 min_data_in_leaf=69.0 min_sum_hessian_in_leaf=4.436715473071065 num_leaves=66.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #147 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8825362229402195 bagging_freq=15.0 feature_fraction=0.9458753258926816 lambda_l1=3.015577507172254 lambda_l2=1.8174419936634085 learning_rate=1.2106332267688809e-05 max_bin=121.0 min_data_in_leaf=60.0 min_sum_hessian_in_leaf=4.5431711727086235 num_leaves=55.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #148 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9038765299565158 bagging_freq=4.0 feature_fraction=0.976867082735603 lambda_l1=3.8382380497678197 lambda_l2=6.335045511350083 learning_rate=0.0013005446767963898 max_bin=175.0 min_data_in_leaf=72.0 min_sum_hessian_in_leaf=4.089818055058592 num_leaves=75.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #149 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8959370529898778 bagging_freq=6.0 feature_fraction=0.8958846875548206 lambda_l1=3.845432503040167 lambda_l2=9.883747686422145 learning_rate=0.0017595852356090424 max_bin=195.0 min_data_in_leaf=77.0 min_sum_hessian_in_leaf=6.832542492357563 num_leaves=90.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #150 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.91033462723832 bagging_freq=8.0 feature_fraction=0.8734254329890262 lambda_l1=3.412732811500938 lambda_l2=4.49593684332162 learning_rate=0.002543101481361734 max_bin=109.0 min_data_in_leaf=87.0 min_sum_hessian_in_leaf=5.114604542852512 num_leaves=81.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #151 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9981207936163567 bagging_freq=9.0 feature_fraction=0.9237053506560035 lambda_l1=2.2944415628729047 lambda_l2=8.421344168583277 learning_rate=0.002333854134566962 max_bin=88.0 min_data_in_leaf=82.0 min_sum_hessian_in_leaf=6.229317344469643 num_leaves=96.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #152 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8915497663538965 bagging_freq=11.0 feature_fraction=0.8685196332368676 lambda_l1=4.399665298568777 lambda_l2=8.806896001230271 learning_rate=0.002947622187630984 max_bin=103.0 min_data_in_leaf=89.0 min_sum_hessian_in_leaf=7.717408068408304 num_leaves=83.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #153 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9716905047936331 bagging_freq=12.0 feature_fraction=0.8480506802292723 lambda_l1=4.0456116796396975 lambda_l2=8.54627062056094 learning_rate=0.0021416795277059064 max_bin=154.0 min_data_in_leaf=75.0 min_sum_hessian_in_leaf=1.9570493260955857 num_leaves=78.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #154 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9673932319837459 bagging_freq=11.0 feature_fraction=0.9060279035640865 lambda_l1=5.216628566821741 lambda_l2=8.225087111348264 learning_rate=0.0031190150565983113 max_bin=156.0 min_data_in_leaf=86.0 min_sum_hessian_in_leaf=3.017629307852529 num_leaves=72.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #155 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9616366638338627 bagging_freq=12.0 feature_fraction=0.7610701211007571 lambda_l1=7.110346176203377 lambda_l2=7.979229429569655 learning_rate=0.0042205506228829796 max_bin=131.0 min_data_in_leaf=24.0 min_sum_hessian_in_leaf=2.8036304086382584 num_leaves=68.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #156 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9500038186087223 bagging_freq=13.0 feature_fraction=0.787010862433628 lambda_l1=8.69886827742393 lambda_l2=7.619581294777176 learning_rate=0.009257049421619187 max_bin=142.0 min_data_in_leaf=66.0 min_sum_hessian_in_leaf=1.335242208969373 num_leaves=50.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #157 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9250264692814807 bagging_freq=11.0 feature_fraction=0.7715372454223778 lambda_l1=7.579795530351528 lambda_l2=7.609050328972546 learning_rate=0.0067510730372084445 max_bin=138.0 min_data_in_leaf=30.0 min_sum_hessian_in_leaf=1.4625443309234127 num_leaves=37.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #158 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9271298990253681 bagging_freq=12.0 feature_fraction=0.7931092666310101 lambda_l1=8.445116300539508 lambda_l2=6.96904793803494 learning_rate=0.005322989370074177 max_bin=134.0 min_data_in_leaf=36.0 min_sum_hessian_in_leaf=1.211381449373524 num_leaves=34.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #159 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9383778243279235 bagging_freq=8.0 feature_fraction=0.9711290775557526 lambda_l1=6.689765253238532 lambda_l2=0.13506354239407561 learning_rate=0.008647906960121694 max_bin=117.0 min_data_in_leaf=32.0 min_sum_hessian_in_leaf=1.0212400033928175 num_leaves=49.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #160 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9861886197348411 bagging_freq=10.0 feature_fraction=0.8337391218468395 lambda_l1=7.740005323435623 lambda_l2=7.294188204934772 learning_rate=0.007995959400562733 max_bin=121.0 min_data_in_leaf=42.0 min_sum_hessian_in_leaf=3.259440583486629 num_leaves=44.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #161 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8286933534575418 bagging_freq=7.0 feature_fraction=0.9651365840533255 lambda_l1=8.875813380594334 lambda_l2=0.2414157335254552 learning_rate=0.009707861485354942 max_bin=137.0 min_data_in_leaf=34.0 min_sum_hessian_in_leaf=2.351949530722721 num_leaves=20.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #162 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8330660129612281 bagging_freq=6.0 feature_fraction=0.972145043469425 lambda_l1=6.8332766057544 lambda_l2=1.482201757828617 learning_rate=0.006748956761420327 max_bin=141.0 min_data_in_leaf=44.0 min_sum_hessian_in_leaf=2.597703164662865 num_leaves=30.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #163 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8035799474950376 bagging_freq=7.0 feature_fraction=0.947209764223237 lambda_l1=0.9555077698826178 lambda_l2=1.2257024427098122 learning_rate=0.0062393649406023224 max_bin=126.0 min_data_in_leaf=45.0 min_sum_hessian_in_leaf=3.493572882552821 num_leaves=23.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #164 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7626929361229458 bagging_freq=5.0 feature_fraction=0.9186405325505747 lambda_l1=0.6247354151864505 lambda_l2=1.9644159036984206 learning_rate=0.0037411854850593405 max_bin=129.0 min_data_in_leaf=40.0 min_sum_hessian_in_leaf=3.149925417756998 num_leaves=13.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #165 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7758316741319338 bagging_freq=6.0 feature_fraction=0.9437289834490992 lambda_l1=5.827085095493494 lambda_l2=5.378073621253528 learning_rate=0.005545628801623824 max_bin=159.0 min_data_in_leaf=92.0 min_sum_hessian_in_leaf=3.7186842499359725 num_leaves=14.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #166 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7595482171511294 bagging_freq=5.0 feature_fraction=0.9123427073088609 lambda_l1=4.804890143101968 lambda_l2=6.23772065434694 learning_rate=0.0044595700569337125 max_bin=151.0 min_data_in_leaf=92.0 min_sum_hessian_in_leaf=3.854075795635885 num_leaves=11.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #167 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.789744299051302 bagging_freq=3.0 feature_fraction=0.9298455417784562 lambda_l1=6.124898202468829 lambda_l2=5.509158125138683 learning_rate=0.004666305452773072 max_bin=158.0 min_data_in_leaf=85.0 min_sum_hessian_in_leaf=7.820374160083963 num_leaves=97.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #168 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.785902639067163 bagging_freq=5.0 feature_fraction=0.9423518845919355 lambda_l1=6.4137522647022145 lambda_l2=5.210924169814605 learning_rate=0.004493762936958849 max_bin=166.0 min_data_in_leaf=90.0 min_sum_hessian_in_leaf=8.344190720874336 num_leaves=91.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #169 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7766853338435086 bagging_freq=3.0 feature_fraction=0.9848507996496847 lambda_l1=1.1861967868434153 lambda_l2=4.364741778336959 learning_rate=0.0027188873942704324 max_bin=185.0 min_data_in_leaf=78.0 min_sum_hessian_in_leaf=8.91632650672808 num_leaves=86.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #170 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8216781649778256 bagging_freq=2.0 feature_fraction=0.9526965563560273 lambda_l1=1.9153796923756847 lambda_l2=5.0050629215854725 learning_rate=0.0028785498356539737 max_bin=175.0 min_data_in_leaf=83.0 min_sum_hessian_in_leaf=9.467623427540053 num_leaves=99.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #171 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9610246425114991 bagging_freq=5.0 feature_fraction=0.8570809312617448 lambda_l1=9.330790198017114 lambda_l2=5.139460908507797 learning_rate=0.004837843557209202 max_bin=164.0 min_data_in_leaf=85.0 min_sum_hessian_in_leaf=8.44226183765284 num_leaves=89.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #172 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9573079226505518 bagging_freq=4.0 feature_fraction=0.8409772585937608 lambda_l1=9.35615242120625 lambda_l2=9.19141812036276 learning_rate=0.003512991094087859 max_bin=166.0 min_data_in_leaf=71.0 min_sum_hessian_in_leaf=9.775241762911376 num_leaves=63.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #173 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9332622611972027 bagging_freq=4.0 feature_fraction=0.8577834074253751 lambda_l1=9.662653426841091 lambda_l2=9.830715058148577 learning_rate=0.009869924017224658 max_bin=161.0 min_data_in_leaf=21.0 min_sum_hessian_in_leaf=1.1119307213969793 num_leaves=76.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #174 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9815429864365173 bagging_freq=3.0 feature_fraction=0.8641016778974426 lambda_l1=9.139990730990839 lambda_l2=9.180414286093956 learning_rate=0.009485624892388696 max_bin=162.0 min_data_in_leaf=11.0 min_sum_hessian_in_leaf=1.1321793174084027 num_leaves=80.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #175 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9801065411530957 bagging_freq=13.0 feature_fraction=0.8506748822987085 lambda_l1=9.96897297675315 lambda_l2=9.654199668418554 learning_rate=0.00974807021001869 max_bin=191.0 min_data_in_leaf=17.0 min_sum_hessian_in_leaf=1.0244225232138622 num_leaves=70.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #176 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9853390255505109 bagging_freq=13.0 feature_fraction=0.991449257718457 lambda_l1=8.39266226043579 lambda_l2=8.993151582365087 learning_rate=0.00881052948994536 max_bin=165.0 min_data_in_leaf=19.0 min_sum_hessian_in_leaf=1.252048043379442 num_leaves=72.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #177 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9909351010433775 bagging_freq=11.0 feature_fraction=0.999244375994618 lambda_l1=9.830646257137477 lambda_l2=3.736778078683414 learning_rate=0.008512829032946501 max_bin=156.0 min_data_in_leaf=63.0 min_sum_hessian_in_leaf=4.679142221858141 num_leaves=76.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #178 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9949009488882496 bagging_freq=10.0 feature_fraction=0.9897663858288521 lambda_l1=0.8516549348686053 lambda_l2=9.99075663615028 learning_rate=0.009264581548582583 max_bin=144.0 min_data_in_leaf=24.0 min_sum_hessian_in_leaf=1.292018640955311 num_leaves=61.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #179 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8063291029061281 bagging_freq=9.0 feature_fraction=0.9855080872692534 lambda_l1=0.2915691317677815 lambda_l2=3.4869307423433886 learning_rate=0.0032004549633730685 max_bin=119.0 min_data_in_leaf=62.0 min_sum_hessian_in_leaf=4.1867927988016405 num_leaves=62.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #180 cur_best_score=0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: bagging_fraction=0.7947841024025808 bagging_freq=6.0 feature_fraction=0.9590330659223989 lambda_l1=0.05161392184898084 lambda_l2=6.007509557615485 learning_rate=0.004077384677476408 max_bin=123.0 min_data_in_leaf=63.0 min_sum_hessian_in_leaf=4.321335082083836 num_leaves=60.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #181 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8204710658150945 bagging_freq=6.0 feature_fraction=0.7626385500247342 lambda_l1=1.3991860411291444 lambda_l2=5.741294452586691 learning_rate=0.0026133638510624957 max_bin=97.0 min_data_in_leaf=69.0 min_sum_hessian_in_leaf=3.4591177706612157 num_leaves=55.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #182 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8129068199959429 bagging_freq=1.0 feature_fraction=0.7772799664469993 lambda_l1=0.3888857505511419 lambda_l2=6.630086828748323 learning_rate=0.004242702786782275 max_bin=114.0 min_data_in_leaf=75.0 min_sum_hessian_in_leaf=2.888770398128131 num_leaves=60.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #183 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8615859767827959 bagging_freq=1.0 feature_fraction=0.7990133419291868 lambda_l1=2.691023782534091 lambda_l2=5.820985629059691 learning_rate=0.005044015914801759 max_bin=94.0 min_data_in_leaf=93.0 min_sum_hessian_in_leaf=1.8535632424477035 num_leaves=36.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #184 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8477038365291044 bagging_freq=2.0 feature_fraction=0.756157523916016 lambda_l1=3.188083938531031 lambda_l2=4.80868335486998 learning_rate=0.00522077133382608 max_bin=91.0 min_data_in_leaf=97.0 min_sum_hessian_in_leaf=2.691766648637258 num_leaves=21.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #185 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8417739930795543 bagging_freq=7.0 feature_fraction=0.8027493675708358 lambda_l1=2.4021296678036546 lambda_l2=6.532718925527313 learning_rate=0.005757777507746832 max_bin=98.0 min_data_in_leaf=88.0 min_sum_hessian_in_leaf=2.5149548987711494 num_leaves=16.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #186 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8479945905084947 bagging_freq=6.0 feature_fraction=0.8114726891267072 lambda_l1=2.9717974504925144 lambda_l2=6.8083728281219775 learning_rate=0.007072837139093251 max_bin=92.0 min_data_in_leaf=95.0 min_sum_hessian_in_leaf=1.8172782941305805 num_leaves=18.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #187 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8536914845707695 bagging_freq=7.0 feature_fraction=0.8264836488303974 lambda_l1=3.500807756801338 lambda_l2=7.057156035081583 learning_rate=0.007631573179521579 max_bin=190.0 min_data_in_leaf=94.0 min_sum_hessian_in_leaf=1.6698471178420724 num_leaves=27.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #188 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8704169710138433 bagging_freq=7.0 feature_fraction=0.876512933218092 lambda_l1=2.531575379439871 lambda_l2=6.712743058937146 learning_rate=0.00817045977235949 max_bin=181.0 min_data_in_leaf=83.0 min_sum_hessian_in_leaf=1.6540331111700788 num_leaves=85.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #189 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9183113675625868 bagging_freq=8.0 feature_fraction=0.8998534476001905 lambda_l1=1.8325065574637738 lambda_l2=7.131581604941333 learning_rate=0.009142691405842195 max_bin=178.0 min_data_in_leaf=67.0 min_sum_hessian_in_leaf=2.1982524819946736 num_leaves=25.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #190 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8871385862326133 bagging_freq=9.0 feature_fraction=0.8901563659946168 lambda_l1=2.074730469245143 lambda_l2=7.565153489720563 learning_rate=0.00900071893087458 max_bin=184.0 min_data_in_leaf=52.0 min_sum_hessian_in_leaf=2.137419068373704 num_leaves=30.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #191 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8436745170115576 bagging_freq=8.0 feature_fraction=0.9784091234445836 lambda_l1=2.268112016778475 lambda_l2=7.3857687606511435 learning_rate=0.008278168849981515 max_bin=187.0 min_data_in_leaf=76.0 min_sum_hessian_in_leaf=1.7524639130257724 num_leaves=39.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM objective call #192 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8385837973134633 bagging_freq=9.0 feature_fraction=0.9790906791556837 lambda_l1=2.011040991997406 lambda_l2=6.308800134815252 learning_rate=0.008643773208174596 max_bin=197.0 min_data_in_leaf=73.0 min_sum_hessian_in_leaf=1.9833388288133182 num_leaves=33.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #193 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7528211412611899 bagging_freq=14.0 feature_fraction=0.8195899544598431 lambda_l1=2.838316449466363 lambda_l2=4.00391307538357 learning_rate=0.007295695256383875 max_bin=177.0 min_data_in_leaf=58.0 min_sum_hessian_in_leaf=2.2511039688729415 num_leaves=41.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #194 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7984979189454587 bagging_freq=15.0 feature_fraction=0.973965795751421 lambda_l1=1.6050589656527783 lambda_l2=4.571204657468233 learning_rate=0.0022972899857404156 max_bin=168.0 min_data_in_leaf=53.0 min_sum_hessian_in_leaf=1.3976951643048345 num_leaves=31.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #195 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7690438931787859 bagging_freq=15.0 feature_fraction=0.7942845563372326 lambda_l1=2.7278867226223182 lambda_l2=3.187908962856006 learning_rate=0.002151237340183312 max_bin=144.0 min_data_in_leaf=54.0 min_sum_hessian_in_leaf=1.3999240513531697 num_leaves=39.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #196 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7513338108473385 bagging_freq=9.0 feature_fraction=0.8163162543498927 lambda_l1=0.9651128032065406 lambda_l2=2.9356087947564395 learning_rate=0.0014881076965916743 max_bin=112.0 min_data_in_leaf=48.0 min_sum_hessian_in_leaf=2.4069627066073593 num_leaves=14.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #197 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7725864219315148 bagging_freq=10.0 feature_fraction=0.7681674281069175 lambda_l1=7.374098997905903 lambda_l2=1.5237330705576093 learning_rate=0.0009050764993459311 max_bin=111.0 min_data_in_leaf=49.0 min_sum_hessian_in_leaf=4.820945061545006 num_leaves=57.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #198 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7815150423107332 bagging_freq=10.0 feature_fraction=0.8104670390224255 lambda_l1=6.440529725509303 lambda_l2=3.430029807692206 learning_rate=0.0017333992812081178 max_bin=107.0 min_data_in_leaf=50.0 min_sum_hessian_in_leaf=3.680938169522737 num_leaves=54.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #199 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8112168015881286 bagging_freq=10.0 feature_fraction=0.8237946307696231 lambda_l1=6.019742204034361 lambda_l2=2.7738678749683428 learning_rate=0.00024263468370969922 max_bin=101.0 min_data_in_leaf=47.0 min_sum_hessian_in_leaf=5.742979983115584 num_leaves=57.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #200 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.826686124430022 bagging_freq=10.0 feature_fraction=0.7989072930394328 lambda_l1=5.441554901824646 lambda_l2=1.7056072171087846 learning_rate=6.135337619508734e-07 max_bin=110.0 min_data_in_leaf=58.0 min_sum_hessian_in_leaf=5.2380710937106665 num_leaves=51.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #201 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8168597144346089 bagging_freq=11.0 feature_fraction=0.9325698895912974 lambda_l1=5.109173567746157 lambda_l2=2.1710352308507925 learning_rate=0.0005169907261724746 max_bin=88.0 min_data_in_leaf=56.0 min_sum_hessian_in_leaf=5.936742662370392 num_leaves=46.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #202 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8146276927823037 bagging_freq=8.0 feature_fraction=0.9068500604902464 lambda_l1=4.521749920983303 lambda_l2=2.572539971230449 learning_rate=0.0011952452972989126 max_bin=95.0 min_data_in_leaf=61.0 min_sum_hessian_in_leaf=5.704703214144515 num_leaves=53.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #203 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8601427069531198 bagging_freq=14.0 feature_fraction=0.9367264074721974 lambda_l1=6.294488816861192 lambda_l2=0.7857442276242805 learning_rate=0.0004641065715687651 max_bin=147.0 min_data_in_leaf=65.0 min_sum_hessian_in_leaf=6.086000590444517 num_leaves=63.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                     \n",
      "LightGBM objective call #204 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8756714161188778 bagging_freq=14.0 feature_fraction=0.9971016734511593 lambda_l1=5.60655638137022 lambda_l2=0.8566192303319585 learning_rate=0.0008334569361320232 max_bin=150.0 min_data_in_leaf=51.0 min_sum_hessian_in_leaf=6.692348767744209 num_leaves=66.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #205 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9060875636797905 bagging_freq=3.0 feature_fraction=0.9931684780451309 lambda_l1=4.706250354657867 lambda_l2=0.004073333518461064 learning_rate=0.000737053734782716 max_bin=148.0 min_data_in_leaf=38.0 min_sum_hessian_in_leaf=6.90910386301487 num_leaves=65.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #206 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8801541770071076 bagging_freq=3.0 feature_fraction=0.9995270115296311 lambda_l1=5.329597768965479 lambda_l2=1.1377269542470074 learning_rate=0.0016145677554108171 max_bin=133.0 min_data_in_leaf=39.0 min_sum_hessian_in_leaf=5.019043840792253 num_leaves=67.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #207 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9146170860503989 bagging_freq=2.0 feature_fraction=0.965527587190285 lambda_l1=3.303564643292654 lambda_l2=3.253028923751258 learning_rate=0.0013740316257494823 max_bin=116.0 min_data_in_leaf=27.0 min_sum_hessian_in_leaf=4.065280602715143 num_leaves=74.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #208 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9010727157167923 bagging_freq=4.0 feature_fraction=0.9955819319395904 lambda_l1=4.311297227683211 lambda_l2=1.0857639441675908 learning_rate=0.0019437541144525891 max_bin=135.0 min_data_in_leaf=40.0 min_sum_hessian_in_leaf=2.9632879732577457 num_leaves=82.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #209 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9435635028196292 bagging_freq=8.0 feature_fraction=0.8689844390248832 lambda_l1=4.09299341471043 lambda_l2=2.40242037182165 learning_rate=0.0010421761873376997 max_bin=104.0 min_data_in_leaf=33.0 min_sum_hessian_in_leaf=7.450706516856798 num_leaves=95.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #210 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9149193317164254 bagging_freq=9.0 feature_fraction=0.897950588690486 lambda_l1=3.6200959475842036 lambda_l2=4.264143363179999 learning_rate=0.0023994182474538083 max_bin=106.0 min_data_in_leaf=27.0 min_sum_hessian_in_leaf=6.48640785485726 num_leaves=94.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #211 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9780008945776778 bagging_freq=9.0 feature_fraction=0.885197525135176 lambda_l1=3.766321411530723 lambda_l2=8.600214393396218 learning_rate=0.0019477520700222014 max_bin=102.0 min_data_in_leaf=69.0 min_sum_hessian_in_leaf=7.125322658526059 num_leaves=92.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #212 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9753438415546404 bagging_freq=11.0 feature_fraction=0.9133179515489439 lambda_l1=1.5284446538609964 lambda_l2=8.796607138796716 learning_rate=0.0034537546807522123 max_bin=140.0 min_data_in_leaf=80.0 min_sum_hessian_in_leaf=2.316850060896757 num_leaves=70.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #213 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.998838768428189 bagging_freq=12.0 feature_fraction=0.9277166119172933 lambda_l1=1.6823394752129084 lambda_l2=8.930266031374735 learning_rate=0.003307195748455958 max_bin=151.0 min_data_in_leaf=100.0 min_sum_hessian_in_leaf=3.12734487247757 num_leaves=74.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #214 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9663290641574868 bagging_freq=12.0 feature_fraction=0.9135796503800823 lambda_l1=0.4912990107613513 lambda_l2=8.1456722108236 learning_rate=0.003015617864645742 max_bin=153.0 min_data_in_leaf=99.0 min_sum_hessian_in_leaf=2.585213539215208 num_leaves=79.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #215 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.970878491095744 bagging_freq=13.0 feature_fraction=0.9174282855389785 lambda_l1=7.34552878072709 lambda_l2=7.939661685691171 learning_rate=0.003660673804875937 max_bin=156.0 min_data_in_leaf=73.0 min_sum_hessian_in_leaf=2.1214601447841788 num_leaves=77.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #216 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9559706410308402 bagging_freq=13.0 feature_fraction=0.9232468043121469 lambda_l1=8.222050948473761 lambda_l2=8.316212333259557 learning_rate=0.0038766501779179873 max_bin=171.0 min_data_in_leaf=70.0 min_sum_hessian_in_leaf=2.0344981664089854 num_leaves=70.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #217 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9536217360602383 bagging_freq=13.0 feature_fraction=0.8797322409494371 lambda_l1=7.9823490435884805 lambda_l2=7.862102481221503 learning_rate=0.0049253741323262695 max_bin=192.0 min_data_in_leaf=36.0 min_sum_hessian_in_leaf=1.5140269442119028 num_leaves=46.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #218 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9498526358136292 bagging_freq=12.0 feature_fraction=0.7818117775236126 lambda_l1=7.212325561899171 lambda_l2=7.813146504485903 learning_rate=0.003986930619400445 max_bin=173.0 min_data_in_leaf=29.0 min_sum_hessian_in_leaf=1.610302085933759 num_leaves=43.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #219 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9457548348396826 bagging_freq=14.0 feature_fraction=0.8298295151519617 lambda_l1=7.9563992932256316 lambda_l2=8.374525103810448 learning_rate=0.006360175634816452 max_bin=138.0 min_data_in_leaf=15.0 min_sum_hessian_in_leaf=1.3311168988031945 num_leaves=48.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #220 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.930732583345107 bagging_freq=13.0 feature_fraction=0.8386928932466562 lambda_l1=8.639573541981513 lambda_l2=9.565408582423974 learning_rate=0.006005751296338978 max_bin=128.0 min_data_in_leaf=22.0 min_sum_hessian_in_leaf=1.1634586681793606 num_leaves=43.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #221 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9374170553000347 bagging_freq=8.0 feature_fraction=0.8451539786947943 lambda_l1=6.990684665828626 lambda_l2=9.730383049704095 learning_rate=0.007633101598794097 max_bin=131.0 min_data_in_leaf=19.0 min_sum_hessian_in_leaf=3.3909476526214695 num_leaves=58.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #222 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9235936346847765 bagging_freq=10.0 feature_fraction=0.8444513832646967 lambda_l1=9.566932890361144 lambda_l2=9.37768511731555 learning_rate=0.007952481884510256 max_bin=127.0 min_data_in_leaf=26.0 min_sum_hessian_in_leaf=1.0796216098325053 num_leaves=41.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #223 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8975776028888324 bagging_freq=8.0 feature_fraction=0.7512979854612188 lambda_l1=6.937030541085628 lambda_l2=0.34967508591210894 learning_rate=0.007311327696750925 max_bin=125.0 min_data_in_leaf=55.0 min_sum_hessian_in_leaf=3.847531598258065 num_leaves=28.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #224 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9395128666444155 bagging_freq=10.0 feature_fraction=0.805576691369519 lambda_l1=5.9612012321103665 lambda_l2=0.5030969465901618 learning_rate=0.006861575471972663 max_bin=123.0 min_data_in_leaf=12.0 min_sum_hessian_in_leaf=3.2794420168832357 num_leaves=49.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #225 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.864329486199831 bagging_freq=7.0 feature_fraction=0.9565678685054512 lambda_l1=5.851214721769793 lambda_l2=2.5177034563749245 learning_rate=0.00024164956021474637 max_bin=114.0 min_data_in_leaf=43.0 min_sum_hessian_in_leaf=5.494008381257934 num_leaves=52.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #226 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8679990836090123 bagging_freq=6.0 feature_fraction=0.9673784294575258 lambda_l1=6.627540679860725 lambda_l2=0.5933462042796243 learning_rate=0.006508033035659134 max_bin=116.0 min_data_in_leaf=64.0 min_sum_hessian_in_leaf=4.521203271875592 num_leaves=59.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #227 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8540851580962451 bagging_freq=15.0 feature_fraction=0.9401415475645936 lambda_l1=4.852276533403039 lambda_l2=1.844193141985396 learning_rate=0.0006350738027380003 max_bin=120.0 min_data_in_leaf=67.0 min_sum_hessian_in_leaf=4.823909845642336 num_leaves=65.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #228 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8839164788863645 bagging_freq=15.0 feature_fraction=0.9475724824140047 lambda_l1=3.125137176068469 lambda_l2=2.2313022233486093 learning_rate=0.00016248853983081337 max_bin=144.0 min_data_in_leaf=61.0 min_sum_hessian_in_leaf=5.546701399014163 num_leaves=56.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #229 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8926008668254097 bagging_freq=4.0 feature_fraction=0.981086181642696 lambda_l1=4.471623918518716 lambda_l2=6.289142053010831 learning_rate=0.0011739955029952912 max_bin=146.0 min_data_in_leaf=68.0 min_sum_hessian_in_leaf=4.376848692765159 num_leaves=72.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #230 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8761510271701076 bagging_freq=1.0 feature_fraction=0.9555788490351206 lambda_l1=2.9646979800128115 lambda_l2=0.35716943897288744 learning_rate=0.0013012402621655258 max_bin=136.0 min_data_in_leaf=71.0 min_sum_hessian_in_leaf=4.4263721245546686 num_leaves=67.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #231 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8953943237781569 bagging_freq=5.0 feature_fraction=0.9745719475935052 lambda_l1=4.036624678651998 lambda_l2=6.0960766478179735 learning_rate=0.002596704335848912 max_bin=200.0 min_data_in_leaf=77.0 min_sum_hessian_in_leaf=8.094480534380208 num_leaves=84.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #232 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9099455595954952 bagging_freq=4.0 feature_fraction=0.9500919470136089 lambda_l1=3.873816062531804 lambda_l2=6.929666460683521 learning_rate=1.2276051280153012e-05 max_bin=193.0 min_data_in_leaf=79.0 min_sum_hessian_in_leaf=3.5793327114902005 num_leaves=83.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #233 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9037468716448017 bagging_freq=5.0 feature_fraction=0.8959517784711404 lambda_l1=3.4521999038743703 lambda_l2=4.86068062452591 learning_rate=0.001638055712756041 max_bin=195.0 min_data_in_leaf=86.0 min_sum_hessian_in_leaf=5.196237504461785 num_leaves=89.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #234 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8891594330136268 bagging_freq=6.0 feature_fraction=0.8736275278714823 lambda_l1=3.9558675447632043 lambda_l2=4.510635548167211 learning_rate=0.002514864098306019 max_bin=199.0 min_data_in_leaf=82.0 min_sum_hessian_in_leaf=4.098849336379891 num_leaves=87.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #235 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9921602713728884 bagging_freq=7.0 feature_fraction=0.9031654312627758 lambda_l1=2.500971855977341 lambda_l2=8.546397086139939 learning_rate=0.002242101070208782 max_bin=109.0 min_data_in_leaf=88.0 min_sum_hessian_in_leaf=6.083149904265635 num_leaves=96.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #236 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9083283985422204 bagging_freq=9.0 feature_fraction=0.8548335045594897 lambda_l1=3.376260799629595 lambda_l2=8.69184658439211 learning_rate=0.0029932019927920387 max_bin=93.0 min_data_in_leaf=89.0 min_sum_hessian_in_leaf=7.926052236941442 num_leaves=100.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #237 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9705629707250543 bagging_freq=11.0 feature_fraction=0.849575852040539 lambda_l1=4.237606989824963 lambda_l2=8.515463531281851 learning_rate=0.0029557224603108173 max_bin=89.0 min_data_in_leaf=81.0 min_sum_hessian_in_leaf=8.646566995804422 num_leaves=92.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #238 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9888830664789251 bagging_freq=11.0 feature_fraction=0.86044481533919 lambda_l1=4.44211502030854 lambda_l2=7.258501604941333 learning_rate=0.0027546332397430685 max_bin=154.0 min_data_in_leaf=75.0 min_sum_hessian_in_leaf=7.474601846642794 num_leaves=90.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #239 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9644169273229319 bagging_freq=12.0 feature_fraction=0.8668051670904997 lambda_l1=5.23123219917237 lambda_l2=8.210515452247897 learning_rate=0.00436188476745208 max_bin=157.0 min_data_in_leaf=96.0 min_sum_hessian_in_leaf=1.9125362799587107 num_leaves=77.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #240 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9590179583512364 bagging_freq=11.0 feature_fraction=0.8625727753372181 lambda_l1=4.674539615484123 lambda_l2=8.84871382750021 learning_rate=0.0032749356037018555 max_bin=159.0 min_data_in_leaf=85.0 min_sum_hessian_in_leaf=2.869555557183259 num_leaves=79.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #241 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9640601015768081 bagging_freq=12.0 feature_fraction=0.906072905032806 lambda_l1=7.699580740002782 lambda_l2=8.054179477656849 learning_rate=0.0042579748886000576 max_bin=142.0 min_data_in_leaf=75.0 min_sum_hessian_in_leaf=2.8134586086528244 num_leaves=69.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #242 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.985500848944488 bagging_freq=12.0 feature_fraction=0.774011859215854 lambda_l1=4.938343599957854 lambda_l2=7.463129521646062 learning_rate=0.0036292294587914626 max_bin=132.0 min_data_in_leaf=72.0 min_sum_hessian_in_leaf=2.6820441409812568 num_leaves=72.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #243 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9778961057124197 bagging_freq=13.0 feature_fraction=0.7855307958212884 lambda_l1=9.058791669937332 lambda_l2=7.67357358672027 learning_rate=0.004137699922887947 max_bin=130.0 min_data_in_leaf=66.0 min_sum_hessian_in_leaf=3.03318414956641 num_leaves=62.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #244 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9523455953226444 bagging_freq=14.0 feature_fraction=0.771659181118626 lambda_l1=8.175685081841815 lambda_l2=7.600430347722157 learning_rate=0.005338753382270871 max_bin=138.0 min_data_in_leaf=13.0 min_sum_hessian_in_leaf=1.431799981403571 num_leaves=50.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #245 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9284020818821256 bagging_freq=13.0 feature_fraction=0.7902607810103766 lambda_l1=8.644763570417076 lambda_l2=6.882617485185136 learning_rate=0.006689879142604018 max_bin=135.0 min_data_in_leaf=30.0 min_sum_hessian_in_leaf=1.2265611013178341 num_leaves=37.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #246 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.934268682128696 bagging_freq=12.0 feature_fraction=0.7686552834996179 lambda_l1=8.771227728979346 lambda_l2=7.066627550035188 learning_rate=0.005507364669949744 max_bin=141.0 min_data_in_leaf=36.0 min_sum_hessian_in_leaf=1.493808333384791 num_leaves=34.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #247 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9200908686325839 bagging_freq=9.0 feature_fraction=0.7538298940558356 lambda_l1=7.5676801398535085 lambda_l2=6.434067802613195 learning_rate=0.00588034314697508 max_bin=128.0 min_data_in_leaf=23.0 min_sum_hessian_in_leaf=1.0458701083978295 num_leaves=35.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #248 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9386734002432034 bagging_freq=11.0 feature_fraction=0.7786074770104233 lambda_l1=8.402456778410357 lambda_l2=5.5578992567048076 learning_rate=0.006163289539933231 max_bin=118.0 min_data_in_leaf=32.0 min_sum_hessian_in_leaf=1.0490813744711913 num_leaves=19.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #249 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.995273624002042 bagging_freq=8.0 feature_fraction=0.7967619229511302 lambda_l1=8.92900014455382 lambda_l2=7.3643772982251265 learning_rate=0.008577256537303578 max_bin=117.0 min_data_in_leaf=45.0 min_sum_hessian_in_leaf=3.3144073918538868 num_leaves=43.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #250 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9877276069651946 bagging_freq=10.0 feature_fraction=0.7945820796007689 lambda_l1=7.746415129721292 lambda_l2=7.26694749086453 learning_rate=0.009641046983755338 max_bin=120.0 min_data_in_leaf=42.0 min_sum_hessian_in_leaf=3.1486851659193893 num_leaves=33.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #251 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8320097428422695 bagging_freq=7.0 feature_fraction=0.9862289966749473 lambda_l1=6.65597755124172 lambda_l2=0.1914916786137799 learning_rate=0.008063199233465084 max_bin=121.0 min_data_in_leaf=34.0 min_sum_hessian_in_leaf=3.792828297992378 num_leaves=20.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #252 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8273237829627323 bagging_freq=6.0 feature_fraction=0.9672202132604933 lambda_l1=8.99277424282559 lambda_l2=1.4046507067511278 learning_rate=0.009437471393200551 max_bin=134.0 min_data_in_leaf=44.0 min_sum_hessian_in_leaf=2.4406417124685404 num_leaves=24.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #253 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8063949501839351 bagging_freq=7.0 feature_fraction=0.9601367254837686 lambda_l1=0.8915788219774984 lambda_l2=1.198166226601187 learning_rate=0.006317767696663286 max_bin=126.0 min_data_in_leaf=45.0 min_sum_hessian_in_leaf=2.6292802666445287 num_leaves=29.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #254 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8328287087149738 bagging_freq=6.0 feature_fraction=0.9459763697698095 lambda_l1=0.6062874113035297 lambda_l2=1.4140881771723088 learning_rate=0.00624283059621681 max_bin=137.0 min_data_in_leaf=34.0 min_sum_hessian_in_leaf=3.499579959992513 num_leaves=17.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #255 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7634867168870408 bagging_freq=5.0 feature_fraction=0.9335186813559098 lambda_l1=0.18454705255103354 lambda_l2=1.9945837830487991 learning_rate=0.0045592936571977796 max_bin=129.0 min_data_in_leaf=41.0 min_sum_hessian_in_leaf=3.1045832966200417 num_leaves=23.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #256 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7914696858933447 bagging_freq=5.0 feature_fraction=0.919860834573639 lambda_l1=1.1628330153088884 lambda_l2=1.9533014102635433 learning_rate=0.0057424833020205054 max_bin=123.0 min_data_in_leaf=38.0 min_sum_hessian_in_leaf=2.5705716284371745 num_leaves=12.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #257 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7604607442923608 bagging_freq=5.0 feature_fraction=0.9415575240589082 lambda_l1=1.1379966442376381 lambda_l2=2.8138139041938963 learning_rate=0.0055076339090749825 max_bin=152.0 min_data_in_leaf=47.0 min_sum_hessian_in_leaf=3.2456372224052967 num_leaves=14.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #258 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.757781974379391 bagging_freq=5.0 feature_fraction=0.9264227036991339 lambda_l1=0.5765085186700305 lambda_l2=5.696550328718848 learning_rate=0.004571097573654683 max_bin=149.0 min_data_in_leaf=98.0 min_sum_hessian_in_leaf=3.6586472848356943 num_leaves=10.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #259 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7709483302496934 bagging_freq=3.0 feature_fraction=0.9301033132379768 lambda_l1=6.28905400147252 lambda_l2=5.402272834286762 learning_rate=0.00513774624459151 max_bin=160.0 min_data_in_leaf=94.0 min_sum_hessian_in_leaf=3.870043344524735 num_leaves=10.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #260 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7781648304837249 bagging_freq=4.0 feature_fraction=0.9416093682386122 lambda_l1=6.454340974048254 lambda_l2=5.28616689537111 learning_rate=0.004791038376058074 max_bin=164.0 min_data_in_leaf=90.0 min_sum_hessian_in_leaf=9.697098878128292 num_leaves=11.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #261 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7822510312323241 bagging_freq=2.0 feature_fraction=0.9855511419133874 lambda_l1=5.488640711287801 lambda_l2=5.17432694110275 learning_rate=0.004564849624061614 max_bin=168.0 min_data_in_leaf=91.0 min_sum_hessian_in_leaf=8.953716726669414 num_leaves=98.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #262 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7862699519331617 bagging_freq=3.0 feature_fraction=0.9528108204678679 lambda_l1=5.9745597253407565 lambda_l2=4.158481790963083 learning_rate=0.003980714502756597 max_bin=185.0 min_data_in_leaf=92.0 min_sum_hessian_in_leaf=8.257821809447943 num_leaves=86.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #263 cur_best_score=0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: bagging_fraction=0.7898051280723417 bagging_freq=2.0 feature_fraction=0.961397224167127 lambda_l1=1.8484431905942462 lambda_l2=3.624225241912188 learning_rate=0.0027402349149146855 max_bin=176.0 min_data_in_leaf=84.0 min_sum_hessian_in_leaf=9.402092665162792 num_leaves=100.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #264 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8036531631879138 bagging_freq=2.0 feature_fraction=0.9820970788727794 lambda_l1=6.190017543295651 lambda_l2=5.0623841082131245 learning_rate=0.0034220792971530072 max_bin=183.0 min_data_in_leaf=78.0 min_sum_hessian_in_leaf=8.846093782137453 num_leaves=98.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #265 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7971363889107413 bagging_freq=1.0 feature_fraction=0.9726153026755849 lambda_l1=2.0403781238544054 lambda_l2=3.887364659910502 learning_rate=0.0037188681771857805 max_bin=187.0 min_data_in_leaf=83.0 min_sum_hessian_in_leaf=9.9602325281397 num_leaves=88.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #266 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8213453981226753 bagging_freq=1.0 feature_fraction=0.9772129452189464 lambda_l1=2.1716619736891882 lambda_l2=4.973664581783206 learning_rate=0.00495459713133363 max_bin=172.0 min_data_in_leaf=86.0 min_sum_hessian_in_leaf=8.509348113067874 num_leaves=93.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #267 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9750007200890793 bagging_freq=2.0 feature_fraction=0.8533190031914759 lambda_l1=9.387128416568638 lambda_l2=4.321716632212205 learning_rate=0.0035275948203000347 max_bin=180.0 min_data_in_leaf=78.0 min_sum_hessian_in_leaf=9.456687009236568 num_leaves=90.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #268 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9595121608176358 bagging_freq=4.0 feature_fraction=0.8578000908195396 lambda_l1=9.952421961018352 lambda_l2=9.281280759589594 learning_rate=0.004745101867572419 max_bin=166.0 min_data_in_leaf=71.0 min_sum_hessian_in_leaf=9.226306657817885 num_leaves=81.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #269 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9994770478048601 bagging_freq=3.0 feature_fraction=0.8369024763610851 lambda_l1=9.208428255421646 lambda_l2=9.983243336616958 learning_rate=0.003797971941363382 max_bin=164.0 min_data_in_leaf=20.0 min_sum_hessian_in_leaf=1.1065213655696768 num_leaves=80.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #270 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9820842166439528 bagging_freq=4.0 feature_fraction=0.8626731943758466 lambda_l1=9.661527358455196 lambda_l2=9.126721494049189 learning_rate=0.009888243376432336 max_bin=161.0 min_data_in_leaf=74.0 min_sum_hessian_in_leaf=1.1248431961376393 num_leaves=77.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #271 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9660843348634844 bagging_freq=4.0 feature_fraction=0.8313315440530736 lambda_l1=9.987849566257418 lambda_l2=9.67141543442442 learning_rate=0.009684328853190746 max_bin=170.0 min_data_in_leaf=17.0 min_sum_hessian_in_leaf=1.1591999119664593 num_leaves=63.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #272 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9807805096868688 bagging_freq=3.0 feature_fraction=0.871159490982961 lambda_l1=9.314537338649586 lambda_l2=9.179924440763063 learning_rate=0.009377986470329896 max_bin=190.0 min_data_in_leaf=14.0 min_sum_hessian_in_leaf=1.0196678288624785 num_leaves=70.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #273 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9933813969101161 bagging_freq=3.0 feature_fraction=0.8500120632565139 lambda_l1=9.734272798432524 lambda_l2=9.879519813305942 learning_rate=0.008850256347833572 max_bin=162.0 min_data_in_leaf=18.0 min_sum_hessian_in_leaf=1.260564181202909 num_leaves=75.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #274 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9810965784434433 bagging_freq=1.0 feature_fraction=0.8778521115241141 lambda_l1=9.192574950094945 lambda_l2=9.627995276735883 learning_rate=0.009829837101705255 max_bin=178.0 min_data_in_leaf=10.0 min_sum_hessian_in_leaf=1.3059482966704787 num_leaves=74.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM objective call #275 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.990930262428287 bagging_freq=14.0 feature_fraction=0.8921660114406034 lambda_l1=9.724279374882688 lambda_l2=8.977939102192956 learning_rate=0.00829217245130831 max_bin=156.0 min_data_in_leaf=11.0 min_sum_hessian_in_leaf=1.2581205370089612 num_leaves=72.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #276 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9998713253117469 bagging_freq=13.0 feature_fraction=0.9899213501417546 lambda_l1=9.885739642138896 lambda_l2=9.45917165759156 learning_rate=0.0092288271610021 max_bin=144.0 min_data_in_leaf=15.0 min_sum_hessian_in_leaf=1.005627884371405 num_leaves=61.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #277 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9997033387197188 bagging_freq=11.0 feature_fraction=0.9980141047627518 lambda_l1=0.33739649957956974 lambda_l2=3.475914177449319 learning_rate=0.008401768670687842 max_bin=154.0 min_data_in_leaf=63.0 min_sum_hessian_in_leaf=4.711911321228034 num_leaves=60.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #278 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9860864305829864 bagging_freq=9.0 feature_fraction=0.9938966966580909 lambda_l1=0.30617894890588326 lambda_l2=3.7622044264641903 learning_rate=0.008789460823784612 max_bin=149.0 min_data_in_leaf=59.0 min_sum_hessian_in_leaf=4.638142920448946 num_leaves=68.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #279 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8044351367269793 bagging_freq=10.0 feature_fraction=0.9864072002653329 lambda_l1=0.11560520137874963 lambda_l2=5.9134713540713495 learning_rate=0.004153383692179915 max_bin=146.0 min_data_in_leaf=63.0 min_sum_hessian_in_leaf=4.268830179211873 num_leaves=54.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #280 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8237972478975932 bagging_freq=8.0 feature_fraction=0.9996199117698916 lambda_l1=0.7010710785523979 lambda_l2=3.1423472498489025 learning_rate=0.0032616988480039626 max_bin=139.0 min_data_in_leaf=61.0 min_sum_hessian_in_leaf=4.190516045698006 num_leaves=59.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #281 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8094203878442306 bagging_freq=7.0 feature_fraction=0.9903183219769324 lambda_l1=1.3760681944724826 lambda_l2=4.6791145838647035 learning_rate=0.002570282527680197 max_bin=97.0 min_data_in_leaf=69.0 min_sum_hessian_in_leaf=3.4744861633372617 num_leaves=55.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #282 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7959159999381017 bagging_freq=6.0 feature_fraction=0.9630723802870579 lambda_l1=0.8118303546284517 lambda_l2=5.741934524106257 learning_rate=0.003195753419543419 max_bin=113.0 min_data_in_leaf=64.0 min_sum_hessian_in_leaf=3.946229346565866 num_leaves=61.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #283 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8210291788450086 bagging_freq=6.0 feature_fraction=0.9709410811627365 lambda_l1=1.429373435151046 lambda_l2=6.5812652641935045 learning_rate=0.004312156228175932 max_bin=108.0 min_data_in_leaf=68.0 min_sum_hessian_in_leaf=3.683746725443733 num_leaves=64.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #284 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8124486008842692 bagging_freq=1.0 feature_fraction=0.7620610702474746 lambda_l1=0.11286661547517823 lambda_l2=5.969654654688905 learning_rate=0.004010189852599385 max_bin=95.0 min_data_in_leaf=76.0 min_sum_hessian_in_leaf=2.950848506389718 num_leaves=56.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #285 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8474577922904795 bagging_freq=1.0 feature_fraction=0.7568983903830667 lambda_l1=2.7042710520686035 lambda_l2=6.672722020382122 learning_rate=0.00502989125097087 max_bin=90.0 min_data_in_leaf=97.0 min_sum_hessian_in_leaf=2.7447006022147127 num_leaves=45.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #286 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8572213870282457 bagging_freq=1.0 feature_fraction=0.7661730379555248 lambda_l1=2.454120326411277 lambda_l2=6.118557529195603 learning_rate=0.005166426236893051 max_bin=91.0 min_data_in_leaf=96.0 min_sum_hessian_in_leaf=2.234250479074574 num_leaves=36.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                     \n",
      "LightGBM objective call #287 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8435348799576031 bagging_freq=2.0 feature_fraction=0.8026694108303364 lambda_l1=2.8803742225233586 lambda_l2=6.42431290504404 learning_rate=0.005281306576208852 max_bin=99.0 min_data_in_leaf=88.0 min_sum_hessian_in_leaf=1.8352111212866695 num_leaves=21.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #288 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7683678462067359 bagging_freq=15.0 feature_fraction=0.8172387251680129 lambda_l1=1.6759304786563969 lambda_l2=4.0022080898797565 learning_rate=0.007483160294745176 max_bin=177.0 min_data_in_leaf=53.0 min_sum_hessian_in_leaf=1.7629713122156667 num_leaves=31.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #289 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7566099979815646 bagging_freq=15.0 feature_fraction=0.8221722900605468 lambda_l1=2.2579079550160754 lambda_l2=2.9520053401713406 learning_rate=0.0021933658758888632 max_bin=168.0 min_data_in_leaf=49.0 min_sum_hessian_in_leaf=1.5571999512379031 num_leaves=40.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #290 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7513469304003044 bagging_freq=15.0 feature_fraction=0.8185423122654175 lambda_l1=1.0151817930865612 lambda_l2=4.117597843365201 learning_rate=0.002349740203861999 max_bin=170.0 min_data_in_leaf=52.0 min_sum_hessian_in_leaf=1.3592811810850374 num_leaves=26.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #291 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7709786601381552 bagging_freq=9.0 feature_fraction=0.8084935325275527 lambda_l1=1.8868238014615346 lambda_l2=1.6145858356316567 learning_rate=0.0014097655690893853 max_bin=110.0 min_data_in_leaf=54.0 min_sum_hessian_in_leaf=1.4034531227844769 num_leaves=39.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #292 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.774648141277104 bagging_freq=10.0 feature_fraction=0.8127771245731856 lambda_l1=5.612204402405781 lambda_l2=2.749676009670048 learning_rate=0.0015763632960594538 max_bin=112.0 min_data_in_leaf=47.0 min_sum_hessian_in_leaf=2.4761131959699267 num_leaves=53.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #293 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7511537959696992 bagging_freq=10.0 feature_fraction=0.8092122936365281 lambda_l1=7.368772569831977 lambda_l2=2.6633428962824004 learning_rate=0.0008747744954142981 max_bin=102.0 min_data_in_leaf=49.0 min_sum_hessian_in_leaf=4.899965628009275 num_leaves=58.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #294 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7831209048375775 bagging_freq=10.0 feature_fraction=0.8283596077855248 lambda_l1=6.846080208559779 lambda_l2=3.028384970408193 learning_rate=0.0018302143548332118 max_bin=101.0 min_data_in_leaf=51.0 min_sum_hessian_in_leaf=6.391599752485179 num_leaves=57.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #295 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8365574329979627 bagging_freq=10.0 feature_fraction=0.7820631973658634 lambda_l1=6.452880869201202 lambda_l2=2.276257533521144 learning_rate=0.00016052792975871594 max_bin=105.0 min_data_in_leaf=55.0 min_sum_hessian_in_leaf=5.347576684451957 num_leaves=51.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #296 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7818261380325799 bagging_freq=10.0 feature_fraction=0.7988007519103415 lambda_l1=6.090858272753257 lambda_l2=1.713966324927068 learning_rate=0.00047955153284955825 max_bin=106.0 min_data_in_leaf=58.0 min_sum_hessian_in_leaf=5.739979063954664 num_leaves=48.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #297 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8130686401008953 bagging_freq=11.0 feature_fraction=0.8242009108276169 lambda_l1=5.407884510691292 lambda_l2=3.3167553247622177 learning_rate=0.00040878609028907305 max_bin=96.0 min_data_in_leaf=57.0 min_sum_hessian_in_leaf=6.91223580519737 num_leaves=46.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #298 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8270872278246196 bagging_freq=11.0 feature_fraction=0.7918252780578202 lambda_l1=4.979681323366902 lambda_l2=2.161731134125878 learning_rate=0.0007177272778651359 max_bin=100.0 min_data_in_leaf=56.0 min_sum_hessian_in_leaf=6.219963876909168 num_leaves=51.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #299 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8135975796325767 bagging_freq=9.0 feature_fraction=0.9067504217669433 lambda_l1=5.180380401889593 lambda_l2=2.5231838473837507 learning_rate=5.412840934962071e-05 max_bin=88.0 min_data_in_leaf=60.0 min_sum_hessian_in_leaf=5.966878933574629 num_leaves=53.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #300 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8368670336981809 bagging_freq=8.0 feature_fraction=0.9350783257693062 lambda_l1=5.069622915790479 lambda_l2=0.9918469230916491 learning_rate=0.001129207697262097 max_bin=92.0 min_data_in_leaf=65.0 min_sum_hessian_in_leaf=5.849664977306991 num_leaves=45.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #301 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8607992782447988 bagging_freq=14.0 feature_fraction=0.9235274711654214 lambda_l1=6.3120906310459 lambda_l2=0.7447037273601556 learning_rate=0.0004394288165445576 max_bin=150.0 min_data_in_leaf=60.0 min_sum_hessian_in_leaf=6.7925261025229595 num_leaves=66.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #302 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8732016660167519 bagging_freq=14.0 feature_fraction=0.9361508210515578 lambda_l1=5.666195814322824 lambda_l2=0.12308531387403576 learning_rate=0.0008140915530985837 max_bin=141.0 min_data_in_leaf=65.0 min_sum_hessian_in_leaf=7.373334109668679 num_leaves=64.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #303 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8504879441793602 bagging_freq=14.0 feature_fraction=0.995312484114979 lambda_l1=5.7623618627368955 lambda_l2=0.811641226336717 learning_rate=0.002042367399756762 max_bin=147.0 min_data_in_leaf=66.0 min_sum_hessian_in_leaf=6.695683094185559 num_leaves=65.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #304 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8708131303348544 bagging_freq=3.0 feature_fraction=0.9998383661939589 lambda_l1=4.678249541422445 lambda_l2=0.8868202486451978 learning_rate=0.001668478455772426 max_bin=132.0 min_data_in_leaf=40.0 min_sum_hessian_in_leaf=5.091572865248622 num_leaves=68.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #305 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8795314637334227 bagging_freq=2.0 feature_fraction=0.9996638492285047 lambda_l1=4.674360983249883 lambda_l2=1.1403901925993913 learning_rate=0.0013649026161285985 max_bin=134.0 min_data_in_leaf=38.0 min_sum_hessian_in_leaf=6.539301557072358 num_leaves=74.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #306 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9144366025857626 bagging_freq=2.0 feature_fraction=0.9816057933712548 lambda_l1=3.66664151051587 lambda_l2=0.6587236338939728 learning_rate=0.0015063530094148775 max_bin=151.0 min_data_in_leaf=29.0 min_sum_hessian_in_leaf=5.504609848888851 num_leaves=67.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #307 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9008206315568726 bagging_freq=3.0 feature_fraction=0.9941513006388548 lambda_l1=4.197868386441617 lambda_l2=0.010526359130132334 learning_rate=0.002015505464668405 max_bin=134.0 min_data_in_leaf=27.0 min_sum_hessian_in_leaf=4.515716749088771 num_leaves=83.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #308 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8883357731972931 bagging_freq=4.0 feature_fraction=0.9767442695387649 lambda_l1=3.2281043343927847 lambda_l2=1.0667188506284537 learning_rate=0.001016736733061786 max_bin=117.0 min_data_in_leaf=31.0 min_sum_hessian_in_leaf=4.028853085119587 num_leaves=81.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #309 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9145960024878486 bagging_freq=8.0 feature_fraction=0.886428140806471 lambda_l1=3.671558523726972 lambda_l2=3.2119490070700856 learning_rate=0.0019899750837091704 max_bin=105.0 min_data_in_leaf=25.0 min_sum_hessian_in_leaf=2.8762767011852395 num_leaves=85.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #310 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9448951386362489 bagging_freq=7.0 feature_fraction=0.8725868427742378 lambda_l1=4.338640210615827 lambda_l2=3.603648503529559 learning_rate=0.0018278361869797123 max_bin=104.0 min_data_in_leaf=28.0 min_sum_hessian_in_leaf=7.672455633769292 num_leaves=93.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #311 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9243842693484268 bagging_freq=8.0 feature_fraction=0.8825639848292817 lambda_l1=3.570296642092737 lambda_l2=2.340590062352816 learning_rate=0.002442073179014753 max_bin=102.0 min_data_in_leaf=32.0 min_sum_hessian_in_leaf=7.153082318527771 num_leaves=94.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #312 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9451948924403464 bagging_freq=9.0 feature_fraction=0.8975532664194843 lambda_l1=3.89550056868472 lambda_l2=4.364713270353121 learning_rate=0.002781389200658864 max_bin=115.0 min_data_in_leaf=24.0 min_sum_hessian_in_leaf=7.242026441187242 num_leaves=96.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #313 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9544092793950809 bagging_freq=9.0 feature_fraction=0.8688123992954787 lambda_l1=3.141897651082673 lambda_l2=8.460103842530964 learning_rate=0.0024888849891204746 max_bin=97.0 min_data_in_leaf=81.0 min_sum_hessian_in_leaf=8.073346005094159 num_leaves=95.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #314 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9501729046161098 bagging_freq=9.0 feature_fraction=0.8871939207009464 lambda_l1=4.099902215852482 lambda_l2=8.752620926879072 learning_rate=0.003078825943017179 max_bin=108.0 min_data_in_leaf=79.0 min_sum_hessian_in_leaf=7.781551552492466 num_leaves=92.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #315 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9751066639323925 bagging_freq=12.0 feature_fraction=0.9108536919926573 lambda_l1=1.6886499427262374 lambda_l2=8.638015679419798 learning_rate=0.0033596387225660876 max_bin=143.0 min_data_in_leaf=73.0 min_sum_hessian_in_leaf=3.1715672369730257 num_leaves=88.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #316 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9687754019623037 bagging_freq=12.0 feature_fraction=0.903711253237632 lambda_l1=1.241785581686016 lambda_l2=8.012913900117482 learning_rate=0.003099326745409601 max_bin=154.0 min_data_in_leaf=100.0 min_sum_hessian_in_leaf=2.298240536214929 num_leaves=78.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #317 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9740137365141122 bagging_freq=13.0 feature_fraction=0.9153675534610127 lambda_l1=0.5079358795372828 lambda_l2=7.80611263970762 learning_rate=0.003426973193978573 max_bin=157.0 min_data_in_leaf=99.0 min_sum_hessian_in_leaf=2.137346188898852 num_leaves=76.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #318 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9691247303022246 bagging_freq=12.0 feature_fraction=0.9274071598396048 lambda_l1=1.4551655761658298 lambda_l2=8.255375067440562 learning_rate=0.0037314498416456806 max_bin=153.0 min_data_in_leaf=80.0 min_sum_hessian_in_leaf=1.9651204810698935 num_leaves=70.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #319 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9998233316665948 bagging_freq=13.0 feature_fraction=0.9197004507147671 lambda_l1=8.078335921092322 lambda_l2=8.316868794702776 learning_rate=0.003870564182657285 max_bin=174.0 min_data_in_leaf=70.0 min_sum_hessian_in_leaf=2.091742387214859 num_leaves=73.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #320 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9554664977018666 bagging_freq=13.0 feature_fraction=0.8818488478653465 lambda_l1=8.26564375971193 lambda_l2=7.915743217604633 learning_rate=0.004820817952519718 max_bin=172.0 min_data_in_leaf=74.0 min_sum_hessian_in_leaf=1.512946867829895 num_leaves=80.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #321 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9492089796945241 bagging_freq=13.0 feature_fraction=0.8924764758358334 lambda_l1=7.174631519982111 lambda_l2=7.840774568519434 learning_rate=0.0038833271645154132 max_bin=193.0 min_data_in_leaf=36.0 min_sum_hessian_in_leaf=1.6206872847408753 num_leaves=49.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #322 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9612427798357263 bagging_freq=13.0 feature_fraction=0.9096953256333751 lambda_l1=7.871835832542966 lambda_l2=7.096853956624581 learning_rate=0.004481675452197791 max_bin=182.0 min_data_in_leaf=71.0 min_sum_hessian_in_leaf=1.6895615817689087 num_leaves=46.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #323 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9336617575546358 bagging_freq=14.0 feature_fraction=0.8344333846911934 lambda_l1=7.970341446514992 lambda_l2=8.339758229373398 learning_rate=0.005792407539893938 max_bin=197.0 min_data_in_leaf=14.0 min_sum_hessian_in_leaf=1.7860900007805027 num_leaves=44.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #324 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9426968759878132 bagging_freq=14.0 feature_fraction=0.8387954993297341 lambda_l1=8.526837884548067 lambda_l2=9.471136048235268 learning_rate=0.005982138264706726 max_bin=127.0 min_data_in_leaf=23.0 min_sum_hessian_in_leaf=1.4668936955325649 num_leaves=41.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #325 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9306184450355024 bagging_freq=15.0 feature_fraction=0.8412524416528535 lambda_l1=7.553347328821732 lambda_l2=9.633526741619313 learning_rate=0.0065862471548920115 max_bin=130.0 min_data_in_leaf=18.0 min_sum_hessian_in_leaf=1.3576808725864689 num_leaves=42.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #326 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9392140098529281 bagging_freq=14.0 feature_fraction=0.8449329700769417 lambda_l1=6.987433098121389 lambda_l2=9.242598284066986 learning_rate=0.006959127903747091 max_bin=123.0 min_data_in_leaf=20.0 min_sum_hessian_in_leaf=1.282921021982663 num_leaves=37.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #327 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9219414783372751 bagging_freq=8.0 feature_fraction=0.8465474223845734 lambda_l1=8.758986524487923 lambda_l2=9.817148717408399 learning_rate=0.007868497501885263 max_bin=126.0 min_data_in_leaf=22.0 min_sum_hessian_in_leaf=1.2210201545797954 num_leaves=43.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #328 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9231707826529122 bagging_freq=7.0 feature_fraction=0.8269850323681356 lambda_l1=9.475103106035252 lambda_l2=9.307764958695657 learning_rate=0.0076463366749611305 max_bin=138.0 min_data_in_leaf=16.0 min_sum_hessian_in_leaf=1.170848346100444 num_leaves=48.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #329 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8959245993662306 bagging_freq=8.0 feature_fraction=0.8441711687659911 lambda_l1=6.863439591705486 lambda_l2=9.957958602040385 learning_rate=0.007314089593551281 max_bin=124.0 min_data_in_leaf=22.0 min_sum_hessian_in_leaf=3.406486660015698 num_leaves=35.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #330 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9304557326376652 bagging_freq=8.0 feature_fraction=0.8583018016462721 lambda_l1=8.63548628823137 lambda_l2=8.98732812694965 learning_rate=0.00711025062359966 max_bin=128.0 min_data_in_leaf=25.0 min_sum_hessian_in_leaf=3.763181166609406 num_leaves=28.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #331 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9054220074778105 bagging_freq=9.0 feature_fraction=0.8018151371470336 lambda_l1=6.784877440660155 lambda_l2=9.452900200345505 learning_rate=0.0068817338139806105 max_bin=131.0 min_data_in_leaf=20.0 min_sum_hessian_in_leaf=3.3172780493088467 num_leaves=33.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #332 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8633860904304408 bagging_freq=7.0 feature_fraction=0.8044199650280971 lambda_l1=5.925127881294699 lambda_l2=0.3895724073856893 learning_rate=0.007889535595819118 max_bin=122.0 min_data_in_leaf=43.0 min_sum_hessian_in_leaf=3.999014899259155 num_leaves=38.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #333 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8844083601658846 bagging_freq=6.0 feature_fraction=0.9484896454865178 lambda_l1=6.584459656919972 lambda_l2=0.3227827550214388 learning_rate=0.006479790027877762 max_bin=116.0 min_data_in_leaf=62.0 min_sum_hessian_in_leaf=4.993644614419382 num_leaves=59.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #334 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8674499127104861 bagging_freq=7.0 feature_fraction=0.9655477915368252 lambda_l1=6.087199781031198 lambda_l2=0.615380096488356 learning_rate=0.007228806708159915 max_bin=114.0 min_data_in_leaf=58.0 min_sum_hessian_in_leaf=4.763301757577527 num_leaves=51.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #335 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8681935414008677 bagging_freq=6.0 feature_fraction=0.9575643952578347 lambda_l1=5.883327276489307 lambda_l2=1.340329660956273 learning_rate=0.007468546636355394 max_bin=118.0 min_data_in_leaf=67.0 min_sum_hessian_in_leaf=4.5248928324182485 num_leaves=55.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #336 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.854423788858458 bagging_freq=5.0 feature_fraction=0.9554409600272845 lambda_l1=4.852548095240685 lambda_l2=1.7783281844552197 learning_rate=0.00012482443194430928 max_bin=120.0 min_data_in_leaf=67.0 min_sum_hessian_in_leaf=5.354640435269696 num_leaves=62.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #337 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8564796873539027 bagging_freq=5.0 feature_fraction=0.9689450013211033 lambda_l1=3.0607159075596164 lambda_l2=1.9982599220398278 learning_rate=0.0005427384508798772 max_bin=145.0 min_data_in_leaf=61.0 min_sum_hessian_in_leaf=4.358347523140376 num_leaves=65.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #338 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.889897069167612 bagging_freq=5.0 feature_fraction=0.940243417036411 lambda_l1=3.416480809160814 lambda_l2=1.8671679593549873 learning_rate=0.000981612443641556 max_bin=145.0 min_data_in_leaf=68.0 min_sum_hessian_in_leaf=4.197960245598617 num_leaves=57.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #339 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8762821290656475 bagging_freq=15.0 feature_fraction=0.950899219325612 lambda_l1=2.978071004643127 lambda_l2=0.008758868248940566 learning_rate=0.0011629422254174084 max_bin=140.0 min_data_in_leaf=72.0 min_sum_hessian_in_leaf=4.979840789088417 num_leaves=71.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #340 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8844273646931511 bagging_freq=4.0 feature_fraction=0.9737938623678332 lambda_l1=2.6613183771086923 lambda_l2=6.191005279346726 learning_rate=0.0011658419139762583 max_bin=137.0 min_data_in_leaf=76.0 min_sum_hessian_in_leaf=5.645989196809528 num_leaves=68.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #341 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8938150836553344 bagging_freq=4.0 feature_fraction=0.9797828747294358 lambda_l1=3.9266880399518618 lambda_l2=6.847498453275124 learning_rate=6.391415848199314e-06 max_bin=195.0 min_data_in_leaf=78.0 min_sum_hessian_in_leaf=4.339721799717844 num_leaves=85.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #342 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8931440955851115 bagging_freq=4.0 feature_fraction=0.9630345183093482 lambda_l1=4.470269573614931 lambda_l2=6.334030421870351 learning_rate=0.0013867260423831922 max_bin=190.0 min_data_in_leaf=83.0 min_sum_hessian_in_leaf=3.497416460633866 num_leaves=83.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #343 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8997414484952063 bagging_freq=5.0 feature_fraction=0.9596084734778938 lambda_l1=3.4726190067131566 lambda_l2=6.084338360550455 learning_rate=0.0016659795005898672 max_bin=199.0 min_data_in_leaf=85.0 min_sum_hessian_in_leaf=5.286632893180315 num_leaves=89.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #344 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9056501770601955 bagging_freq=5.0 feature_fraction=0.9489711285286093 lambda_l1=2.8686835012425873 lambda_l2=6.934640734765282 learning_rate=0.002242806505519373 max_bin=188.0 min_data_in_leaf=87.0 min_sum_hessian_in_leaf=3.5822427358464166 num_leaves=84.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #345 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9103379353467242 bagging_freq=6.0 feature_fraction=0.952010165051677 lambda_l1=3.875590432338303 lambda_l2=4.8014643772756855 learning_rate=0.0025700750424483133 max_bin=199.0 min_data_in_leaf=82.0 min_sum_hessian_in_leaf=4.012746211387222 num_leaves=87.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #346 cur_best_score=0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: bagging_fraction=0.9090121783067825 bagging_freq=5.0 feature_fraction=0.9295322750365793 lambda_l1=4.026569010472012 lambda_l2=4.513619625436308 learning_rate=0.0028955394440339077 max_bin=196.0 min_data_in_leaf=90.0 min_sum_hessian_in_leaf=3.5920219356253056 num_leaves=91.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #347 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.918190714612206 bagging_freq=6.0 feature_fraction=0.8921173554092473 lambda_l1=2.458108996232694 lambda_l2=5.520335036923167 learning_rate=0.002233915034572524 max_bin=194.0 min_data_in_leaf=88.0 min_sum_hessian_in_leaf=4.14216971706341 num_leaves=99.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #348 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9032457291001488 bagging_freq=7.0 feature_fraction=0.8767170705036841 lambda_l1=3.3126457588339617 lambda_l2=5.255086339155292 learning_rate=0.0029010482592784752 max_bin=185.0 min_data_in_leaf=93.0 min_sum_hessian_in_leaf=5.165136893855413 num_leaves=96.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #349 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9931481493817225 bagging_freq=7.0 feature_fraction=0.8513864307668001 lambda_l1=2.5517936171304276 lambda_l2=9.061378244672696 learning_rate=0.0027400296709302165 max_bin=88.0 min_data_in_leaf=89.0 min_sum_hessian_in_leaf=8.834412404367198 num_leaves=100.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #350 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9897117664790462 bagging_freq=7.0 feature_fraction=0.8610015929840815 lambda_l1=2.240332579167213 lambda_l2=8.778254679222956 learning_rate=0.0035751079921727716 max_bin=94.0 min_data_in_leaf=81.0 min_sum_hessian_in_leaf=8.364015219590275 num_leaves=97.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #351 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.994062320075408 bagging_freq=11.0 feature_fraction=0.8632272079433788 lambda_l1=4.405680842450911 lambda_l2=8.549414198619198 learning_rate=0.0030431649501796226 max_bin=93.0 min_data_in_leaf=86.0 min_sum_hessian_in_leaf=7.576445996592457 num_leaves=91.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #352 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9638362959447417 bagging_freq=12.0 feature_fraction=0.8538213910490107 lambda_l1=5.216252471302183 lambda_l2=8.111557354216586 learning_rate=0.004354414974410864 max_bin=161.0 min_data_in_leaf=95.0 min_sum_hessian_in_leaf=9.91061105996605 num_leaves=100.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #353 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9590485481781876 bagging_freq=11.0 feature_fraction=0.8656959408243257 lambda_l1=5.27782562447293 lambda_l2=7.280931492380768 learning_rate=0.0032762557876798654 max_bin=158.0 min_data_in_leaf=84.0 min_sum_hessian_in_leaf=2.4103209158182164 num_leaves=78.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #354 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9848779955569706 bagging_freq=11.0 feature_fraction=0.8666131500412213 lambda_l1=4.755720282120116 lambda_l2=7.628246181213987 learning_rate=0.0043095696274896254 max_bin=158.0 min_data_in_leaf=96.0 min_sum_hessian_in_leaf=1.8877469393709039 num_leaves=87.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #355 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.965969264688932 bagging_freq=12.0 feature_fraction=0.8793005197065801 lambda_l1=5.4274547791208505 lambda_l2=7.417232414890938 learning_rate=0.004170896431180806 max_bin=155.0 min_data_in_leaf=76.0 min_sum_hessian_in_leaf=2.888600850995798 num_leaves=77.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #356 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9774498339479177 bagging_freq=12.0 feature_fraction=0.8880597376776916 lambda_l1=4.962490669777622 lambda_l2=7.522877125414911 learning_rate=0.0035743895399733827 max_bin=148.0 min_data_in_leaf=73.0 min_sum_hessian_in_leaf=2.756463219217831 num_leaves=72.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #357 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9798452252330666 bagging_freq=12.0 feature_fraction=0.776828028467867 lambda_l1=8.984115948317909 lambda_l2=7.968206857819694 learning_rate=0.004109505879871578 max_bin=142.0 min_data_in_leaf=75.0 min_sum_hessian_in_leaf=2.667286557169113 num_leaves=63.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM objective call #358 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9848707526606718 bagging_freq=13.0 feature_fraction=0.786279210190772 lambda_l1=7.666703990442554 lambda_l2=7.168042577840852 learning_rate=0.003633316519088909 max_bin=136.0 min_data_in_leaf=71.0 min_sum_hessian_in_leaf=3.007801539300598 num_leaves=75.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #359 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9731728284642883 bagging_freq=14.0 feature_fraction=0.7748786794560739 lambda_l1=7.764220824569133 lambda_l2=7.6745471104886 learning_rate=0.005478173568397287 max_bin=131.0 min_data_in_leaf=65.0 min_sum_hessian_in_leaf=2.774303605344124 num_leaves=62.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #360 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.952711197314308 bagging_freq=15.0 feature_fraction=0.7696000601918038 lambda_l1=8.192736652381809 lambda_l2=7.49536000368204 learning_rate=0.00531418709594563 max_bin=133.0 min_data_in_leaf=69.0 min_sum_hessian_in_leaf=2.4662234026378167 num_leaves=69.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #361 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9701977706580922 bagging_freq=13.0 feature_fraction=0.7885777587794591 lambda_l1=8.894494351816553 lambda_l2=6.819075061860095 learning_rate=0.005717352948009012 max_bin=129.0 min_data_in_leaf=13.0 min_sum_hessian_in_leaf=1.7220724346350946 num_leaves=49.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #362 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9490853943029313 bagging_freq=14.0 feature_fraction=0.7505936428339008 lambda_l1=9.519385950032605 lambda_l2=6.625180251903532 learning_rate=0.006592967725292786 max_bin=139.0 min_data_in_leaf=11.0 min_sum_hessian_in_leaf=2.227672395294424 num_leaves=53.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #363 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9262072887617342 bagging_freq=15.0 feature_fraction=0.7680270599530895 lambda_l1=8.398531507819339 lambda_l2=6.942464519673965 learning_rate=0.005484218052304856 max_bin=141.0 min_data_in_leaf=31.0 min_sum_hessian_in_leaf=1.447625392754781 num_leaves=32.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #364 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9352553089242208 bagging_freq=13.0 feature_fraction=0.7547164211643405 lambda_l1=7.45580918728044 lambda_l2=6.452250311167575 learning_rate=0.006021148780676405 max_bin=136.0 min_data_in_leaf=28.0 min_sum_hessian_in_leaf=1.0506562007313982 num_leaves=36.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #365 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9189485187335531 bagging_freq=11.0 feature_fraction=0.7795295256656202 lambda_l1=8.678255859008082 lambda_l2=5.573248684151453 learning_rate=0.0061977825965185765 max_bin=119.0 min_data_in_leaf=33.0 min_sum_hessian_in_leaf=1.0719153191456323 num_leaves=26.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #366 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9359635916123907 bagging_freq=10.0 feature_fraction=0.7595498964663406 lambda_l1=8.776582259051454 lambda_l2=6.416686667107878 learning_rate=0.006685441518395303 max_bin=124.0 min_data_in_leaf=30.0 min_sum_hessian_in_leaf=1.2291431634606356 num_leaves=24.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #367 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.935742559032441 bagging_freq=10.0 feature_fraction=0.750144998144818 lambda_l1=8.360064284957813 lambda_l2=5.83062436664997 learning_rate=0.005668870451523303 max_bin=117.0 min_data_in_leaf=46.0 min_sum_hessian_in_leaf=1.0138258882777866 num_leaves=20.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #368 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9964880218587375 bagging_freq=9.0 feature_fraction=0.7963995822515166 lambda_l1=7.458950822412489 lambda_l2=7.1742471860646395 learning_rate=0.009079830950866346 max_bin=111.0 min_data_in_leaf=35.0 min_sum_hessian_in_leaf=3.248477838429943 num_leaves=30.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #369 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9783402759419284 bagging_freq=8.0 feature_fraction=0.7925713419756079 lambda_l1=7.187593947992083 lambda_l2=6.710605506930608 learning_rate=0.008589244542289164 max_bin=120.0 min_data_in_leaf=42.0 min_sum_hessian_in_leaf=3.084313088876925 num_leaves=20.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                     \n",
      "LightGBM objective call #370 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9998873178952118 bagging_freq=8.0 feature_fraction=0.7814334670886128 lambda_l1=7.857239730520433 lambda_l2=7.285242381000357 learning_rate=0.008182948943139428 max_bin=113.0 min_data_in_leaf=45.0 min_sum_hessian_in_leaf=3.3763570273117276 num_leaves=18.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #371 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8179725748371253 bagging_freq=6.0 feature_fraction=0.9869528873831154 lambda_l1=8.98337062472566 lambda_l2=7.205340165783583 learning_rate=0.009511995861334045 max_bin=121.0 min_data_in_leaf=43.0 min_sum_hessian_in_leaf=3.1591204537264415 num_leaves=23.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #372 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8322598319749477 bagging_freq=7.0 feature_fraction=0.9680541676886668 lambda_l1=7.090516931223576 lambda_l2=1.3052233442628336 learning_rate=0.00999854224773683 max_bin=134.0 min_data_in_leaf=39.0 min_sum_hessian_in_leaf=2.357853343700438 num_leaves=15.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #373 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8302786469253267 bagging_freq=6.0 feature_fraction=0.9451480242188379 lambda_l1=0.8083607741861346 lambda_l2=1.4746232631343799 learning_rate=0.008480904511066782 max_bin=132.0 min_data_in_leaf=35.0 min_sum_hessian_in_leaf=3.7549632109036586 num_leaves=17.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #374 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8076121929537862 bagging_freq=6.0 feature_fraction=0.9859500230157872 lambda_l1=0.9682208285753395 lambda_l2=1.4947190853250842 learning_rate=0.008067671168606795 max_bin=143.0 min_data_in_leaf=34.0 min_sum_hessian_in_leaf=2.448563517084409 num_leaves=16.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #375 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7626811374669806 bagging_freq=6.0 feature_fraction=0.9382701294745625 lambda_l1=0.22233216556328447 lambda_l2=1.1757785887476977 learning_rate=0.006399116285511599 max_bin=126.0 min_data_in_leaf=41.0 min_sum_hessian_in_leaf=2.5417750830696764 num_leaves=23.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #376 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8010013837949432 bagging_freq=6.0 feature_fraction=0.9323918898607311 lambda_l1=0.08949791529902229 lambda_l2=2.0262324761638038 learning_rate=0.004990242925679392 max_bin=126.0 min_data_in_leaf=44.0 min_sum_hessian_in_leaf=2.6715943450117545 num_leaves=12.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #377 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7944204969085598 bagging_freq=5.0 feature_fraction=0.9208975318239904 lambda_l1=0.7139232046020194 lambda_l2=1.6647556971488797 learning_rate=0.006185379853824312 max_bin=129.0 min_data_in_leaf=37.0 min_sum_hessian_in_leaf=2.589521901880117 num_leaves=12.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #378 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7655935129443544 bagging_freq=5.0 feature_fraction=0.9207535751831071 lambda_l1=0.43906240171018385 lambda_l2=2.482907446633956 learning_rate=0.005807330028252098 max_bin=124.0 min_data_in_leaf=38.0 min_sum_hessian_in_leaf=3.0175755161606412 num_leaves=13.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #379 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7884972088806748 bagging_freq=5.0 feature_fraction=0.9438418998954766 lambda_l1=1.3365952178393103 lambda_l2=1.8895588081329107 learning_rate=0.005584535599842379 max_bin=152.0 min_data_in_leaf=47.0 min_sum_hessian_in_leaf=3.2457081972663824 num_leaves=14.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #380 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.757906201602914 bagging_freq=4.0 feature_fraction=0.9160600021832113 lambda_l1=1.1886877853724864 lambda_l2=2.8859472349542283 learning_rate=0.004600906179711733 max_bin=147.0 min_data_in_leaf=52.0 min_sum_hessian_in_leaf=2.868513807125041 num_leaves=15.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #381 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7594857995861246 bagging_freq=3.0 feature_fraction=0.9241925709169455 lambda_l1=1.0540946295042377 lambda_l2=3.9359851511170767 learning_rate=0.005012383210891164 max_bin=149.0 min_data_in_leaf=98.0 min_sum_hessian_in_leaf=3.81370428317191 num_leaves=11.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #382 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7724030741390114 bagging_freq=3.0 feature_fraction=0.928355387182529 lambda_l1=1.1745776106363341 lambda_l2=4.696364012018768 learning_rate=0.005278095945048901 max_bin=161.0 min_data_in_leaf=50.0 min_sum_hessian_in_leaf=3.4682906609680244 num_leaves=12.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #383 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7782033145110552 bagging_freq=4.0 feature_fraction=0.9358714969337293 lambda_l1=6.2917313938189 lambda_l2=5.3042440752368165 learning_rate=0.004747048337744029 max_bin=164.0 min_data_in_leaf=93.0 min_sum_hessian_in_leaf=3.7054519733105495 num_leaves=10.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #384 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7851482299072966 bagging_freq=2.0 feature_fraction=0.9406146795349964 lambda_l1=5.559389600615809 lambda_l2=5.107400199264427 learning_rate=0.0047997493140162495 max_bin=167.0 min_data_in_leaf=91.0 min_sum_hessian_in_leaf=6.146303264967594 num_leaves=10.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #385 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7800743514272772 bagging_freq=2.0 feature_fraction=0.9781044341802879 lambda_l1=6.493938857345117 lambda_l2=4.1503807821798855 learning_rate=0.005171670685692184 max_bin=179.0 min_data_in_leaf=91.0 min_sum_hessian_in_leaf=9.101211068457006 num_leaves=98.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #386 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7684710347545011 bagging_freq=1.0 feature_fraction=0.9553021669736422 lambda_l1=6.2052311474316095 lambda_l2=4.188005605913832 learning_rate=0.003973738853392942 max_bin=169.0 min_data_in_leaf=93.0 min_sum_hessian_in_leaf=9.883778949265881 num_leaves=93.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #387 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7896887178560801 bagging_freq=2.0 feature_fraction=0.9591965984578711 lambda_l1=5.835837734059344 lambda_l2=3.5240178634964057 learning_rate=0.004628117983460673 max_bin=175.0 min_data_in_leaf=90.0 min_sum_hessian_in_leaf=9.303551722389287 num_leaves=98.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #388 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8020158766258645 bagging_freq=1.0 feature_fraction=0.9852952697170793 lambda_l1=6.095377704513587 lambda_l2=3.7501319873640857 learning_rate=0.0033820338057928847 max_bin=182.0 min_data_in_leaf=84.0 min_sum_hessian_in_leaf=8.52499399569914 num_leaves=97.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #389 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8031244159406625 bagging_freq=1.0 feature_fraction=0.9722700839942355 lambda_l1=1.8156468507809729 lambda_l2=3.676025062118069 learning_rate=0.00389637557939578 max_bin=186.0 min_data_in_leaf=79.0 min_sum_hessian_in_leaf=8.049164009777165 num_leaves=88.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #390 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7976111328757093 bagging_freq=2.0 feature_fraction=0.980865424055698 lambda_l1=2.3520292649253323 lambda_l2=3.866044091946837 learning_rate=0.003835545612107578 max_bin=188.0 min_data_in_leaf=83.0 min_sum_hessian_in_leaf=9.882747327613572 num_leaves=86.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #391 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7934086562155793 bagging_freq=1.0 feature_fraction=0.9721564933450192 lambda_l1=2.0846078088865836 lambda_l2=5.005948288388389 learning_rate=0.0026704021788677913 max_bin=183.0 min_data_in_leaf=87.0 min_sum_hessian_in_leaf=8.699773610755747 num_leaves=95.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #392 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8187638355904021 bagging_freq=2.0 feature_fraction=0.990728690553149 lambda_l1=1.905515046163571 lambda_l2=4.80871059023073 learning_rate=0.003122940102625726 max_bin=176.0 min_data_in_leaf=77.0 min_sum_hessian_in_leaf=9.634783525299499 num_leaves=93.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #393 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.825203527913461 bagging_freq=2.0 feature_fraction=0.9790370847321779 lambda_l1=2.8149146473476367 lambda_l2=4.497064454151082 learning_rate=0.0034988091870500346 max_bin=189.0 min_data_in_leaf=80.0 min_sum_hessian_in_leaf=9.119182010209345 num_leaves=90.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #394 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8380094043072024 bagging_freq=1.0 feature_fraction=0.9767167048276438 lambda_l1=1.520393294538925 lambda_l2=4.404091639231589 learning_rate=0.0036420541632458912 max_bin=173.0 min_data_in_leaf=78.0 min_sum_hessian_in_leaf=9.943744357735357 num_leaves=91.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #395 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9595738705913228 bagging_freq=1.0 feature_fraction=0.8537079710386967 lambda_l1=2.1530029276934144 lambda_l2=4.887473153215545 learning_rate=0.004427249060177479 max_bin=180.0 min_data_in_leaf=82.0 min_sum_hessian_in_leaf=9.402491436527999 num_leaves=89.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #396 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.989121102094451 bagging_freq=3.0 feature_fraction=0.8587380930232378 lambda_l1=9.186374698400208 lambda_l2=9.872593408536494 learning_rate=0.00475252160416805 max_bin=163.0 min_data_in_leaf=72.0 min_sum_hessian_in_leaf=6.996409081625505 num_leaves=81.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #397 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.999430595572786 bagging_freq=3.0 feature_fraction=0.8351180434609362 lambda_l1=9.915817232897277 lambda_l2=9.079750992636678 learning_rate=0.004212752988290288 max_bin=166.0 min_data_in_leaf=71.0 min_sum_hessian_in_leaf=1.1731704574432875 num_leaves=82.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #398 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9818088976042451 bagging_freq=4.0 feature_fraction=0.8366583763967375 lambda_l1=9.982427423289556 lambda_l2=9.652321050514736 learning_rate=0.00377476490293674 max_bin=171.0 min_data_in_leaf=74.0 min_sum_hessian_in_leaf=1.1523778019202575 num_leaves=81.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #399 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.964967671396794 bagging_freq=4.0 feature_fraction=0.8300405081345171 lambda_l1=9.971950465134574 lambda_l2=9.27211317835715 learning_rate=0.00948914398282228 max_bin=166.0 min_data_in_leaf=69.0 min_sum_hessian_in_leaf=1.104833683588714 num_leaves=80.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #400 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9949297908007304 bagging_freq=3.0 feature_fraction=0.8320140135903958 lambda_l1=9.305242272690137 lambda_l2=9.693898709454041 learning_rate=0.009908917673636546 max_bin=170.0 min_data_in_leaf=17.0 min_sum_hessian_in_leaf=1.1034283520906991 num_leaves=70.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #401 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9818056787304555 bagging_freq=3.0 feature_fraction=0.8483952549426372 lambda_l1=9.621539647232902 lambda_l2=9.97754766038581 learning_rate=0.008829313035898855 max_bin=160.0 min_data_in_leaf=10.0 min_sum_hessian_in_leaf=1.3400977659606086 num_leaves=76.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #402 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9920566916994505 bagging_freq=3.0 feature_fraction=0.8696369132059399 lambda_l1=9.609988170999259 lambda_l2=9.948178243333238 learning_rate=0.00907960865491586 max_bin=163.0 min_data_in_leaf=17.0 min_sum_hessian_in_leaf=1.1246750434234605 num_leaves=73.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #403 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9736773641620347 bagging_freq=4.0 feature_fraction=0.8768244312692677 lambda_l1=9.733959396000381 lambda_l2=9.588228057166921 learning_rate=0.00937063826135407 max_bin=174.0 min_data_in_leaf=14.0 min_sum_hessian_in_leaf=1.0094988004525334 num_leaves=74.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #404 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9915233874230485 bagging_freq=1.0 feature_fraction=0.8748148938039022 lambda_l1=9.356756521119683 lambda_l2=8.845765753103848 learning_rate=0.009261212031616428 max_bin=178.0 min_data_in_leaf=11.0 min_sum_hessian_in_leaf=1.3109542784789425 num_leaves=72.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #405 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9987141819555698 bagging_freq=2.0 feature_fraction=0.891685014761421 lambda_l1=9.778461023991184 lambda_l2=9.48680916792811 learning_rate=0.009691868291840837 max_bin=154.0 min_data_in_leaf=12.0 min_sum_hessian_in_leaf=1.2722899443213356 num_leaves=75.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #406 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9855246116332699 bagging_freq=1.0 feature_fraction=0.9005131107212515 lambda_l1=9.142547337599261 lambda_l2=9.372015296636697 learning_rate=0.008901238471846238 max_bin=156.0 min_data_in_leaf=14.0 min_sum_hessian_in_leaf=1.0177199872945661 num_leaves=67.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #407 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9986657541932179 bagging_freq=14.0 feature_fraction=0.8828165353921255 lambda_l1=9.757299304132882 lambda_l2=9.952050451065581 learning_rate=0.008261813421375871 max_bin=151.0 min_data_in_leaf=15.0 min_sum_hessian_in_leaf=1.385252734696182 num_leaves=59.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #408 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9896212795616789 bagging_freq=14.0 feature_fraction=0.8975313894208576 lambda_l1=9.862980696417516 lambda_l2=8.986005535975496 learning_rate=0.008693534985290444 max_bin=156.0 min_data_in_leaf=11.0 min_sum_hessian_in_leaf=1.2244268030412429 num_leaves=61.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #409 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9994646098692885 bagging_freq=9.0 feature_fraction=0.9995390300645984 lambda_l1=0.531810947200691 lambda_l2=3.010395442446047 learning_rate=0.009255221057415134 max_bin=149.0 min_data_in_leaf=63.0 min_sum_hessian_in_leaf=4.651603576160809 num_leaves=64.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #410 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9889533268142633 bagging_freq=11.0 feature_fraction=0.9937974099359467 lambda_l1=0.21922684089696678 lambda_l2=3.4527241630945467 learning_rate=0.008373638569985844 max_bin=145.0 min_data_in_leaf=60.0 min_sum_hessian_in_leaf=4.938699041523574 num_leaves=60.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #411 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9854043386339671 bagging_freq=10.0 feature_fraction=0.9917901046048669 lambda_l1=0.08425308755541258 lambda_l2=3.3983444220976984 learning_rate=0.008323194324687679 max_bin=146.0 min_data_in_leaf=59.0 min_sum_hessian_in_leaf=4.598021241083027 num_leaves=57.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #412 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8239573528158701 bagging_freq=9.0 feature_fraction=0.9987717384195648 lambda_l1=0.31849218972404314 lambda_l2=3.1723712574235434 learning_rate=0.00852080098797648 max_bin=139.0 min_data_in_leaf=57.0 min_sum_hessian_in_leaf=4.227194844791042 num_leaves=54.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #413 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8098440044908498 bagging_freq=8.0 feature_fraction=0.9960790445061033 lambda_l1=0.031112387303180444 lambda_l2=3.8840636445307153 learning_rate=0.0028923362715744315 max_bin=151.0 min_data_in_leaf=63.0 min_sum_hessian_in_leaf=4.761449727777942 num_leaves=54.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #414 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8057441297858333 bagging_freq=9.0 feature_fraction=0.9899499185784646 lambda_l1=0.7290340337663179 lambda_l2=3.076927109110434 learning_rate=0.0031825794330699424 max_bin=153.0 min_data_in_leaf=61.0 min_sum_hessian_in_leaf=4.250853729717428 num_leaves=56.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #415 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7978746401862653 bagging_freq=7.0 feature_fraction=0.9846604383380934 lambda_l1=0.7188472438631212 lambda_l2=5.686225362188332 learning_rate=0.0024884934277040827 max_bin=147.0 min_data_in_leaf=65.0 min_sum_hessian_in_leaf=4.00126018492611 num_leaves=59.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #416 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.817333535454645 bagging_freq=7.0 feature_fraction=0.9671947174597139 lambda_l1=1.331458569433505 lambda_l2=5.761040255220634 learning_rate=0.003226432514407004 max_bin=97.0 min_data_in_leaf=63.0 min_sum_hessian_in_leaf=3.9823347264067963 num_leaves=55.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #417 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8410597833227959 bagging_freq=7.0 feature_fraction=0.9635327097636888 lambda_l1=0.8919611196759565 lambda_l2=5.90104383214832 learning_rate=0.003980275594955999 max_bin=107.0 min_data_in_leaf=68.0 min_sum_hessian_in_leaf=3.4422592180726617 num_leaves=51.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #418 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8226187041592058 bagging_freq=8.0 feature_fraction=0.9629234019207258 lambda_l1=1.4348614403658027 lambda_l2=6.237562314357443 learning_rate=0.0026362480660520327 max_bin=99.0 min_data_in_leaf=69.0 min_sum_hessian_in_leaf=3.906437932171169 num_leaves=64.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #419 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8475384296117908 bagging_freq=6.0 feature_fraction=0.7597908275340572 lambda_l1=1.7221861319486942 lambda_l2=6.585740484743577 learning_rate=0.004411802934092377 max_bin=91.0 min_data_in_leaf=67.0 min_sum_hessian_in_leaf=2.850114967053665 num_leaves=45.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #420 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.850238518934374 bagging_freq=1.0 feature_fraction=0.7546889344444113 lambda_l1=2.6875389911608396 lambda_l2=6.0223439593345445 learning_rate=0.005108645692326009 max_bin=89.0 min_data_in_leaf=76.0 min_sum_hessian_in_leaf=2.019789366636457 num_leaves=48.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #421 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8464216734855048 bagging_freq=1.0 feature_fraction=0.7629395629048134 lambda_l1=2.411535303472168 lambda_l2=6.583067010974709 learning_rate=0.005210354096847077 max_bin=90.0 min_data_in_leaf=99.0 min_sum_hessian_in_leaf=2.211168489709877 num_leaves=39.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #422 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8437163910955433 bagging_freq=1.0 feature_fraction=0.763870973412078 lambda_l1=2.6526528625896213 lambda_l2=6.207790515809199 learning_rate=0.005357679594378743 max_bin=94.0 min_data_in_leaf=96.0 min_sum_hessian_in_leaf=2.351735309375993 num_leaves=44.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #423 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8568847564314781 bagging_freq=2.0 feature_fraction=0.7662948526825741 lambda_l1=2.909519080316743 lambda_l2=5.400868254576616 learning_rate=0.005024483072977299 max_bin=91.0 min_data_in_leaf=94.0 min_sum_hessian_in_leaf=1.7341556022814653 num_leaves=27.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #424 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.86154162961455 bagging_freq=1.0 feature_fraction=0.7576686385618131 lambda_l1=2.361732378553529 lambda_l2=6.036996523343736 learning_rate=0.0060768146411988855 max_bin=95.0 min_data_in_leaf=97.0 min_sum_hessian_in_leaf=1.8503076908692095 num_leaves=32.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #425 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7502691351235731 bagging_freq=15.0 feature_fraction=0.8151363160630642 lambda_l1=2.0319345818362837 lambda_l2=6.732307666142024 learning_rate=0.007022342009309729 max_bin=98.0 min_data_in_leaf=53.0 min_sum_hessian_in_leaf=1.5591090652267026 num_leaves=30.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #426 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8565720353826093 bagging_freq=2.0 feature_fraction=0.8218160114133863 lambda_l1=1.624649041783977 lambda_l2=6.364602236123289 learning_rate=0.00595271171306331 max_bin=88.0 min_data_in_leaf=54.0 min_sum_hessian_in_leaf=1.786731987887531 num_leaves=34.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #427 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7506708636633793 bagging_freq=14.0 feature_fraction=0.8166649746897123 lambda_l1=1.7666625568289642 lambda_l2=4.025412172002253 learning_rate=0.002250340404168539 max_bin=168.0 min_data_in_leaf=51.0 min_sum_hessian_in_leaf=1.9755190671416638 num_leaves=25.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #428 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7549858037229503 bagging_freq=14.0 feature_fraction=0.8052827334184873 lambda_l1=1.8756216797311596 lambda_l2=2.6260161896239733 learning_rate=0.0020462652504140543 max_bin=173.0 min_data_in_leaf=53.0 min_sum_hessian_in_leaf=1.556245597317869 num_leaves=28.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #429 cur_best_score=0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: bagging_fraction=0.7702417216292953 bagging_freq=15.0 feature_fraction=0.8113580298702436 lambda_l1=2.073970957350613 lambda_l2=2.7393508966438436 learning_rate=0.001711175073219291 max_bin=110.0 min_data_in_leaf=48.0 min_sum_hessian_in_leaf=1.6570636304458795 num_leaves=41.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #430 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7745736752310527 bagging_freq=15.0 feature_fraction=0.8199419054448807 lambda_l1=1.1267026433897942 lambda_l2=2.813719777973545 learning_rate=0.0014549925938998137 max_bin=179.0 min_data_in_leaf=50.0 min_sum_hessian_in_leaf=1.4121854654508492 num_leaves=38.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #431 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7506980485602757 bagging_freq=10.0 feature_fraction=0.8069533749440516 lambda_l1=1.5671417579122444 lambda_l2=2.3106390585760246 learning_rate=0.0018485234456513252 max_bin=111.0 min_data_in_leaf=49.0 min_sum_hessian_in_leaf=1.5632147724825995 num_leaves=40.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #432 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7642984180405555 bagging_freq=10.0 feature_fraction=0.8114193567109308 lambda_l1=6.848644116549401 lambda_l2=2.6714347541781343 learning_rate=0.0015645921291841478 max_bin=101.0 min_data_in_leaf=51.0 min_sum_hessian_in_leaf=5.911187566945269 num_leaves=53.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #433 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7750251729563138 bagging_freq=10.0 feature_fraction=0.8087773557271295 lambda_l1=6.597677437036537 lambda_l2=2.2103618380771306 learning_rate=0.0008354822357269757 max_bin=103.0 min_data_in_leaf=55.0 min_sum_hessian_in_leaf=5.223017876839732 num_leaves=51.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #434 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7624614446161541 bagging_freq=10.0 feature_fraction=0.7996913152606792 lambda_l1=6.728316207170613 lambda_l2=1.6159250525320523 learning_rate=0.0006258081360695331 max_bin=105.0 min_data_in_leaf=56.0 min_sum_hessian_in_leaf=6.436937323839748 num_leaves=47.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #435 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7842648243926608 bagging_freq=10.0 feature_fraction=0.7824309815699303 lambda_l1=5.668996172373014 lambda_l2=2.1718370359636023 learning_rate=0.0008892053149237691 max_bin=102.0 min_data_in_leaf=48.0 min_sum_hessian_in_leaf=6.34304153970624 num_leaves=58.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #436 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7901390218684767 bagging_freq=11.0 feature_fraction=0.822853216775287 lambda_l1=7.301766812813638 lambda_l2=2.410571855019092 learning_rate=0.000125378309568993 max_bin=106.0 min_data_in_leaf=58.0 min_sum_hessian_in_leaf=5.704778427565147 num_leaves=49.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #437 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.815810193216432 bagging_freq=11.0 feature_fraction=0.7903508841389797 lambda_l1=6.428935614706063 lambda_l2=1.7271272868372702 learning_rate=0.00036457786467823856 max_bin=99.0 min_data_in_leaf=51.0 min_sum_hessian_in_leaf=6.2856312833997015 num_leaves=51.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #438 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8289262319073243 bagging_freq=11.0 feature_fraction=0.797976781113381 lambda_l1=5.420608674283281 lambda_l2=2.1830555214127023 learning_rate=0.00033931904273714676 max_bin=100.0 min_data_in_leaf=56.0 min_sum_hessian_in_leaf=6.881226034799223 num_leaves=47.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #439 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8148111420603246 bagging_freq=11.0 feature_fraction=0.7893739415217419 lambda_l1=5.082632173821124 lambda_l2=2.086153313228295 learning_rate=2.3483332547313558e-05 max_bin=96.0 min_data_in_leaf=58.0 min_sum_hessian_in_leaf=5.986305490861893 num_leaves=52.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #440 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8375198834472415 bagging_freq=9.0 feature_fraction=0.7976150767923776 lambda_l1=5.2709531701537315 lambda_l2=2.555182383798663 learning_rate=0.0007057588675367278 max_bin=104.0 min_data_in_leaf=56.0 min_sum_hessian_in_leaf=5.411077090915016 num_leaves=47.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM objective call #441 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8118836639711271 bagging_freq=9.0 feature_fraction=0.9076202728193553 lambda_l1=4.9199257697361265 lambda_l2=1.2753687704267809 learning_rate=0.00045788828613023457 max_bin=93.0 min_data_in_leaf=61.0 min_sum_hessian_in_leaf=5.719994220779478 num_leaves=43.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #442 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8364533736980038 bagging_freq=9.0 feature_fraction=0.7735332257347556 lambda_l1=4.636812173635642 lambda_l2=0.5132112456034374 learning_rate=0.0002631654664175237 max_bin=88.0 min_data_in_leaf=59.0 min_sum_hessian_in_leaf=7.166372842602036 num_leaves=49.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #443 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8410672727764938 bagging_freq=8.0 feature_fraction=0.9048432415109767 lambda_l1=5.15241397196692 lambda_l2=1.1213163117575213 learning_rate=0.0011601860484348448 max_bin=95.0 min_data_in_leaf=60.0 min_sum_hessian_in_leaf=6.836782205628977 num_leaves=46.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #444 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.870074039859612 bagging_freq=8.0 feature_fraction=0.9124656300917582 lambda_l1=5.77253443511655 lambda_l2=0.8656653131014578 learning_rate=0.0007284567981975045 max_bin=88.0 min_data_in_leaf=66.0 min_sum_hessian_in_leaf=7.416525237027617 num_leaves=66.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #445 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8750209728763647 bagging_freq=14.0 feature_fraction=0.9229844231523405 lambda_l1=5.7103270522366545 lambda_l2=0.7932771484728427 learning_rate=0.0013395479996229968 max_bin=141.0 min_data_in_leaf=66.0 min_sum_hessian_in_leaf=6.578190644374741 num_leaves=64.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #446 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8637901476170177 bagging_freq=14.0 feature_fraction=0.9356760494366584 lambda_l1=5.5747775030262074 lambda_l2=0.14875395869123764 learning_rate=0.0010420744064582445 max_bin=143.0 min_data_in_leaf=65.0 min_sum_hessian_in_leaf=6.630912896773915 num_leaves=66.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #447 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8717585632034401 bagging_freq=15.0 feature_fraction=0.9510769700890241 lambda_l1=6.178622019274103 lambda_l2=0.020904547116289876 learning_rate=0.001973526970437031 max_bin=149.0 min_data_in_leaf=64.0 min_sum_hessian_in_leaf=7.592730111709275 num_leaves=68.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #448 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8782821949748308 bagging_freq=15.0 feature_fraction=0.9977248094238338 lambda_l1=4.5723946317422985 lambda_l2=0.9110250870336346 learning_rate=0.0017379371733438679 max_bin=135.0 min_data_in_leaf=40.0 min_sum_hessian_in_leaf=8.064287063461597 num_leaves=69.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #449 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8859451636939725 bagging_freq=2.0 feature_fraction=0.9823001967064449 lambda_l1=4.7409035066860925 lambda_l2=0.6653765709684982 learning_rate=0.0015166390032514273 max_bin=133.0 min_data_in_leaf=26.0 min_sum_hessian_in_leaf=5.519419120855706 num_leaves=62.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #450 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8823827749096481 bagging_freq=2.0 feature_fraction=0.9931220034417715 lambda_l1=4.239332811707936 lambda_l2=0.3227836561442881 learning_rate=0.0013131292604928717 max_bin=138.0 min_data_in_leaf=28.0 min_sum_hessian_in_leaf=7.250743357004669 num_leaves=67.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #451 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8794739204478637 bagging_freq=3.0 feature_fraction=0.9996840281576589 lambda_l1=3.6790849433529806 lambda_l2=0.033571238862298625 learning_rate=0.002111100755791886 max_bin=132.0 min_data_in_leaf=30.0 min_sum_hessian_in_leaf=5.137754330620651 num_leaves=74.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #452 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8893176076813757 bagging_freq=3.0 feature_fraction=0.9762022214585678 lambda_l1=4.139121403530786 lambda_l2=0.45503475463169396 learning_rate=0.0010085774256087976 max_bin=136.0 min_data_in_leaf=32.0 min_sum_hessian_in_leaf=4.408640910747903 num_leaves=83.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                     \n",
      "LightGBM objective call #453 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8984029713009214 bagging_freq=2.0 feature_fraction=0.9823051696776766 lambda_l1=3.6841115717374175 lambda_l2=1.0585772728011196 learning_rate=0.0019671806078473135 max_bin=117.0 min_data_in_leaf=25.0 min_sum_hessian_in_leaf=4.480477617394009 num_leaves=85.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #454 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9150974987405104 bagging_freq=3.0 feature_fraction=0.9721249888922234 lambda_l1=3.5841887607980762 lambda_l2=0.6612873105362719 learning_rate=0.0015156358116069114 max_bin=114.0 min_data_in_leaf=27.0 min_sum_hessian_in_leaf=4.584316631093362 num_leaves=78.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #455 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9097506502768921 bagging_freq=4.0 feature_fraction=0.9893034179750074 lambda_l1=3.2217844153272734 lambda_l2=0.5369577064979747 learning_rate=0.0018903502565811615 max_bin=108.0 min_data_in_leaf=29.0 min_sum_hessian_in_leaf=3.5833208657281737 num_leaves=83.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #456 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9126286028315765 bagging_freq=4.0 feature_fraction=0.9683728557900804 lambda_l1=4.290637806353544 lambda_l2=0.057641470526645124 learning_rate=0.0023639140981588876 max_bin=112.0 min_data_in_leaf=23.0 min_sum_hessian_in_leaf=4.888341374242896 num_leaves=79.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #457 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9252585607820998 bagging_freq=8.0 feature_fraction=0.8900340051538584 lambda_l1=3.1833360639376616 lambda_l2=3.3124714575310827 learning_rate=0.002403589450477652 max_bin=103.0 min_data_in_leaf=21.0 min_sum_hessian_in_leaf=3.1024588481286126 num_leaves=93.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #458 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9025814390634751 bagging_freq=7.0 feature_fraction=0.8820670742602582 lambda_l1=3.382640050824 lambda_l2=3.1979660858260104 learning_rate=0.001998354851520194 max_bin=105.0 min_data_in_leaf=19.0 min_sum_hessian_in_leaf=3.803375697345921 num_leaves=94.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #459 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9438360993868163 bagging_freq=8.0 feature_fraction=0.8845781231311499 lambda_l1=3.8564983044569536 lambda_l2=4.318378462898479 learning_rate=0.002803980695870904 max_bin=104.0 min_data_in_leaf=24.0 min_sum_hessian_in_leaf=7.183485877269271 num_leaves=96.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #460 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9404760635949233 bagging_freq=8.0 feature_fraction=0.87429537224742 lambda_l1=3.540952236832628 lambda_l2=3.5704645136708164 learning_rate=0.002430209741179737 max_bin=98.0 min_data_in_leaf=21.0 min_sum_hessian_in_leaf=7.650745264753297 num_leaves=95.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #461 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.95392895775597 bagging_freq=9.0 feature_fraction=0.8699435946614361 lambda_l1=4.071585705973722 lambda_l2=8.41065538009649 learning_rate=0.002944025138442016 max_bin=108.0 min_data_in_leaf=33.0 min_sum_hessian_in_leaf=8.028430282494696 num_leaves=92.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #462 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9480572807762341 bagging_freq=9.0 feature_fraction=0.9001135949217961 lambda_l1=3.1241887549733387 lambda_l2=8.63592814609959 learning_rate=0.0026135945649768725 max_bin=108.0 min_data_in_leaf=80.0 min_sum_hessian_in_leaf=8.362291563926327 num_leaves=96.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #463 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.954289432123585 bagging_freq=9.0 feature_fraction=0.8968300107598188 lambda_l1=2.9265945666755444 lambda_l2=8.698131771086176 learning_rate=0.0033807186234144806 max_bin=116.0 min_data_in_leaf=79.0 min_sum_hessian_in_leaf=7.976036051413378 num_leaves=99.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #464 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9611202299243236 bagging_freq=12.0 feature_fraction=0.9031542054301428 lambda_l1=2.607158752807355 lambda_l2=8.038867447867215 learning_rate=0.0030820411392011 max_bin=115.0 min_data_in_leaf=73.0 min_sum_hessian_in_leaf=2.2558702772586767 num_leaves=88.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #465 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9690572884131977 bagging_freq=12.0 feature_fraction=0.9125034379994047 lambda_l1=2.2570773894853007 lambda_l2=7.767053038374027 learning_rate=0.0034362736306409853 max_bin=158.0 min_data_in_leaf=81.0 min_sum_hessian_in_leaf=2.1078238588008786 num_leaves=90.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #466 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9742859310337694 bagging_freq=12.0 feature_fraction=0.9159407509289345 lambda_l1=0.4826069701814182 lambda_l2=8.465703395987479 learning_rate=0.0030711910988407355 max_bin=158.0 min_data_in_leaf=99.0 min_sum_hessian_in_leaf=2.18805452668255 num_leaves=86.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #467 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9679326816508419 bagging_freq=12.0 feature_fraction=0.9069822325381606 lambda_l1=1.4946692038151332 lambda_l2=8.079509779181674 learning_rate=0.0037209068310291903 max_bin=152.0 min_data_in_leaf=100.0 min_sum_hessian_in_leaf=1.9978690144522646 num_leaves=76.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #468 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.979105585608495 bagging_freq=13.0 feature_fraction=0.9271450039807301 lambda_l1=1.3413299242802519 lambda_l2=8.291385654031956 learning_rate=0.0033936192247613316 max_bin=154.0 min_data_in_leaf=73.0 min_sum_hessian_in_leaf=2.088182026548572 num_leaves=77.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #469 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9707533308312994 bagging_freq=13.0 feature_fraction=0.894838203584585 lambda_l1=0.4667502588960034 lambda_l2=8.224953222343458 learning_rate=0.004097194876326881 max_bin=165.0 min_data_in_leaf=75.0 min_sum_hessian_in_leaf=1.9297259390434258 num_leaves=70.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #470 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9578624329848803 bagging_freq=13.0 feature_fraction=0.9178241270900637 lambda_l1=8.072837611068007 lambda_l2=7.849849683752811 learning_rate=0.0038730425477998967 max_bin=160.0 min_data_in_leaf=85.0 min_sum_hessian_in_leaf=2.0811972499730476 num_leaves=79.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #471 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9750364504727042 bagging_freq=13.0 feature_fraction=0.889725697699216 lambda_l1=8.387251096879233 lambda_l2=7.775704341228354 learning_rate=0.004273374299607451 max_bin=192.0 min_data_in_leaf=71.0 min_sum_hessian_in_leaf=1.6127560952827908 num_leaves=71.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #472 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9477519836563473 bagging_freq=13.0 feature_fraction=0.9098064863958585 lambda_l1=8.178773774016625 lambda_l2=8.262155178679814 learning_rate=0.0037832664422033837 max_bin=174.0 min_data_in_leaf=76.0 min_sum_hessian_in_leaf=1.838580696938285 num_leaves=72.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #473 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9624387038945197 bagging_freq=13.0 feature_fraction=0.9014115625870158 lambda_l1=7.9000331769825145 lambda_l2=7.503480412851098 learning_rate=0.0044976152090695 max_bin=183.0 min_data_in_leaf=70.0 min_sum_hessian_in_leaf=1.493258607296009 num_leaves=61.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #474 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9583968563358668 bagging_freq=13.0 feature_fraction=0.89447812063837 lambda_l1=8.217860723111782 lambda_l2=7.10823110086289 learning_rate=0.004867435748099168 max_bin=181.0 min_data_in_leaf=70.0 min_sum_hessian_in_leaf=1.649298256150038 num_leaves=56.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #475 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9516054308673622 bagging_freq=13.0 feature_fraction=0.882453582489266 lambda_l1=8.06398532561209 lambda_l2=8.395072434246153 learning_rate=0.005755131039871705 max_bin=196.0 min_data_in_leaf=74.0 min_sum_hessian_in_leaf=1.6604919455408955 num_leaves=45.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #476 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9363457905579161 bagging_freq=14.0 feature_fraction=0.8372445846497323 lambda_l1=8.592598706776833 lambda_l2=7.9158072013524095 learning_rate=0.005935414344420225 max_bin=197.0 min_data_in_leaf=19.0 min_sum_hessian_in_leaf=1.4660178951895022 num_leaves=41.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #477 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9423459860027361 bagging_freq=15.0 feature_fraction=0.8436298391879813 lambda_l1=7.7778338393794995 lambda_l2=9.044005658538453 learning_rate=0.006532128569167276 max_bin=188.0 min_data_in_leaf=16.0 min_sum_hessian_in_leaf=1.3635897855150196 num_leaves=37.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #478 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9295846044829308 bagging_freq=15.0 feature_fraction=0.8400345755728095 lambda_l1=7.63975851193751 lambda_l2=8.901406904552971 learning_rate=0.006872143127198184 max_bin=198.0 min_data_in_leaf=17.0 min_sum_hessian_in_leaf=1.7151618857101114 num_leaves=42.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #479 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9398085681685393 bagging_freq=15.0 feature_fraction=0.841767171766708 lambda_l1=8.52406671399786 lambda_l2=9.216990531445388 learning_rate=0.007072979187792274 max_bin=128.0 min_data_in_leaf=20.0 min_sum_hessian_in_leaf=1.449779446370392 num_leaves=35.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #480 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9294330006559195 bagging_freq=14.0 feature_fraction=0.8475465126715227 lambda_l1=7.57214945690899 lambda_l2=9.807190167887056 learning_rate=0.006934187028225494 max_bin=122.0 min_data_in_leaf=13.0 min_sum_hessian_in_leaf=1.2358904126785386 num_leaves=37.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #481 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9214646278493673 bagging_freq=7.0 feature_fraction=0.8277707822002836 lambda_l1=9.438649593835773 lambda_l2=9.51392753267266 learning_rate=0.007742303261942757 max_bin=127.0 min_data_in_leaf=23.0 min_sum_hessian_in_leaf=1.2990277846351586 num_leaves=42.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #482 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9220600920174754 bagging_freq=15.0 feature_fraction=0.833443829475049 lambda_l1=8.728405351689787 lambda_l2=9.411906065114291 learning_rate=0.007653465538531852 max_bin=129.0 min_data_in_leaf=19.0 min_sum_hessian_in_leaf=1.1873700720408493 num_leaves=43.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #483 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8972294873346333 bagging_freq=7.0 feature_fraction=0.8462318873257457 lambda_l1=7.30164121330348 lambda_l2=9.29141903158796 learning_rate=0.007449402618026617 max_bin=124.0 min_data_in_leaf=18.0 min_sum_hessian_in_leaf=1.2044643320674824 num_leaves=34.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #484 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9190109669238931 bagging_freq=8.0 feature_fraction=0.8502920059731456 lambda_l1=8.966900117400042 lambda_l2=9.951993984076971 learning_rate=0.0073369331863925875 max_bin=126.0 min_data_in_leaf=26.0 min_sum_hessian_in_leaf=3.6766416260248485 num_leaves=29.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #485 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9084040569128745 bagging_freq=8.0 feature_fraction=0.8274770312314234 lambda_l1=8.84321817017698 lambda_l2=9.765233243493874 learning_rate=0.007968398681956805 max_bin=132.0 min_data_in_leaf=22.0 min_sum_hessian_in_leaf=3.3361794497497335 num_leaves=32.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #486 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8935454444300229 bagging_freq=8.0 feature_fraction=0.8572589875629452 lambda_l1=6.841624249455215 lambda_l2=8.971294283571005 learning_rate=0.00713423834759613 max_bin=122.0 min_data_in_leaf=22.0 min_sum_hessian_in_leaf=3.296340925318686 num_leaves=27.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #487 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8895509969493728 bagging_freq=7.0 feature_fraction=0.8048665566733129 lambda_l1=7.161358905672412 lambda_l2=9.316301259732871 learning_rate=0.007674937962374358 max_bin=131.0 min_data_in_leaf=25.0 min_sum_hessian_in_leaf=3.397374936571517 num_leaves=33.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #488 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9050779246225972 bagging_freq=7.0 feature_fraction=0.8245902652873922 lambda_l1=6.99775480639339 lambda_l2=9.98333578796447 learning_rate=0.007982108847088103 max_bin=124.0 min_data_in_leaf=16.0 min_sum_hessian_in_leaf=2.963810307953968 num_leaves=35.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #489 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8825127031718079 bagging_freq=6.0 feature_fraction=0.815442744257619 lambda_l1=6.725571354221052 lambda_l2=8.840557852001409 learning_rate=0.006404731824780293 max_bin=120.0 min_data_in_leaf=28.0 min_sum_hessian_in_leaf=3.918555649839717 num_leaves=29.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #490 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8676603283870801 bagging_freq=7.0 feature_fraction=0.8527392816492475 lambda_l1=6.629777150227169 lambda_l2=9.531492690755984 learning_rate=0.006749037572371406 max_bin=119.0 min_data_in_leaf=25.0 min_sum_hessian_in_leaf=4.208495290579608 num_leaves=21.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #491 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8648627266418736 bagging_freq=6.0 feature_fraction=0.8025358369600478 lambda_l1=6.024108478762136 lambda_l2=0.3430545804536792 learning_rate=0.007183978604748977 max_bin=114.0 min_data_in_leaf=62.0 min_sum_hessian_in_leaf=4.683592175816773 num_leaves=39.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #492 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8654608070997281 bagging_freq=6.0 feature_fraction=0.9567221283193217 lambda_l1=6.070051375282166 lambda_l2=1.319267785971845 learning_rate=0.007444058844767294 max_bin=119.0 min_data_in_leaf=62.0 min_sum_hessian_in_leaf=4.935993789643533 num_leaves=55.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #493 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8526309013747114 bagging_freq=5.0 feature_fraction=0.9556399211862473 lambda_l1=6.44218375496026 lambda_l2=0.3884740742587811 learning_rate=0.007879425636267883 max_bin=117.0 min_data_in_leaf=58.0 min_sum_hessian_in_leaf=5.354432558859967 num_leaves=59.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #494 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8608910712957666 bagging_freq=6.0 feature_fraction=0.9388522070971645 lambda_l1=6.5598008480146675 lambda_l2=0.21468123432471398 learning_rate=0.00759598116810819 max_bin=113.0 min_data_in_leaf=67.0 min_sum_hessian_in_leaf=5.031391338569745 num_leaves=57.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #495 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8548798501483529 bagging_freq=5.0 feature_fraction=0.9472647213421629 lambda_l1=5.979075906779365 lambda_l2=1.6849163700806513 learning_rate=0.006475782960724495 max_bin=110.0 min_data_in_leaf=67.0 min_sum_hessian_in_leaf=4.893270286445212 num_leaves=62.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #496 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8524801277155121 bagging_freq=5.0 feature_fraction=0.9637490714596024 lambda_l1=4.462545425626004 lambda_l2=1.467833225966605 learning_rate=2.6901319610022874e-05 max_bin=145.0 min_data_in_leaf=68.0 min_sum_hessian_in_leaf=4.253332160114566 num_leaves=54.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #497 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8748074238944175 bagging_freq=5.0 feature_fraction=0.9533793466521424 lambda_l1=3.044618453024417 lambda_l2=1.3361529834059271 learning_rate=0.0006094599156100299 max_bin=141.0 min_data_in_leaf=68.0 min_sum_hessian_in_leaf=4.614449149155419 num_leaves=65.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #498 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8571154755642414 bagging_freq=5.0 feature_fraction=0.9436236332778999 lambda_l1=3.3266379857283614 lambda_l2=1.0087756009410915 learning_rate=0.00029280891374977927 max_bin=144.0 min_data_in_leaf=65.0 min_sum_hessian_in_leaf=4.450978786816922 num_leaves=62.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #499 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.872366244586863 bagging_freq=4.0 feature_fraction=0.9706131695995472 lambda_l1=2.844050317934376 lambda_l2=1.9020554561613296 learning_rate=0.0010569612962519502 max_bin=136.0 min_data_in_leaf=77.0 min_sum_hessian_in_leaf=5.585895082927095 num_leaves=68.0\n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "                                                                     \n",
      "LightGBM objective call #500 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8841589159518165 bagging_freq=4.0 feature_fraction=0.9737567973055427 lambda_l1=3.024086148480068 lambda_l2=6.850705553854805 learning_rate=0.0012049907268457732 max_bin=139.0 min_data_in_leaf=72.0 min_sum_hessian_in_leaf=4.311923225716929 num_leaves=65.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "nb_trees=1 val_loss={'rmse': nan}                                    \n",
      "val_r2_score=0.0                                                     \n",
      "100%|██████████| 500/500 [29:57<00:00,  3.59s/trial, best loss: -0.0]\n",
      "--------------------------------------------------\n",
      "The best params:\n",
      "{'bagging_fraction': 0.9901523137621939, 'bagging_freq': 8.0, 'feature_fraction': 0.9794803683645283, 'lambda_l1': 2.403666923687541, 'lambda_l2': 7.626310436598386, 'learning_rate': 0.0032899076107307168, 'max_bin': 144.0, 'min_data_in_leaf': 70.0, 'min_sum_hessian_in_leaf': 3.70520397201021, 'num_leaves': 59.0}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import sklearn\n",
    "import numpy\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "import colorama\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "N_HYPEROPT_PROBES = 500\n",
    "HYPEROPT_ALGO = tpe.suggest  #  tpe.suggest OR hyperopt.rand.suggest\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "colorama.init()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def get_lgb_params(space):\n",
    "    lgb_params = dict()\n",
    "    lgb_params['boosting_type'] = space['boosting_type'] if 'boosting_type' in space else 'gbdt'\n",
    "    lgb_params['objective'] = 'regression'\n",
    "    lgb_params['metric'] = 'rmse'\n",
    "    lgb_params['learning_rate'] = space['learning_rate']\n",
    "    lgb_params['num_leaves'] = int(space['num_leaves'])\n",
    "    lgb_params['min_data_in_leaf'] = int(space['min_data_in_leaf'])\n",
    "    lgb_params['min_sum_hessian_in_leaf'] = space['min_sum_hessian_in_leaf']\n",
    "    lgb_params['max_depth'] = -1\n",
    "    lgb_params['lambda_l1'] = space['lambda_l1'] if 'lambda_l1' in space else 0.0\n",
    "    lgb_params['lambda_l2'] = space['lambda_l2'] if 'lambda_l2' in space else 0.0\n",
    "    lgb_params['max_bin'] = int(space['max_bin']) if 'max_bin' in space else 256\n",
    "    lgb_params['feature_fraction'] = space['feature_fraction']\n",
    "    lgb_params['bagging_fraction'] = space['bagging_fraction']\n",
    "    lgb_params['bagging_freq'] = int(space['bagging_freq']) if 'bagging_freq' in space else 1\n",
    "    lgb_params['nthread'] = 4\n",
    "    return lgb_params\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "obj_call_count = 0\n",
    "cur_best_score = 0 # 0 or np.inf\n",
    "log_writer = open( 'log/lgb-hyperopt-log.txt', 'w' )\n",
    "\n",
    "\n",
    "def objective(space):\n",
    "    global obj_call_count, cur_best_score\n",
    "\n",
    "    obj_call_count += 1\n",
    "\n",
    "    print('\\nLightGBM objective call #{} cur_best_score={:7.5f}'.format(obj_call_count,cur_best_score) )\n",
    "\n",
    "    lgb_params = get_lgb_params(space)\n",
    "\n",
    "    sorted_params = sorted(space.items(), key=lambda z: z[0])\n",
    "    params_str = str.join(' ', ['{}={}'.format(k, v) for k, v in sorted_params])\n",
    "    print('Params: {}'.format(params_str) )\n",
    "    \n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "    out_of_fold = np.zeros(len(X_train))\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "        D_train = lgb.Dataset(X_train.iloc[train_idx], label=Y_train[train_idx])\n",
    "        D_val = lgb.Dataset(X_train.iloc[val_idx], label=Y_train[val_idx])\n",
    "        # Train\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(lgb_params,\n",
    "                           D_train,\n",
    "                           num_boost_round=num_round,\n",
    "                           # metrics='mlogloss',\n",
    "                           valid_sets=D_val,\n",
    "                           # valid_names='val',\n",
    "                           # fobj=None,\n",
    "                           # feval=None,\n",
    "                           # init_model=None,\n",
    "                           # feature_name='auto',\n",
    "                           # categorical_feature='auto',\n",
    "                           early_stopping_rounds=200,\n",
    "                           # evals_result=None,\n",
    "                           verbose_eval=False,\n",
    "                           # learning_rates=None,\n",
    "                           # keep_training_booster=False,\n",
    "                           # callbacks=None\n",
    "                           )\n",
    "        # predict\n",
    "        nb_trees = clf.best_iteration\n",
    "        val_loss = clf.best_score['valid_0']\n",
    "        print('nb_trees={} val_loss={}'.format(nb_trees, val_loss))\n",
    "        out_of_fold[val_idx] = clf.predict(X_train.iloc[val_idx], num_iteration=nb_trees)\n",
    "        score = r2_score(out_of_fold, Y_train)\n",
    "\n",
    "    print('val_r2_score={}'.format(score))\n",
    "\n",
    "    log_writer.write('score={} Params:{} nb_trees={}\\n'.format(score, params_str, nb_trees ))\n",
    "    log_writer.flush()\n",
    "\n",
    "    if score>cur_best_score:\n",
    "        cur_best_score = score\n",
    "        print(colorama.Fore.GREEN + 'NEW BEST SCORE={}'.format(cur_best_score) + colorama.Fore.RESET)\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "space ={\n",
    "        'num_leaves': hp.quniform ('num_leaves', 10, 100, 1),\n",
    "        'min_data_in_leaf':  hp.quniform ('min_data_in_leaf', 10, 100, 1),\n",
    "        'feature_fraction': hp.uniform('feature_fraction', 0.75, 1.0),\n",
    "        'bagging_fraction': hp.uniform('bagging_fraction', 0.75, 1.0),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0, 0.01),\n",
    "#         'learning_rate': hp.loguniform('learning_rate', -5.0, -2.3),\n",
    "        'min_sum_hessian_in_leaf': hp.loguniform('min_sum_hessian_in_leaf', 0, 2.3),\n",
    "        'max_bin': hp.quniform ('max_bin', 88, 200, 1),\n",
    "        'bagging_freq': hp.quniform ('bagging_freq', 1, 15, 1),\n",
    "        'lambda_l1': hp.uniform('lambda_l1', 0, 10 ),\n",
    "        'lambda_l2': hp.uniform('lambda_l2', 0, 10 ),\n",
    "       }\n",
    "\n",
    "trials = Trials()\n",
    "best = hyperopt.fmin(fn=objective,\n",
    "                     space=space,\n",
    "                     algo=HYPEROPT_ALGO,\n",
    "                     max_evals=N_HYPEROPT_PROBES,\n",
    "                     trials=trials,\n",
    "                     verbose=1)\n",
    "\n",
    "print('-'*50)\n",
    "print('The best params:')\n",
    "print( best )\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
